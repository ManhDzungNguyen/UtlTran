{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":710,"status":"ok","timestamp":1642486293288,"user":{"displayName":"Mạnh Dũng Nguyễn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghv0al56qw_A8F0xE48V5OetG5WUMxf6MGyxK1g4cI=s64","userId":"13942456880411028305"},"user_tz":-420},"id":"6WgJfjtx6g9s","outputId":"489622c7-fe91-467e-b029-7a0b3a6c2dfc"},"outputs":[{"name":"stdout","output_type":"stream","text":["Tue Jan 18 06:11:31 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 495.46       Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   39C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27221,"status":"ok","timestamp":1642486320505,"user":{"displayName":"Mạnh Dũng Nguyễn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghv0al56qw_A8F0xE48V5OetG5WUMxf6MGyxK1g4cI=s64","userId":"13942456880411028305"},"user_tz":-420},"id":"H6vszI4Z6vdg","outputId":"54bb0928-2f50-49dc-d40b-d55d0b71747b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":117894,"status":"ok","timestamp":1642486438394,"user":{"displayName":"Mạnh Dũng Nguyễn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghv0al56qw_A8F0xE48V5OetG5WUMxf6MGyxK1g4cI=s64","userId":"13942456880411028305"},"user_tz":-420},"id":"sUVC9D446J4M","outputId":"65affc12-d2bd-4cfb-d688-9ac1b00336a3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting transformers==3.5.1\n","  Downloading transformers-3.5.1-py3-none-any.whl (1.3 MB)\n","\u001b[K     |████████████████████████████████| 1.3 MB 3.8 MB/s \n","\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from transformers==3.5.1) (3.17.3)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 63.5 MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.5.1) (21.3)\n","Collecting sentencepiece==0.1.91\n","  Downloading sentencepiece-0.1.91-cp37-cp37m-manylinux1_x86_64.whl (1.1 MB)\n","\u001b[K     |████████████████████████████████| 1.1 MB 71.4 MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3.5.1) (1.19.5)\n","Collecting tokenizers==0.9.3\n","  Downloading tokenizers-0.9.3-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n","\u001b[K     |████████████████████████████████| 2.9 MB 53.1 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm\u003e=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3.5.1) (4.62.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3.5.1) (2.23.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.5.1) (3.4.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.5.1) (2019.12.20)\n","Requirement already satisfied: pyparsing!=3.0.5,\u003e=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging-\u003etransformers==3.5.1) (3.0.6)\n","Requirement already satisfied: six\u003e=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf-\u003etransformers==3.5.1) (1.15.0)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers==3.5.1) (2021.10.8)\n","Requirement already satisfied: idna\u003c3,\u003e=2.5 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers==3.5.1) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,\u003c1.26,\u003e=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers==3.5.1) (1.24.3)\n","Requirement already satisfied: chardet\u003c4,\u003e=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers==3.5.1) (3.0.4)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses-\u003etransformers==3.5.1) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses-\u003etransformers==3.5.1) (1.1.0)\n","Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n","Successfully installed sacremoses-0.0.47 sentencepiece-0.1.91 tokenizers-0.9.3 transformers-3.5.1\n","Collecting torch==1.4.0\n","  Downloading torch-1.4.0-cp37-cp37m-manylinux1_x86_64.whl (753.4 MB)\n","\u001b[K     |████████████████████████████████| 753.4 MB 6.6 kB/s \n","\u001b[?25hInstalling collected packages: torch\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.10.0+cu111\n","    Uninstalling torch-1.10.0+cu111:\n","      Successfully uninstalled torch-1.10.0+cu111\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchvision 0.11.1+cu111 requires torch==1.10.0, but you have torch 1.4.0 which is incompatible.\n","torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.4.0 which is incompatible.\n","torchaudio 0.10.0+cu111 requires torch==1.10.0, but you have torch 1.4.0 which is incompatible.\u001b[0m\n","Successfully installed torch-1.4.0\n"]}],"source":["#version modifed training less RAM + trivia dataset\n","!pip install transformers==3.5.1\n","!pip install torch==1.4.0"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":5510,"status":"ok","timestamp":1642486445728,"user":{"displayName":"Mạnh Dũng Nguyễn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghv0al56qw_A8F0xE48V5OetG5WUMxf6MGyxK1g4cI=s64","userId":"13942456880411028305"},"user_tz":-420},"id":"ffCTlYYK6J4M"},"outputs":[],"source":["from transformers import BertTokenizer, BertForPreTraining, BertForQuestionAnswering, BertModel, BertConfig\n","from transformers import XLMRobertaForQuestionAnswering, XLMRobertaTokenizer, XLMRobertaConfig\n","import torch\n","import torch.nn as nn\n","from transformers.data.metrics.squad_metrics import compute_predictions_log_probs, compute_predictions_logits, squad_evaluate\n","from transformers.data.processors.squad import SquadResult, SquadV1Processor, SquadV2Processor"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hecp6HpV6J4N"},"outputs":[],"source":["# class mBert(nn.Module):\n","#     def __init__(self):\n","#         super(mBert, self).__init__()\n","#         self.bert_block = BertModel.from_pretrained(\"bert-base-multilingual-cased\")\n","#         self.question = nn.Linear(768, 2, bias=True)\n","#     def forward(self, inputs):\n","#         pooled_output, sequence_output = self.bert_block(inputs)\n","#         return self.question(sequence_output)"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":188},"executionInfo":{"elapsed":56520,"status":"ok","timestamp":1642486502246,"user":{"displayName":"Mạnh Dũng Nguyễn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghv0al56qw_A8F0xE48V5OetG5WUMxf6MGyxK1g4cI=s64","userId":"13942456880411028305"},"user_tz":-420},"id":"PjTN0n-V6J4N","outputId":"4ccad365-ade5-4c86-a744-4800f5d93901"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"94ee0a04b4cf4b7ca3aef0d59df25879","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/513 [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"87adbd525ce8463face45cfc88aedd79","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/2.24G [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at xlm-roberta-large were not used when initializing XLMRobertaForQuestionAnswering: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n","- This IS expected if you are initializing XLMRobertaForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLMRobertaForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of XLMRobertaForQuestionAnswering were not initialized from the model checkpoint at xlm-roberta-large and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["#model = XLMRobertaForQuestionAnswering.from_pretrained('/content/drive/MyDrive/Colab Notebooks/MRC - VLSP/Data Preprocessing/final_model_Jan11')\n","model = XLMRobertaForQuestionAnswering.from_pretrained('xlm-roberta-large')"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49},"executionInfo":{"elapsed":3454,"status":"ok","timestamp":1642486505697,"user":{"displayName":"Mạnh Dũng Nguyễn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghv0al56qw_A8F0xE48V5OetG5WUMxf6MGyxK1g4cI=s64","userId":"13942456880411028305"},"user_tz":-420},"id":"980HgqWS6J4O","outputId":"6fd59fd6-db48-4808-f082-7aa5befd3be9"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0ab171dd715c4d8cb9fd07fc5da85b8a","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/5.07M [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["# model = mBert()\n","tokenizer = XLMRobertaTokenizer.from_pretrained(\"xlm-roberta-large\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QKjrd56l6J4O"},"outputs":[],"source":["# !mkdir dataset \\\n","# \u0026\u0026 cd dataset \\\n","# \u0026\u0026 wget https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v1.1.json \\\n","# \u0026\u0026 wget https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v1.1.json"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1642486505698,"user":{"displayName":"Mạnh Dũng Nguyễn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghv0al56qw_A8F0xE48V5OetG5WUMxf6MGyxK1g4cI=s64","userId":"13942456880411028305"},"user_tz":-420},"id":"clnm69g26J4O"},"outputs":[],"source":["processor = SquadV1Processor()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F59ui6vI6J4O"},"outputs":[],"source":["# train_examples = processor.get_train_examples('../input/trivia-full-filted','train_wiki_total.json')\n","# dev_examples = processor.get_dev_examples('../input/viquad-v1','dev_ViQuAD.json')"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1642486505698,"user":{"displayName":"Mạnh Dũng Nguyễn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghv0al56qw_A8F0xE48V5OetG5WUMxf6MGyxK1g4cI=s64","userId":"13942456880411028305"},"user_tz":-420},"id":"CV-eK2lF6J4O"},"outputs":[],"source":["from transformers.data.processors.squad import squad_convert_examples_to_features"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1642486505698,"user":{"displayName":"Mạnh Dũng Nguyễn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghv0al56qw_A8F0xE48V5OetG5WUMxf6MGyxK1g4cI=s64","userId":"13942456880411028305"},"user_tz":-420},"id":"i2QzqFUb6J4P"},"outputs":[],"source":["def read_saved_data(input_dir,evaluate=False,output_examples=False):\n","    from torch.utils.data import TensorDataset\n","\n","    if output_examples:\n","        feat=\"features;datasets;examples\"\n","    else:\n","        feat=\"datasets\"\n","\n","    all_features = {\"features\":[],\"examples\":[],\"datasets\":[]}\n","    all_input_ids = torch.tensor([], dtype=torch.long)\n","    all_attention_masks = torch.tensor([], dtype=torch.long)\n","    all_token_type_ids = torch.tensor([], dtype=torch.long)\n","    all_cls_index = torch.tensor([], dtype=torch.long)\n","    all_p_mask = torch.tensor([], dtype=torch.float)\n","    all_is_impossible = torch.tensor([], dtype=torch.float)\n","    all_start_positions = torch.tensor([], dtype=torch.long)\n","    all_end_positions = torch.tensor([], dtype=torch.long)\n","\n","    for i in feat.split(\";\"):\n","        for file_name in os.listdir(os.path.join(input_dir,i)):\n","            data = torch.load(os.path.join(input_dir,i,file_name))[i]\n","            if isinstance(data,TensorDataset):\n","                if evaluate:\n","                    all_input_ids = torch.cat([all_input_ids,data.tensors[0]],dim=0)\n","                    all_attention_masks = torch.cat([all_attention_masks,data.tensors[1]],dim=0)\n","                    all_token_type_ids = torch.cat([all_token_type_ids,data.tensors[2]],dim=0)\n","                    all_cls_index = torch.cat([all_cls_index,data.tensors[4]],dim=0)\n","                    all_p_mask = torch.cat([all_p_mask,data.tensors[5]],dim=0)\n","                else:\n","                    all_input_ids = torch.cat([all_input_ids,data.tensors[0]],dim=0)\n","                    all_attention_masks = torch.cat([all_attention_masks,data.tensors[1]],dim=0)\n","                    all_token_type_ids = torch.cat([all_token_type_ids,data.tensors[2]],dim=0)\n","                    all_start_positions = torch.cat([all_start_positions,data.tensors[3]],dim=0)\n","                    all_end_positions = torch.cat([all_end_positions,data.tensors[4]],dim=0)\n","                    all_cls_index = torch.cat([all_cls_index,data.tensors[5]],dim=0)\n","                    all_p_mask = torch.cat([all_p_mask,data.tensors[6]],dim=0)\n","                    all_is_impossible = torch.cat([all_is_impossible,data.tensors[7]],dim=0)\n","            elif isinstance(data,list):\n","                all_features[i] += data\n","    \n","    if evaluate and \"datasets\" in feat.split(\";\"):\n","        all_example_index = torch.arange(all_input_ids.size(0), dtype=torch.long)\n","        all_features[\"datasets\"] = TensorDataset(all_input_ids, all_attention_masks, all_token_type_ids, all_example_index, all_cls_index, all_p_mask)\n","    elif not evaluate and \"datasets\" in feat.split(\";\"):\n","        all_features[\"datasets\"] = TensorDataset(all_input_ids,all_attention_masks,all_token_type_ids,all_start_positions,all_end_positions,all_cls_index,all_p_mask,all_is_impossible,)\n","\n","\n","    if output_examples:\n","        return all_features['datasets'], all_features['examples'], all_features['features']\n","    else:\n","        return all_features['datasets']"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1642486505698,"user":{"displayName":"Mạnh Dũng Nguyễn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghv0al56qw_A8F0xE48V5OetG5WUMxf6MGyxK1g4cI=s64","userId":"13942456880411028305"},"user_tz":-420},"id":"U2u3dk_r6J4P"},"outputs":[],"source":["import gc\n","max_seq_length = 384\n","def load_and_cache_examples(tokenizer, evaluate=False, output_examples= False):\n","    input_dir = \".\"\n","    cached_features_file = os.path.join(\n","        input_dir,\n","        \"cached_{}_{}_{}\".format(\n","            \"dev\" if evaluate else \"train\",\n","            \"xlmr\",\n","            str(max_seq_length),\n","        ),\n","    )\n","    root_dir = os.path.join(cached_features_file+\"_dir\")\n","    features_file = os.path.join(root_dir,'features')\n","    datasets_file = os.path.join(root_dir,'datasets')\n","    examples_file = os.path.join(root_dir,'examples')\n","    if evaluate:\n","        print(\"NO EVAL\")\n","#         examples = processor.get_dev_examples('../input/viquad-v1', 'dev_ViQuAD.json')\n","#         examples = processor.get_dev_examples('../input/merge-dataset', 'merge_dataset_v1_dev.json')\n","    else:\n","#         examples = processor.get_train_examples('../input/viquad-v1', 'train_ViQuAD.json')\n","        examples = processor.get_train_examples('/content/drive/MyDrive/Colab Notebooks/MRC - VLSP/Dataset','trivia+newsqa_dataset_Jan18_v1_train.json')\n","    for i,j in enumerate(range(0, len(examples), 40000)):\n","        sub_examples = examples[j:j+40000]\n","        features, dataset = squad_convert_examples_to_features(\n","                examples=sub_examples,\n","                tokenizer=tokenizer,\n","                max_seq_length=384,\n","                doc_stride=128,\n","                max_query_length=64,\n","                is_training=not evaluate,\n","                return_dataset=\"pt\",\n","                threads=10,\n","            )\n","        if not os.path.exists(os.path.join(features_file)):\n","            os.makedirs(os.path.join(features_file))\n","        if not os.path.exists(os.path.join(datasets_file)):\n","            os.makedirs(os.path.join(datasets_file))\n","        if not os.path.exists(os.path.join(examples_file)):\n","            os.makedirs(os.path.join(examples_file))\n","        print(\"Saving features into cached files %s, %s, %s\", os.path.join(features_file,'features_'+str(i)),os.path.join(datasets_file,'datasets_'+str(i)),os.path.join(examples_file,'examples_'+str(i)))\n","        torch.save({\"features\": features}, os.path.join(features_file,'features_'+str(i)))\n","        torch.save({\"datasets\": dataset}, os.path.join(datasets_file,'datasets_'+str(i)))\n","        torch.save({\"examples\": sub_examples}, os.path.join(examples_file,'examples_'+str(i)))\n","        print(\"Done\")\n","        del features, dataset\n","        gc.collect()\n","    del examples\n","    return read_saved_data(root_dir,evaluate=evaluate,output_examples=output_examples)"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":438997,"status":"ok","timestamp":1642486944691,"user":{"displayName":"Mạnh Dũng Nguyễn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghv0al56qw_A8F0xE48V5OetG5WUMxf6MGyxK1g4cI=s64","userId":"13942456880411028305"},"user_tz":-420},"id":"J10zdvAa6J4Q","outputId":"342f8e36-c8ce-42c7-c867-c9c4086b4b13"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 76595/76595 [00:17\u003c00:00, 4285.07it/s]\n","convert squad examples to features:   0%|          | 0/40000 [00:00\u003c?, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:1423: FutureWarning: The `max_len` attribute has been deprecated and will be removed in a future version, use `model_max_length` instead.\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:1423: FutureWarning: The `max_len` attribute has been deprecated and will be removed in a future version, use `model_max_length` instead.\n","  FutureWarning,\n","convert squad examples to features: 100%|██████████| 40000/40000 [02:38\u003c00:00, 252.49it/s]\n","add example index and unique id: 100%|██████████| 40000/40000 [00:00\u003c00:00, 684147.65it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Saving features into cached files %s, %s, %s ./cached_train_xlmr_384_dir/features/features_0 ./cached_train_xlmr_384_dir/datasets/datasets_0 ./cached_train_xlmr_384_dir/examples/examples_0\n","Done\n"]},{"name":"stderr","output_type":"stream","text":["\rconvert squad examples to features:   0%|          | 0/36595 [00:00\u003c?, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:1423: FutureWarning: The `max_len` attribute has been deprecated and will be removed in a future version, use `model_max_length` instead.\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:1423: FutureWarning: The `max_len` attribute has been deprecated and will be removed in a future version, use `model_max_length` instead.\n","  FutureWarning,\n","convert squad examples to features: 100%|██████████| 36595/36595 [02:34\u003c00:00, 237.33it/s]\n","add example index and unique id: 100%|██████████| 36595/36595 [00:00\u003c00:00, 697582.87it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Saving features into cached files %s, %s, %s ./cached_train_xlmr_384_dir/features/features_1 ./cached_train_xlmr_384_dir/datasets/datasets_1 ./cached_train_xlmr_384_dir/examples/examples_1\n","Done\n"]}],"source":["import os\n","train_dataset = load_and_cache_examples(tokenizer, evaluate= False, output_examples = False)"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1642486944692,"user":{"displayName":"Mạnh Dũng Nguyễn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghv0al56qw_A8F0xE48V5OetG5WUMxf6MGyxK1g4cI=s64","userId":"13942456880411028305"},"user_tz":-420},"id":"EVuI9If66J4Q"},"outputs":[],"source":["def to_list(tensor):\n","    return tensor.detach().cpu().tolist()"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1642486944692,"user":{"displayName":"Mạnh Dũng Nguyễn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghv0al56qw_A8F0xE48V5OetG5WUMxf6MGyxK1g4cI=s64","userId":"13942456880411028305"},"user_tz":-420},"id":"DLFh_eN76J4R"},"outputs":[],"source":["import os\n","def evaluate(model, tokenizer, dev_dataset, dev_examples, dev_features):\n","    eval_sampler = SequentialSampler(dev_dataset)\n","    eval_dataloader = DataLoader(dev_dataset, sampler=eval_sampler, batch_size=12)\n","    all_results = []\n","#     start_time = timeit.default_timer()\n","    for batch in tqdm(eval_dataloader, desc=\"Evaluating\"):\n","        model.eval()\n","        batch = tuple(t.to(device) for t in batch)\n","        with torch.no_grad():\n","            inputs = {\n","                \"input_ids\": batch[0],\n","                \"attention_mask\": batch[1],\n","                \"token_type_ids\": batch[2],\n","            }\n","            del inputs[\"token_type_ids\"]\n","            example_indices = batch[3]\n","            outputs = model(**inputs)\n","        for i, example_index in enumerate(example_indices):\n","            eval_feature = dev_features[example_index.item()]\n","            unique_id = int(eval_feature.unique_id)\n","#             for output in outputs:\n","#                 print(output)\n","            output = [to_list(output[i]) for output in outputs]\n","#             output = [to_list(output) for output in outputs]\n","            if len(output) \u003e= 5:\n","                start_logits = output[0]\n","                start_top_index = output[1]\n","                end_logits = output[2]\n","                end_top_index = output[3]\n","                cls_logits = output[4]\n","\n","                result = SquadResult(\n","                    unique_id,\n","                    start_logits,\n","                    end_logits,\n","                    start_top_index=start_top_index,\n","                    end_top_index=end_top_index,\n","                    cls_logits=cls_logits,\n","                )\n","            else:\n","                start_logits, end_logits = output\n","                result = SquadResult(unique_id, start_logits, end_logits)\n","            all_results.append(result)\n","    \n","    output_prediction_file = os.path.join(\"./\", \"predictions_{}.json\".format(\"\"))\n","    output_nbest_file = os.path.join(\"./\", \"nbest_predictions_{}.json\".format(\"\"))\n","    output_null_log_odds_file = os.path.join(\"./\", \"null_odds_{}.json\".format(\"\"))\n","    predictions = compute_predictions_logits(\n","            dev_examples,\n","            dev_features,\n","            all_results,\n","            20,\n","            300,\n","            False,\n","            output_prediction_file,\n","            output_nbest_file,\n","            output_null_log_odds_file,\n","            True,\n","            False,\n","            0.0,\n","            tokenizer,\n","        )\n","    results = squad_evaluate(dev_examples, predictions)\n","    return results"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1642486944692,"user":{"displayName":"Mạnh Dũng Nguyễn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghv0al56qw_A8F0xE48V5OetG5WUMxf6MGyxK1g4cI=s64","userId":"13942456880411028305"},"user_tz":-420},"id":"4i5HAFBD6J4R"},"outputs":[],"source":["from torch.utils.tensorboard import SummaryWriter\n","from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n","from transformers import AdamW, get_linear_schedule_with_warmup\n","from tqdm import trange, tqdm\n","device = torch.device('cuda')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZOERItTY6J4R"},"outputs":[],"source":["# for param in model.bert.parameters():\n","#     param.requires_grad = False"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"5eV3WagS6J4R"},"outputs":[{"name":"stderr","output_type":"stream","text":["Iteration:  26%|██▌       | 4999/19149 [53:35\u003c2:31:39,  1.56it/s]"]},{"name":"stdout","output_type":"stream","text":[" global_step = %s, average loss = %s 5000 2.001495752763748\n"]},{"name":"stderr","output_type":"stream","text":["Iteration:  52%|█████▏    | 9999/19149 [1:47:08\u003c1:38:05,  1.55it/s]"]},{"name":"stdout","output_type":"stream","text":[" global_step = %s, average loss = %s 10000 1.705783836760372\n"]},{"name":"stderr","output_type":"stream","text":["Iteration:  78%|███████▊  | 14999/19149 [2:40:42\u003c44:26,  1.56it/s]"]},{"name":"stdout","output_type":"stream","text":[" global_step = %s, average loss = %s 15000 1.5276071681057413\n"]},{"name":"stderr","output_type":"stream","text":["Iteration: 100%|██████████| 19149/19149 [3:25:08\u003c00:00,  1.56it/s]\n","Epoch: 100%|██████████| 1/1 [3:25:08\u003c00:00, 12308.02s/it]\n"]},{"data":{"text/plain":["('/content/drive/MyDrive/Colab Notebooks/MRC - VLSP/Models/trivia_newsqa_pretrained_model_Jan18/tokenizer_config.json',\n"," '/content/drive/MyDrive/Colab Notebooks/MRC - VLSP/Models/trivia_newsqa_pretrained_model_Jan18/special_tokens_map.json',\n"," '/content/drive/MyDrive/Colab Notebooks/MRC - VLSP/Models/trivia_newsqa_pretrained_model_Jan18/sentencepiece.bpe.model',\n"," '/content/drive/MyDrive/Colab Notebooks/MRC - VLSP/Models/trivia_newsqa_pretrained_model_Jan18/added_tokens.json')"]},"execution_count":null,"metadata":{},"output_type":"execute_result"}],"source":["import numpy as np\n","num_epochs = 1\n","tb_writer = SummaryWriter()\n","train_sampler = RandomSampler(train_dataset)\n","train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=4)\n","t_total = len(train_dataloader) // 1 * num_epochs\n","\n","\n","no_decay = [\"bias\", \"LayerNorm.weight\"]\n","\n","optimizer_grouped_parameters = [\n","    {\n","        \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n","        \"weight_decay\": 0,\n","    },\n","    {\"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], \"weight_decay\": 0.0},\n","]\n","optimizer = AdamW(optimizer_grouped_parameters, lr=2e-5, eps = 1e-8)\n","scheduler = get_linear_schedule_with_warmup(\n","    optimizer, num_warmup_steps=814, num_training_steps=t_total\n",")\n","\n","device = torch.device('cuda')\n","\n","model.to(device)\n","\n","global_step = 1\n","epochs_trained = 0\n","steps_trained_in_current_epoch = 0\n","tr_loss, logging_loss = 0.0, 0.0\n","\n","model.zero_grad()\n","train_iterator = trange(\n","    epochs_trained, int(num_epochs), desc=\"Epoch\", disable=-1 not in [-1, 0]\n",")\n","\n","from functools import partial\n","tqdm = partial(tqdm, position=0, leave=True)\n","\n","for _ in train_iterator:\n","    epoch_iterator = tqdm(train_dataloader, desc=\"Iteration\", disable=False)\n","    for step, batch in enumerate(epoch_iterator):\n","        model.train()\n","        batch = tuple(t.to(device) for t in batch)\n","        \n","        inputs = {\n","            \"input_ids\": batch[0],\n","            \"attention_mask\": batch[1],\n","            \"token_type_ids\": batch[2],\n","            \"start_positions\": batch[3],\n","            \"end_positions\": batch[4],\n","        }\n","        del inputs[\"token_type_ids\"]\n","        outputs = model(**inputs)\n","        loss = outputs[0]\n","        loss.backward()\n","        tr_loss += loss.item()\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n","        optimizer.step()\n","        scheduler.step()\n","        model.zero_grad()\n","        global_step += 1\n","\n","        if global_step % 5000 == 0:\n","#             output_dir = os.path.join('./', \"checkpoint-{}\".format(global_step))\n","#             model_to_save = model.module if hasattr(model, \"module\") else model\n","#             model_to_save.save_pretrained(output_dir)\n","#             tokenizer.save_pretrained(output_dir)\n","#             torch.save(optimizer.state_dict(), os.path.join(output_dir, \"optimizer.pt\"))\n","#             torch.save(scheduler.state_dict(), os.path.join(output_dir, \"scheduler.pt\"))\n","            print(\" global_step = %s, average loss = %s\", global_step, tr_loss/global_step)\n","\n","            \n","# output_dir = os.path.join('./', 'final_model')\n","output_dir = os.path.join('/content/drive/MyDrive/Colab Notebooks/MRC - VLSP/Models', 'trivia_newsqa_pretrained_model_Jan18')\n","model_to_save = model.module if hasattr(model, \"module\") else model\n","model_to_save.save_pretrained(output_dir)\n","tokenizer.save_pretrained(output_dir)\n","\n","# print(\" global_step = %s, average loss = %s\", global_step, tr_loss/global_step)\n","\n","# results = evaluate(model, tokenizer, dev_dataset, dev_examples, dev_features)\n","# for key, value in results.items():\n","#     print(key, value)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"422LWRpJ6J4S"},"outputs":[],"source":["tokenizer_1 = XLMRobertaTokenizer.from_pretrained(\"xlm-roberta-large\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"k6Myl0EQ6J4S","outputId":"8a505426-bfb9-4183-9031-868498796dd0"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 18/18 [00:01\u003c00:00, 17.98it/s]\n","convert squad examples to features:   0%|          | 0/2210 [00:00\u003c?, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:1423: FutureWarning: The `max_len` attribute has been deprecated and will be removed in a future version, use `model_max_length` instead.\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:1423: FutureWarning: The `max_len` attribute has been deprecated and will be removed in a future version, use `model_max_length` instead.\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:1423: FutureWarning: The `max_len` attribute has been deprecated and will be removed in a future version, use `model_max_length` instead.\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:1423: FutureWarning: The `max_len` attribute has been deprecated and will be removed in a future version, use `model_max_length` instead.\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:1423: FutureWarning: The `max_len` attribute has been deprecated and will be removed in a future version, use `model_max_length` instead.\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:1423: FutureWarning: The `max_len` attribute has been deprecated and will be removed in a future version, use `model_max_length` instead.\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:1423: FutureWarning: The `max_len` attribute has been deprecated and will be removed in a future version, use `model_max_length` instead.\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:1423: FutureWarning: The `max_len` attribute has been deprecated and will be removed in a future version, use `model_max_length` instead.\n","  FutureWarning,\n","convert squad examples to features: 100%|██████████| 2210/2210 [00:05\u003c00:00, 400.51it/s]\n","add example index and unique id: 100%|██████████| 2210/2210 [00:00\u003c00:00, 579881.88it/s]\n"]}],"source":["test_examples = processor.get_dev_examples('/content/drive/MyDrive/Colab Notebooks/MRC - VLSP/Dataset/ViQuADv1.1','test_ViQuAD.json')\n","test_features, test_dataset = squad_convert_examples_to_features(test_examples, \n","                                                       tokenizer, \n","                                                       max_seq_length = 384, \n","                                                       doc_stride = 128,\n","                                                       max_query_length = 64,\n","                                                       is_training = False,\n","                                                       return_dataset = 'pt',\n","                                                       threads = 10\n","                                                       )"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"b5QBgylV6J4S","outputId":"8cfaadfb-4aae-4dac-f7e5-a93fd592fc22"},"outputs":[{"name":"stderr","output_type":"stream","text":["Evaluating: 100%|██████████| 201/201 [01:38\u003c00:00,  2.05it/s]\n"]},{"name":"stdout","output_type":"stream","text":["exact 66.57608695652173\n","f1 85.93879954485978\n","total 2208\n","HasAns_exact 66.57608695652173\n","HasAns_f1 85.93879954485978\n","HasAns_total 2208\n","best_exact 66.57608695652173\n","best_exact_thresh 0.0\n","best_f1 85.93879954485978\n","best_f1_thresh 0.0\n"]}],"source":["results = evaluate(model, tokenizer_1, test_dataset, test_examples, test_features)\n","for key, value in results.items():\n","    print(key, value)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VERhwnKn6J4S"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uPtYd4556J4T"},"outputs":[],"source":[""]}],"metadata":{"accelerator":"GPU","colab":{"background_execution":"on","machine_shape":"hm","name":"fork-of-xlm-r_merge_data.ipynb","version":""},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"},"widgets":{"application/vnd.jupyter.widget-state+json":{"0ab171dd715c4d8cb9fd07fc5da85b8a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f572be95487a4f478ec6e6d410e89138","IPY_MODEL_4a56a9bf2a7a4886b0f208c36df4ab37","IPY_MODEL_3a82b2f35fad4152a08f3f0f3d5222ca"],"layout":"IPY_MODEL_a344ea89603c4e3cae8803ced86b58fe"}},"0f628c70a88b4b2a870c2cc7f048ad51":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"212a67c5384549a3ad22d0cb827511b9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"23367de7fc914552896a904fbc10ce21":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3a82b2f35fad4152a08f3f0f3d5222ca":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_212a67c5384549a3ad22d0cb827511b9","placeholder":"​","style":"IPY_MODEL_9050e3b9993f4ee89ea5b5e3c6e422e3","value":" 5.07M/5.07M [00:01\u0026lt;00:00, 4.99MB/s]"}},"4013555b354f49bca44f4edf52685473":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"426b3b2ad9a044d2914333b56625d91e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4a56a9bf2a7a4886b0f208c36df4ab37":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_83808c1356d940c4b5cd63ab4e8e80b4","max":5069051,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6bb28a2bc7a2484bb0d4eddce4c94519","value":5069051}},"53154186cb8d4284bb4c0abceda6d742":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_74abdb25fa8d422cba45d5ec70b54592","max":2244861551,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4013555b354f49bca44f4edf52685473","value":2244861551}},"5716d6e97e59465f95bb51b75408cdb0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6bb28a2bc7a2484bb0d4eddce4c94519":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"74abdb25fa8d422cba45d5ec70b54592":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7e65d61253ab49cb96a41075ac58c6b7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"80c59a18fff846df8ee9da8022c9a40b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"83808c1356d940c4b5cd63ab4e8e80b4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"87adbd525ce8463face45cfc88aedd79":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_88fe409c0a6c4745a9a13757d0a8b04f","IPY_MODEL_53154186cb8d4284bb4c0abceda6d742","IPY_MODEL_f336cfd9ff52430f89db395635330965"],"layout":"IPY_MODEL_5716d6e97e59465f95bb51b75408cdb0"}},"88fe409c0a6c4745a9a13757d0a8b04f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_891c3bff3a8c4501b61637fa5506931a","placeholder":"​","style":"IPY_MODEL_977def0ab19a490ba47d46981323db39","value":"Downloading: 100%"}},"891c3bff3a8c4501b61637fa5506931a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9050e3b9993f4ee89ea5b5e3c6e422e3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"927bd82c0d454b44a1bffdf6548c3247":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_80c59a18fff846df8ee9da8022c9a40b","max":513,"min":0,"orientation":"horizontal","style":"IPY_MODEL_db05bb8112644b70a5be7d5a386e9013","value":513}},"94ee0a04b4cf4b7ca3aef0d59df25879":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d4fbbbfbbb064e8ab28b31a73bfa9848","IPY_MODEL_927bd82c0d454b44a1bffdf6548c3247","IPY_MODEL_e63ca815d82f412c92faceb400a37455"],"layout":"IPY_MODEL_ce03cd8476fb4a7a9f0ed2919f2ba53f"}},"977def0ab19a490ba47d46981323db39":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a344ea89603c4e3cae8803ced86b58fe":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"afeaa51f108443a782adbe3bcb81a29b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ccfc80f2a32747fcb5803950aa23f9ea":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ce03cd8476fb4a7a9f0ed2919f2ba53f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d4fbbbfbbb064e8ab28b31a73bfa9848":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ccfc80f2a32747fcb5803950aa23f9ea","placeholder":"​","style":"IPY_MODEL_d503488c268a42e1aaa7710b3eb53d3a","value":"Downloading: 100%"}},"d503488c268a42e1aaa7710b3eb53d3a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"db05bb8112644b70a5be7d5a386e9013":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e63ca815d82f412c92faceb400a37455":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_afeaa51f108443a782adbe3bcb81a29b","placeholder":"​","style":"IPY_MODEL_426b3b2ad9a044d2914333b56625d91e","value":" 513/513 [00:00\u0026lt;00:00, 15.0kB/s]"}},"f336cfd9ff52430f89db395635330965":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0f628c70a88b4b2a870c2cc7f048ad51","placeholder":"​","style":"IPY_MODEL_7e65d61253ab49cb96a41075ac58c6b7","value":" 2.24G/2.24G [00:40\u0026lt;00:00, 56.0MB/s]"}},"f488c776d3584b8f905727f44f26798a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f572be95487a4f478ec6e6d410e89138":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f488c776d3584b8f905727f44f26798a","placeholder":"​","style":"IPY_MODEL_23367de7fc914552896a904fbc10ce21","value":"Downloading: 100%"}}}}},"nbformat":4,"nbformat_minor":0}