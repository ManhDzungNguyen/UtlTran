{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1641884705287,"user":{"displayName":"Mạnh Dũng Nguyễn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghv0al56qw_A8F0xE48V5OetG5WUMxf6MGyxK1g4cI=s64","userId":"13942456880411028305"},"user_tz":-420},"id":"6WgJfjtx6g9s","outputId":"089adbca-297a-4127-bb95-1029c5e2cdf3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Tue Jan 11 07:05:04 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 495.46       Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   41C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20424,"status":"ok","timestamp":1641884731799,"user":{"displayName":"Mạnh Dũng Nguyễn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghv0al56qw_A8F0xE48V5OetG5WUMxf6MGyxK1g4cI=s64","userId":"13942456880411028305"},"user_tz":-420},"id":"H6vszI4Z6vdg","outputId":"ed78108f-0323-4a81-9ada-844022188285"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":113182,"status":"ok","timestamp":1641884848240,"user":{"displayName":"Mạnh Dũng Nguyễn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghv0al56qw_A8F0xE48V5OetG5WUMxf6MGyxK1g4cI=s64","userId":"13942456880411028305"},"user_tz":-420},"id":"sUVC9D446J4M","outputId":"865d9bed-2bf0-49f8-b3cb-3f29705e9104"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting transformers==3.5.1\n","  Downloading transformers-3.5.1-py3-none-any.whl (1.3 MB)\n","\u001b[K     |████████████████████████████████| 1.3 MB 4.9 MB/s \n","\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from transformers==3.5.1) (3.17.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3.5.1) (2.23.0)\n","Collecting tokenizers==0.9.3\n","  Downloading tokenizers-0.9.3-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n","\u001b[K     |████████████████████████████████| 2.9 MB 58.9 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.5.1) (3.4.0)\n","Collecting sentencepiece==0.1.91\n","  Downloading sentencepiece-0.1.91-cp37-cp37m-manylinux1_x86_64.whl (1.1 MB)\n","\u001b[K     |████████████████████████████████| 1.1 MB 56.0 MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3.5.1) (1.19.5)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3.5.1) (4.62.3)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 54.5 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.5.1) (2019.12.20)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.5.1) (21.3)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.5.1) (3.0.6)\n","Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf->transformers==3.5.1) (1.15.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.5.1) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.5.1) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.5.1) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.5.1) (3.0.4)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.5.1) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.5.1) (1.1.0)\n","Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n","Successfully installed sacremoses-0.0.47 sentencepiece-0.1.91 tokenizers-0.9.3 transformers-3.5.1\n","Collecting torch==1.4.0\n","  Downloading torch-1.4.0-cp37-cp37m-manylinux1_x86_64.whl (753.4 MB)\n","\u001b[K     |████████████████████████████████| 753.4 MB 5.9 kB/s \n","\u001b[?25hInstalling collected packages: torch\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.10.0+cu111\n","    Uninstalling torch-1.10.0+cu111:\n","      Successfully uninstalled torch-1.10.0+cu111\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchvision 0.11.1+cu111 requires torch==1.10.0, but you have torch 1.4.0 which is incompatible.\n","torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.4.0 which is incompatible.\n","torchaudio 0.10.0+cu111 requires torch==1.10.0, but you have torch 1.4.0 which is incompatible.\u001b[0m\n","Successfully installed torch-1.4.0\n"]}],"source":["#version modifed training less RAM + trivia dataset\n","!pip install transformers==3.5.1\n","!pip install torch==1.4.0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ffCTlYYK6J4M"},"outputs":[],"source":["from transformers import BertTokenizer, BertForPreTraining, BertForQuestionAnswering, BertModel, BertConfig\n","from transformers import XLMRobertaForQuestionAnswering, XLMRobertaTokenizer, XLMRobertaConfig\n","import torch\n","import torch.nn as nn\n","from transformers.data.metrics.squad_metrics import compute_predictions_log_probs, compute_predictions_logits, squad_evaluate\n","from transformers.data.processors.squad import SquadResult, SquadV1Processor, SquadV2Processor"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hecp6HpV6J4N"},"outputs":[],"source":["# class mBert(nn.Module):\n","#     def __init__(self):\n","#         super(mBert, self).__init__()\n","#         self.bert_block = BertModel.from_pretrained(\"bert-base-multilingual-cased\")\n","#         self.question = nn.Linear(768, 2, bias=True)\n","#     def forward(self, inputs):\n","#         pooled_output, sequence_output = self.bert_block(inputs)\n","#         return self.question(sequence_output)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":188,"referenced_widgets":["2b1a652fce3f4c25bf5e794a8d473387","fe816b79962f44baaf30cde19bce01b8","12c5444db3d249509f599cf11af8815c","2d505f2c00e147cb8c5a8fc25cc849b5","5c33911980704772b2f9e7d839600ffd","9f458cb04a104dbba9f672887297c203","524eacf3c00a409b94a3b36f14c7d6d0","6f8199a296ad448f9bf924300a2981b2","4cbf89e36b374f2280f8430549515c58","261ffb66e1724af5aab9082859245d6c","c28a7865dc494cd5913b4bd2dd0e5199","f198d8d3a05d4d039608953ca651c203","e7c1fd7c212b4f76b3277f66d0cebab3","8eec272eb3034bbb92d1e3de7a3b4d86","0cc8c80670294acc8b9afcc8a82a803d","a85ee080d3514854b527d8d16fa0fc49","457c02cb12fb4360965ddad09cf9405f","29287d2cf2cc4403b461f246181b1924","7bc97c1ecd4c4577a390f6bc853e4c52","9c32ab2a275540f989bb810a4cf28f34","60a397010afe4fc3bf0d3f4fca6edc88","4605009614e74e80adf11955a8a5a0d4"]},"executionInfo":{"elapsed":68519,"status":"ok","timestamp":1641884933026,"user":{"displayName":"Mạnh Dũng Nguyễn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghv0al56qw_A8F0xE48V5OetG5WUMxf6MGyxK1g4cI=s64","userId":"13942456880411028305"},"user_tz":-420},"id":"PjTN0n-V6J4N","outputId":"549f25f5-d359-4da2-b178-5739622d5ba5"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2b1a652fce3f4c25bf5e794a8d473387","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/513 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f198d8d3a05d4d039608953ca651c203","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/2.24G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at xlm-roberta-large were not used when initializing XLMRobertaForQuestionAnswering: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n","- This IS expected if you are initializing XLMRobertaForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLMRobertaForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of XLMRobertaForQuestionAnswering were not initialized from the model checkpoint at xlm-roberta-large and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["# model = XLMRobertaForQuestionAnswering.from_pretrained('../input/ckpt-xlmr-xquad-pretrain/final_model')\n","model = XLMRobertaForQuestionAnswering.from_pretrained('xlm-roberta-large')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["2c6e34c6624842118e5f06dfafddb98a","c5f560197c9340f18189cdd8446dd976","6b8af8f84f324663b4613cc311838b6a","bffba7e732014ca388c38970d67e3778","c3deada8b47249c88ff076c365483b77","d1c6d1d593ad4ca4a439c72416a4e029","1221db8fa2cf48f784b5edaa4bed6b3d","25773199ddf84bf4afd56bc07c0ebf12","cb312f8386564fe08671391f58b88867","cc3179ccfcff485dbeeca03836356202","8a485770a5de4b1d9545a2c51538dbf0"]},"executionInfo":{"elapsed":561,"status":"ok","timestamp":1641884933579,"user":{"displayName":"Mạnh Dũng Nguyễn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghv0al56qw_A8F0xE48V5OetG5WUMxf6MGyxK1g4cI=s64","userId":"13942456880411028305"},"user_tz":-420},"id":"980HgqWS6J4O","outputId":"ab5d28b8-6cc4-4240-9019-d41f4b088a17"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2c6e34c6624842118e5f06dfafddb98a","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["# model = mBert()\n","tokenizer = XLMRobertaTokenizer.from_pretrained(\"xlm-roberta-large\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QKjrd56l6J4O"},"outputs":[],"source":["# !mkdir dataset \\\n","# && cd dataset \\\n","# && wget https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v1.1.json \\\n","# && wget https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v1.1.json"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"clnm69g26J4O"},"outputs":[],"source":["processor = SquadV1Processor()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F59ui6vI6J4O"},"outputs":[],"source":["# train_examples = processor.get_train_examples('../input/trivia-full-filted','train_wiki_total.json')\n","# dev_examples = processor.get_dev_examples('../input/viquad-v1','dev_ViQuAD.json')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CV-eK2lF6J4O"},"outputs":[],"source":["from transformers.data.processors.squad import squad_convert_examples_to_features"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i2QzqFUb6J4P"},"outputs":[],"source":["def read_saved_data(input_dir,evaluate=False,output_examples=False):\n","    from torch.utils.data import TensorDataset\n","\n","    if output_examples:\n","        feat=\"features;datasets;examples\"\n","    else:\n","        feat=\"datasets\"\n","\n","    all_features = {\"features\":[],\"examples\":[],\"datasets\":[]}\n","    all_input_ids = torch.tensor([], dtype=torch.long)\n","    all_attention_masks = torch.tensor([], dtype=torch.long)\n","    all_token_type_ids = torch.tensor([], dtype=torch.long)\n","    all_cls_index = torch.tensor([], dtype=torch.long)\n","    all_p_mask = torch.tensor([], dtype=torch.float)\n","    all_is_impossible = torch.tensor([], dtype=torch.float)\n","    all_start_positions = torch.tensor([], dtype=torch.long)\n","    all_end_positions = torch.tensor([], dtype=torch.long)\n","\n","    for i in feat.split(\";\"):\n","        for file_name in os.listdir(os.path.join(input_dir,i)):\n","            data = torch.load(os.path.join(input_dir,i,file_name))[i]\n","            if isinstance(data,TensorDataset):\n","                if evaluate:\n","                    all_input_ids = torch.cat([all_input_ids,data.tensors[0]],dim=0)\n","                    all_attention_masks = torch.cat([all_attention_masks,data.tensors[1]],dim=0)\n","                    all_token_type_ids = torch.cat([all_token_type_ids,data.tensors[2]],dim=0)\n","                    all_cls_index = torch.cat([all_cls_index,data.tensors[4]],dim=0)\n","                    all_p_mask = torch.cat([all_p_mask,data.tensors[5]],dim=0)\n","                else:\n","                    all_input_ids = torch.cat([all_input_ids,data.tensors[0]],dim=0)\n","                    all_attention_masks = torch.cat([all_attention_masks,data.tensors[1]],dim=0)\n","                    all_token_type_ids = torch.cat([all_token_type_ids,data.tensors[2]],dim=0)\n","                    all_start_positions = torch.cat([all_start_positions,data.tensors[3]],dim=0)\n","                    all_end_positions = torch.cat([all_end_positions,data.tensors[4]],dim=0)\n","                    all_cls_index = torch.cat([all_cls_index,data.tensors[5]],dim=0)\n","                    all_p_mask = torch.cat([all_p_mask,data.tensors[6]],dim=0)\n","                    all_is_impossible = torch.cat([all_is_impossible,data.tensors[7]],dim=0)\n","            elif isinstance(data,list):\n","                all_features[i] += data\n","    \n","    if evaluate and \"datasets\" in feat.split(\";\"):\n","        all_example_index = torch.arange(all_input_ids.size(0), dtype=torch.long)\n","        all_features[\"datasets\"] = TensorDataset(all_input_ids, all_attention_masks, all_token_type_ids, all_example_index, all_cls_index, all_p_mask)\n","    elif not evaluate and \"datasets\" in feat.split(\";\"):\n","        all_features[\"datasets\"] = TensorDataset(all_input_ids,all_attention_masks,all_token_type_ids,all_start_positions,all_end_positions,all_cls_index,all_p_mask,all_is_impossible,)\n","\n","\n","    if output_examples:\n","        return all_features['datasets'], all_features['examples'], all_features['features']\n","    else:\n","        return all_features['datasets']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U2u3dk_r6J4P"},"outputs":[],"source":["import gc\n","max_seq_length = 384\n","def load_and_cache_examples(tokenizer, evaluate=False, output_examples= False):\n","    input_dir = \".\"\n","    cached_features_file = os.path.join(\n","        input_dir,\n","        \"cached_{}_{}_{}\".format(\n","            \"dev\" if evaluate else \"train\",\n","            \"xlmr\",\n","            str(max_seq_length),\n","        ),\n","    )\n","    root_dir = os.path.join(cached_features_file+\"_dir\")\n","    features_file = os.path.join(root_dir,'features')\n","    datasets_file = os.path.join(root_dir,'datasets')\n","    examples_file = os.path.join(root_dir,'examples')\n","    if evaluate:\n","        print(\"NO EVAL\")\n","#         examples = processor.get_dev_examples('../input/viquad-v1', 'dev_ViQuAD.json')\n","#         examples = processor.get_dev_examples('../input/merge-dataset', 'merge_dataset_v1_dev.json')\n","    else:\n","#         examples = processor.get_train_examples('../input/viquad-v1', 'train_ViQuAD.json')\n","        examples = processor.get_train_examples('/content/drive/MyDrive/Colab Notebooks/MRC - VLSP/Dataset','train_wiki_total.json')\n","    for i,j in enumerate(range(0, len(examples), 1000)):\n","        sub_examples = examples[j:j+1000]\n","        features, dataset = squad_convert_examples_to_features(\n","                examples=sub_examples,\n","                tokenizer=tokenizer,\n","                max_seq_length=384,\n","                doc_stride=128,\n","                max_query_length=64,\n","                is_training=not evaluate,\n","                return_dataset=\"pt\",\n","                threads=10,\n","            )\n","        if not os.path.exists(os.path.join(features_file)):\n","            os.makedirs(os.path.join(features_file))\n","        if not os.path.exists(os.path.join(datasets_file)):\n","            os.makedirs(os.path.join(datasets_file))\n","        if not os.path.exists(os.path.join(examples_file)):\n","            os.makedirs(os.path.join(examples_file))\n","        print(\"Saving features into cached files %s, %s, %s\", os.path.join(features_file,'features_'+str(i)),os.path.join(datasets_file,'datasets_'+str(i)),os.path.join(examples_file,'examples_'+str(i)))\n","        torch.save({\"features\": features}, os.path.join(features_file,'features_'+str(i)))\n","        torch.save({\"datasets\": dataset}, os.path.join(datasets_file,'datasets_'+str(i)))\n","        torch.save({\"examples\": sub_examples}, os.path.join(examples_file,'examples_'+str(i)))\n","        print(\"Done\")\n","        del features, dataset\n","        gc.collect()\n","    del examples\n","    return read_saved_data(root_dir,evaluate=evaluate,output_examples=output_examples)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J10zdvAa6J4Q"},"outputs":[],"source":["import os\n","train_dataset = load_and_cache_examples(tokenizer, evaluate= False, output_examples = False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EVuI9If66J4Q"},"outputs":[],"source":["def to_list(tensor):\n","    return tensor.detach().cpu().tolist()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DLFh_eN76J4R"},"outputs":[],"source":["import os\n","def evaluate(model, tokenizer, dev_dataset, dev_examples, dev_features):\n","    eval_sampler = SequentialSampler(dev_dataset)\n","    eval_dataloader = DataLoader(dev_dataset, sampler=eval_sampler, batch_size=12)\n","    all_results = []\n","#     start_time = timeit.default_timer()\n","    for batch in tqdm(eval_dataloader, desc=\"Evaluating\"):\n","        model.eval()\n","        batch = tuple(t.to(device) for t in batch)\n","        with torch.no_grad():\n","            inputs = {\n","                \"input_ids\": batch[0],\n","                \"attention_mask\": batch[1],\n","                \"token_type_ids\": batch[2],\n","            }\n","            del inputs[\"token_type_ids\"]\n","            example_indices = batch[3]\n","            outputs = model(**inputs)\n","        for i, example_index in enumerate(example_indices):\n","            eval_feature = dev_features[example_index.item()]\n","            unique_id = int(eval_feature.unique_id)\n","#             for output in outputs:\n","#                 print(output)\n","            output = [to_list(output[i]) for output in outputs]\n","#             output = [to_list(output) for output in outputs]\n","            if len(output) >= 5:\n","                start_logits = output[0]\n","                start_top_index = output[1]\n","                end_logits = output[2]\n","                end_top_index = output[3]\n","                cls_logits = output[4]\n","\n","                result = SquadResult(\n","                    unique_id,\n","                    start_logits,\n","                    end_logits,\n","                    start_top_index=start_top_index,\n","                    end_top_index=end_top_index,\n","                    cls_logits=cls_logits,\n","                )\n","            else:\n","                start_logits, end_logits = output\n","                result = SquadResult(unique_id, start_logits, end_logits)\n","            all_results.append(result)\n","    \n","    output_prediction_file = os.path.join(\"./\", \"predictions_{}.json\".format(\"\"))\n","    output_nbest_file = os.path.join(\"./\", \"nbest_predictions_{}.json\".format(\"\"))\n","    output_null_log_odds_file = os.path.join(\"./\", \"null_odds_{}.json\".format(\"\"))\n","    predictions = compute_predictions_logits(\n","            dev_examples,\n","            dev_features,\n","            all_results,\n","            20,\n","            300,\n","            False,\n","            output_prediction_file,\n","            output_nbest_file,\n","            output_null_log_odds_file,\n","            True,\n","            False,\n","            0.0,\n","            tokenizer,\n","        )\n","    results = squad_evaluate(dev_examples, predictions)\n","    return results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4i5HAFBD6J4R"},"outputs":[],"source":["from torch.utils.tensorboard import SummaryWriter\n","from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n","from transformers import AdamW, get_linear_schedule_with_warmup\n","from tqdm import trange, tqdm\n","device = torch.device('cuda')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZOERItTY6J4R"},"outputs":[],"source":["# for param in model.bert.parameters():\n","#     param.requires_grad = False"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5eV3WagS6J4R","executionInfo":{"status":"ok","timestamp":1641932102007,"user_tz":-420,"elapsed":9276656,"user":{"displayName":"Mạnh Dũng Nguyễn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghv0al56qw_A8F0xE48V5OetG5WUMxf6MGyxK1g4cI=s64","userId":"13942456880411028305"}},"outputId":"845efc6a-3c0c-421e-985e-2ae33ea63be1"},"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Iteration:   7%|▋         | 4999/69102 [54:36<11:37:52,  1.53it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":[" global_step = %s, average loss = %s 5000 1.4721733810633422\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Iteration:  14%|█▍        | 9999/69102 [1:49:09<10:50:31,  1.51it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":[" global_step = %s, average loss = %s 10000 1.3216455758176744\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Iteration:  22%|██▏       | 14999/69102 [2:43:39<9:51:45,  1.52it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":[" global_step = %s, average loss = %s 15000 1.258040886203448\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Iteration:  29%|██▉       | 19999/69102 [3:38:08<9:00:58,  1.51it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":[" global_step = %s, average loss = %s 20000 1.204137418114394\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Iteration:  36%|███▌      | 24999/69102 [4:32:37<8:00:34,  1.53it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":[" global_step = %s, average loss = %s 25000 1.1678154926107078\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Iteration:  43%|████▎     | 29999/69102 [5:27:08<7:09:01,  1.52it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":[" global_step = %s, average loss = %s 30000 1.134150926455545\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Iteration:  51%|█████     | 34999/69102 [6:21:37<6:13:04,  1.52it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":[" global_step = %s, average loss = %s 35000 1.1044443568379219\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Iteration:  58%|█████▊    | 39999/69102 [7:16:06<5:15:43,  1.54it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":[" global_step = %s, average loss = %s 40000 1.0762507041959557\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Iteration:  65%|██████▌   | 44999/69102 [8:10:35<4:23:44,  1.52it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":[" global_step = %s, average loss = %s 45000 1.0525894852775253\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Iteration:  72%|███████▏  | 49999/69102 [9:05:04<3:28:48,  1.52it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":[" global_step = %s, average loss = %s 50000 1.0298563551616295\n"]},{"output_type":"stream","name":"stderr","text":["Iteration:  80%|███████▉  | 54999/69102 [9:59:31<2:35:01,  1.52it/s]"]},{"output_type":"stream","name":"stdout","text":[" global_step = %s, average loss = %s 55000 1.0078649646899578\n"]},{"output_type":"stream","name":"stderr","text":["Iteration:  87%|████████▋ | 59999/69102 [10:53:59<1:38:48,  1.54it/s]"]},{"output_type":"stream","name":"stdout","text":[" global_step = %s, average loss = %s 60000 0.9879128462003854\n"]},{"output_type":"stream","name":"stderr","text":["Iteration:  94%|█████████▍| 64999/69102 [11:48:26<44:36,  1.53it/s]"]},{"output_type":"stream","name":"stdout","text":[" global_step = %s, average loss = %s 65000 0.9689783027216792\n"]},{"output_type":"stream","name":"stderr","text":["Iteration: 100%|██████████| 69102/69102 [12:33:05<00:00,  1.53it/s]\n","Epoch: 100%|██████████| 1/1 [12:33:05<00:00, 45185.61s/it]\n"]},{"output_type":"execute_result","data":{"text/plain":["('/content/drive/MyDrive/Colab Notebooks/MRC - VLSP/Data Preprocessing/final_model_Jan11/tokenizer_config.json',\n"," '/content/drive/MyDrive/Colab Notebooks/MRC - VLSP/Data Preprocessing/final_model_Jan11/special_tokens_map.json',\n"," '/content/drive/MyDrive/Colab Notebooks/MRC - VLSP/Data Preprocessing/final_model_Jan11/sentencepiece.bpe.model',\n"," '/content/drive/MyDrive/Colab Notebooks/MRC - VLSP/Data Preprocessing/final_model_Jan11/added_tokens.json')"]},"metadata":{},"execution_count":15}],"source":["import numpy as np\n","num_epochs = 1\n","tb_writer = SummaryWriter()\n","train_sampler = RandomSampler(train_dataset)\n","train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=4)\n","t_total = len(train_dataloader) // 1 * num_epochs\n","\n","\n","no_decay = [\"bias\", \"LayerNorm.weight\"]\n","\n","optimizer_grouped_parameters = [\n","    {\n","        \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n","        \"weight_decay\": 0,\n","    },\n","    {\"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], \"weight_decay\": 0.0},\n","]\n","optimizer = AdamW(optimizer_grouped_parameters, lr=2e-5, eps = 1e-8)\n","scheduler = get_linear_schedule_with_warmup(\n","    optimizer, num_warmup_steps=814, num_training_steps=t_total\n",")\n","\n","device = torch.device('cuda')\n","\n","model.to(device)\n","\n","global_step = 1\n","epochs_trained = 0\n","steps_trained_in_current_epoch = 0\n","tr_loss, logging_loss = 0.0, 0.0\n","\n","model.zero_grad()\n","train_iterator = trange(\n","    epochs_trained, int(num_epochs), desc=\"Epoch\", disable=-1 not in [-1, 0]\n",")\n","\n","from functools import partial\n","tqdm = partial(tqdm, position=0, leave=True)\n","\n","for _ in train_iterator:\n","    epoch_iterator = tqdm(train_dataloader, desc=\"Iteration\", disable=False)\n","    for step, batch in enumerate(epoch_iterator):\n","        model.train()\n","        batch = tuple(t.to(device) for t in batch)\n","        \n","        inputs = {\n","            \"input_ids\": batch[0],\n","            \"attention_mask\": batch[1],\n","            \"token_type_ids\": batch[2],\n","            \"start_positions\": batch[3],\n","            \"end_positions\": batch[4],\n","        }\n","        del inputs[\"token_type_ids\"]\n","        outputs = model(**inputs)\n","        loss = outputs[0]\n","        loss.backward()\n","        tr_loss += loss.item()\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n","        optimizer.step()\n","        scheduler.step()\n","        model.zero_grad()\n","        global_step += 1\n","\n","        if global_step % 5000 == 0:\n","#             output_dir = os.path.join('./', \"checkpoint-{}\".format(global_step))\n","#             model_to_save = model.module if hasattr(model, \"module\") else model\n","#             model_to_save.save_pretrained(output_dir)\n","#             tokenizer.save_pretrained(output_dir)\n","#             torch.save(optimizer.state_dict(), os.path.join(output_dir, \"optimizer.pt\"))\n","#             torch.save(scheduler.state_dict(), os.path.join(output_dir, \"scheduler.pt\"))\n","            print(\" global_step = %s, average loss = %s\", global_step, tr_loss/global_step)\n","\n","            \n","# output_dir = os.path.join('./', 'final_model')\n","output_dir = os.path.join('/content/drive/MyDrive/Colab Notebooks/MRC - VLSP/Data Preprocessing', 'final_model_Jan11')\n","model_to_save = model.module if hasattr(model, \"module\") else model\n","model_to_save.save_pretrained(output_dir)\n","tokenizer.save_pretrained(output_dir)\n","\n","# print(\" global_step = %s, average loss = %s\", global_step, tr_loss/global_step)\n","\n","# results = evaluate(model, tokenizer, dev_dataset, dev_examples, dev_features)\n","# for key, value in results.items():\n","#     print(key, value)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"422LWRpJ6J4S"},"outputs":[],"source":["# tokenizer_1 = XLMRobertaTokenizer.from_pretrained(\"xlm-roberta-large\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k6Myl0EQ6J4S"},"outputs":[],"source":["# test_examples = processor.get_dev_examples('../input/viquad-v1','test_ViQuAD.json')\n","# test_features, test_dataset = squad_convert_examples_to_features(test_examples, \n","#                                                        tokenizer, \n","#                                                        max_seq_length = 384, \n","#                                                        doc_stride = 128,\n","#                                                        max_query_length = 64,\n","#                                                        is_training = False,\n","#                                                        return_dataset = 'pt',\n","#                                                        threads = 10\n","#                                                        )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b5QBgylV6J4S"},"outputs":[],"source":["# results = evaluate(model, tokenizer_1, test_dataset, test_examples, test_features)\n","# for key, value in results.items():\n","#     print(key, value)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VERhwnKn6J4S"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uPtYd4556J4T"},"outputs":[],"source":[""]}],"metadata":{"accelerator":"GPU","colab":{"background_execution":"on","machine_shape":"hm","name":"fork-of-xlm-r.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"},"widgets":{"application/vnd.jupyter.widget-state+json":{"0cc8c80670294acc8b9afcc8a82a803d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_60a397010afe4fc3bf0d3f4fca6edc88","placeholder":"​","style":"IPY_MODEL_4605009614e74e80adf11955a8a5a0d4","value":" 2.24G/2.24G [00:55&lt;00:00, 38.5MB/s]"}},"1221db8fa2cf48f784b5edaa4bed6b3d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"12c5444db3d249509f599cf11af8815c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6f8199a296ad448f9bf924300a2981b2","max":513,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4cbf89e36b374f2280f8430549515c58","value":513}},"25773199ddf84bf4afd56bc07c0ebf12":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"261ffb66e1724af5aab9082859245d6c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"29287d2cf2cc4403b461f246181b1924":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2b1a652fce3f4c25bf5e794a8d473387":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fe816b79962f44baaf30cde19bce01b8","IPY_MODEL_12c5444db3d249509f599cf11af8815c","IPY_MODEL_2d505f2c00e147cb8c5a8fc25cc849b5"],"layout":"IPY_MODEL_5c33911980704772b2f9e7d839600ffd"}},"2c6e34c6624842118e5f06dfafddb98a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c5f560197c9340f18189cdd8446dd976","IPY_MODEL_6b8af8f84f324663b4613cc311838b6a","IPY_MODEL_bffba7e732014ca388c38970d67e3778"],"layout":"IPY_MODEL_c3deada8b47249c88ff076c365483b77"}},"2d505f2c00e147cb8c5a8fc25cc849b5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_261ffb66e1724af5aab9082859245d6c","placeholder":"​","style":"IPY_MODEL_c28a7865dc494cd5913b4bd2dd0e5199","value":" 513/513 [00:00&lt;00:00, 18.2kB/s]"}},"457c02cb12fb4360965ddad09cf9405f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4605009614e74e80adf11955a8a5a0d4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4cbf89e36b374f2280f8430549515c58":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"524eacf3c00a409b94a3b36f14c7d6d0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5c33911980704772b2f9e7d839600ffd":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"60a397010afe4fc3bf0d3f4fca6edc88":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6b8af8f84f324663b4613cc311838b6a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_25773199ddf84bf4afd56bc07c0ebf12","max":5069051,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cb312f8386564fe08671391f58b88867","value":5069051}},"6f8199a296ad448f9bf924300a2981b2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7bc97c1ecd4c4577a390f6bc853e4c52":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8a485770a5de4b1d9545a2c51538dbf0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8eec272eb3034bbb92d1e3de7a3b4d86":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7bc97c1ecd4c4577a390f6bc853e4c52","max":2244861551,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9c32ab2a275540f989bb810a4cf28f34","value":2244861551}},"9c32ab2a275540f989bb810a4cf28f34":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9f458cb04a104dbba9f672887297c203":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a85ee080d3514854b527d8d16fa0fc49":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bffba7e732014ca388c38970d67e3778":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cc3179ccfcff485dbeeca03836356202","placeholder":"​","style":"IPY_MODEL_8a485770a5de4b1d9545a2c51538dbf0","value":" 5.07M/5.07M [00:00&lt;00:00, 17.3MB/s]"}},"c28a7865dc494cd5913b4bd2dd0e5199":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c3deada8b47249c88ff076c365483b77":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c5f560197c9340f18189cdd8446dd976":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d1c6d1d593ad4ca4a439c72416a4e029","placeholder":"​","style":"IPY_MODEL_1221db8fa2cf48f784b5edaa4bed6b3d","value":"Downloading: 100%"}},"cb312f8386564fe08671391f58b88867":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cc3179ccfcff485dbeeca03836356202":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d1c6d1d593ad4ca4a439c72416a4e029":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e7c1fd7c212b4f76b3277f66d0cebab3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_457c02cb12fb4360965ddad09cf9405f","placeholder":"​","style":"IPY_MODEL_29287d2cf2cc4403b461f246181b1924","value":"Downloading: 100%"}},"f198d8d3a05d4d039608953ca651c203":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e7c1fd7c212b4f76b3277f66d0cebab3","IPY_MODEL_8eec272eb3034bbb92d1e3de7a3b4d86","IPY_MODEL_0cc8c80670294acc8b9afcc8a82a803d"],"layout":"IPY_MODEL_a85ee080d3514854b527d8d16fa0fc49"}},"fe816b79962f44baaf30cde19bce01b8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9f458cb04a104dbba9f672887297c203","placeholder":"​","style":"IPY_MODEL_524eacf3c00a409b94a3b36f14c7d6d0","value":"Downloading: 100%"}}}}},"nbformat":4,"nbformat_minor":0}