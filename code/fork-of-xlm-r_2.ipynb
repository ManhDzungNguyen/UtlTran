{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1641906339133,"user":{"displayName":"Mạnh Dũng Nguyễn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghv0al56qw_A8F0xE48V5OetG5WUMxf6MGyxK1g4cI=s64","userId":"13942456880411028305"},"user_tz":-420},"id":"1icdb3YXPOGC","outputId":"06782fdc-844e-4908-8b2d-5193b42eeef7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Tue Jan 11 13:05:38 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 495.46       Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   35C    P0    29W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20303,"status":"ok","timestamp":1641906365435,"user":{"displayName":"Mạnh Dũng Nguyễn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghv0al56qw_A8F0xE48V5OetG5WUMxf6MGyxK1g4cI=s64","userId":"13942456880411028305"},"user_tz":-420},"id":"GPRaAjIIPPet","outputId":"ad1bb60b-f3ab-4c44-9d3d-6c18df9b1dfa"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":107192,"status":"ok","timestamp":1641906477431,"user":{"displayName":"Mạnh Dũng Nguyễn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghv0al56qw_A8F0xE48V5OetG5WUMxf6MGyxK1g4cI=s64","userId":"13942456880411028305"},"user_tz":-420},"id":"DW9g4G-wOw0x","outputId":"3cb88a5d-c68c-4cf6-b117-d20adf543b1d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting transformers==3.5.1\n","  Downloading transformers-3.5.1-py3-none-any.whl (1.3 MB)\n","\u001b[?25l\r\u001b[K     |▎                               | 10 kB 42.7 MB/s eta 0:00:01\r\u001b[K     |▌                               | 20 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |▊                               | 30 kB 20.6 MB/s eta 0:00:01\r\u001b[K     |█                               | 40 kB 17.5 MB/s eta 0:00:01\r\u001b[K     |█▎                              | 51 kB 16.8 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 61 kB 15.6 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 71 kB 15.6 MB/s eta 0:00:01\r\u001b[K     |██                              | 81 kB 17.3 MB/s eta 0:00:01\r\u001b[K     |██▎                             | 92 kB 15.4 MB/s eta 0:00:01\r\u001b[K     |██▌                             | 102 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 112 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |███                             | 122 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 133 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 143 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 153 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |████                            | 163 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |████▎                           | 174 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |████▌                           | 184 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 194 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |█████                           | 204 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 215 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 225 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 235 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |██████                          | 245 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 256 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 266 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 276 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |███████                         | 286 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 296 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 307 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 317 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |████████                        | 327 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 337 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 348 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 358 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 368 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 378 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 389 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 399 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 409 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 419 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 430 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 440 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 450 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 460 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 471 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 481 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 491 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 501 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 512 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 522 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 532 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 542 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 552 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 563 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 573 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 583 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 593 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 604 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 614 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 624 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 634 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 645 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 655 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 665 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 675 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 686 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 696 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 706 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 716 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 727 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 737 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 747 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 757 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 768 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 778 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 788 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 798 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 808 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 819 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 829 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 839 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 849 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 860 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 870 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 880 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 890 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 901 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 911 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 921 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 931 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 942 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 952 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 962 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 972 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 983 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 993 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 1.0 MB 14.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.0 MB 14.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 1.0 MB 14.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 1.0 MB 14.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 1.0 MB 14.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.1 MB 14.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 1.1 MB 14.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 1.1 MB 14.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.1 MB 14.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.1 MB 14.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 1.1 MB 14.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.1 MB 14.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 1.1 MB 14.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.1 MB 14.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 1.1 MB 14.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 1.2 MB 14.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 1.2 MB 14.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.2 MB 14.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 1.2 MB 14.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.2 MB 14.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.2 MB 14.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.2 MB 14.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.2 MB 14.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.2 MB 14.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.2 MB 14.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.3 MB 14.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.3 MB 14.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.3 MB 14.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.3 MB 14.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.3 MB 14.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.3 MB 14.0 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.5.1) (3.4.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.5.1) (21.3)\n","Collecting tokenizers==0.9.3\n","  Downloading tokenizers-0.9.3-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n","\u001b[K     |████████████████████████████████| 2.9 MB 81.9 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.5.1) (2019.12.20)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 90.7 MB/s \n","\u001b[?25hCollecting sentencepiece==0.1.91\n","  Downloading sentencepiece-0.1.91-cp37-cp37m-manylinux1_x86_64.whl (1.1 MB)\n","\u001b[K     |████████████████████████████████| 1.1 MB 84.2 MB/s \n","\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from transformers==3.5.1) (3.17.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3.5.1) (4.62.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3.5.1) (2.23.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3.5.1) (1.19.5)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.5.1) (3.0.6)\n","Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf->transformers==3.5.1) (1.15.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.5.1) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.5.1) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.5.1) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.5.1) (3.0.4)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.5.1) (1.1.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.5.1) (7.1.2)\n","Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n","Successfully installed sacremoses-0.0.47 sentencepiece-0.1.91 tokenizers-0.9.3 transformers-3.5.1\n","Collecting torch==1.4.0\n","  Downloading torch-1.4.0-cp37-cp37m-manylinux1_x86_64.whl (753.4 MB)\n","\u001b[K     |████████████████████████████████| 753.4 MB 6.3 kB/s \n","\u001b[?25hInstalling collected packages: torch\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.10.0+cu111\n","    Uninstalling torch-1.10.0+cu111:\n","      Successfully uninstalled torch-1.10.0+cu111\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchvision 0.11.1+cu111 requires torch==1.10.0, but you have torch 1.4.0 which is incompatible.\n","torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.4.0 which is incompatible.\n","torchaudio 0.10.0+cu111 requires torch==1.10.0, but you have torch 1.4.0 which is incompatible.\u001b[0m\n","Successfully installed torch-1.4.0\n"]}],"source":["#version modifed training less RAM + trivia dataset\n","!pip install transformers==3.5.1\n","!pip install torch==1.4.0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rs1x7oYrOw00"},"outputs":[],"source":["from transformers import BertTokenizer, BertForPreTraining, BertForQuestionAnswering, BertModel, BertConfig\n","from transformers import XLMRobertaForQuestionAnswering, XLMRobertaTokenizer, XLMRobertaConfig\n","import torch\n","import torch.nn as nn\n","from transformers.data.metrics.squad_metrics import compute_predictions_log_probs, compute_predictions_logits, squad_evaluate\n","from transformers.data.processors.squad import SquadResult, SquadV1Processor, SquadV2Processor"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LzENU5sGOw01"},"outputs":[],"source":["# class mBert(nn.Module):\n","#     def __init__(self):\n","#         super(mBert, self).__init__()\n","#         self.bert_block = BertModel.from_pretrained(\"bert-base-multilingual-cased\")\n","#         self.question = nn.Linear(768, 2, bias=True)\n","#     def forward(self, inputs):\n","#         pooled_output, sequence_output = self.bert_block(inputs)\n","#         return self.question(sequence_output)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":188,"referenced_widgets":["0abbb8f587ec492eb449c7ee3cb6d78b","aa6e52fac9b6404cac2e933693988905","43c785572b454a20a720889235f16b56","76c3fc827e824114a646f2634af0c8ad","0f97382c09694ef4bf0599cef4562e38","b6d3eec335654e489bbd9217890f88c2","5581bab7dfef4107bf878a271a11da07","6d928868abcc48558fc87b5fd8924fa6","f0cd3b239a29469b9b50fbcc3f9a95b5","1a05d62323d74f329d6fce98715e4097","dac6339054af4363988f231147ea575c","3c6647b51f1741da850af7a20605bb62","6f8c27fe0a87435c86b5637b2b42d909","4837cacf57724760999a89a0365bca6e","edffec3f92e94ca3a81ea78faa081a1f","e65e44e3c9144c028cc3042d897be393","5e852e9a8ac34dabb83a030755617534","f4057157417c41f6acbc8186b4de8821","afee3108efd74ba19242e6e32fac9a08","7fbf249791754b0d9ad9c6e27e7336c0","09a2c37c4ace49e69aa804aba2eea84e","c1e6920fa9cd402aacb99b7586fefe46"]},"executionInfo":{"elapsed":51371,"status":"ok","timestamp":1641906574044,"user":{"displayName":"Mạnh Dũng Nguyễn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghv0al56qw_A8F0xE48V5OetG5WUMxf6MGyxK1g4cI=s64","userId":"13942456880411028305"},"user_tz":-420},"id":"mbfgK2wbOw01","outputId":"7482a49d-2584-4cbe-b971-8ee3d6ac6563"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0abbb8f587ec492eb449c7ee3cb6d78b","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/513 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3c6647b51f1741da850af7a20605bb62","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/2.24G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at xlm-roberta-large were not used when initializing XLMRobertaForQuestionAnswering: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n","- This IS expected if you are initializing XLMRobertaForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLMRobertaForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of XLMRobertaForQuestionAnswering were not initialized from the model checkpoint at xlm-roberta-large and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["# model = XLMRobertaForQuestionAnswering.from_pretrained('../input/ckpt-xlmr-xquad-pretrain/final_model')\n","model = XLMRobertaForQuestionAnswering.from_pretrained('xlm-roberta-large')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["d0123ac550a44d21a8d4c2e429ed38e3","29d746c6a60249528a971d36db2f383c","77944ceee3734a4fb9a796c0622c99dc","dbf4751f44f74bf0a047610d981e4ca0","998b0376d06a42919b09aebeb68f23e5","bff7196efaac474d8e3e45c25b07788f","c2a3f5aaa86f44bbb28550950c4a4dcc","2ca1a0e9a05548cba4e498112203e0bb","ff9014db204f4fcb9a5af0072bea1e47","89844ac41a5b4447b5aefe02eb7823d5","1723e237e92742eb988cf1c8d549b5bb"]},"executionInfo":{"elapsed":2378,"status":"ok","timestamp":1641906576415,"user":{"displayName":"Mạnh Dũng Nguyễn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghv0al56qw_A8F0xE48V5OetG5WUMxf6MGyxK1g4cI=s64","userId":"13942456880411028305"},"user_tz":-420},"id":"3f09cca3Ow02","outputId":"c8e7e24d-51df-46ce-c3e2-b71bd7bc7255"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d0123ac550a44d21a8d4c2e429ed38e3","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["# model = mBert()\n","tokenizer = XLMRobertaTokenizer.from_pretrained(\"xlm-roberta-large\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rX95s2Y4Ow02"},"outputs":[],"source":["# !mkdir dataset \\\n","# && cd dataset \\\n","# && wget https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v1.1.json \\\n","# && wget https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v1.1.json"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FPC1k-DdOw03"},"outputs":[],"source":["processor = SquadV1Processor()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c4ptpSGqOw04"},"outputs":[],"source":["# train_examples = processor.get_train_examples('../input/trivia-full-filted','train_wiki_total.json')\n","# dev_examples = processor.get_dev_examples('../input/viquad-v1','dev_ViQuAD.json')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5ZpeGZ79Ow04"},"outputs":[],"source":["from transformers.data.processors.squad import squad_convert_examples_to_features"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VE2G_mvxOw05"},"outputs":[],"source":["def read_saved_data(input_dir,evaluate=False,output_examples=False):\n","    from torch.utils.data import TensorDataset\n","\n","    if output_examples:\n","        feat=\"features;datasets;examples\"\n","    else:\n","        feat=\"datasets\"\n","\n","    all_features = {\"features\":[],\"examples\":[],\"datasets\":[]}\n","    all_input_ids = torch.tensor([], dtype=torch.long)\n","    all_attention_masks = torch.tensor([], dtype=torch.long)\n","    all_token_type_ids = torch.tensor([], dtype=torch.long)\n","    all_cls_index = torch.tensor([], dtype=torch.long)\n","    all_p_mask = torch.tensor([], dtype=torch.float)\n","    all_is_impossible = torch.tensor([], dtype=torch.float)\n","    all_start_positions = torch.tensor([], dtype=torch.long)\n","    all_end_positions = torch.tensor([], dtype=torch.long)\n","\n","    for i in feat.split(\";\"):\n","        for file_name in os.listdir(os.path.join(input_dir,i)):\n","            data = torch.load(os.path.join(input_dir,i,file_name))[i]\n","            if isinstance(data,TensorDataset):\n","                if evaluate:\n","                    all_input_ids = torch.cat([all_input_ids,data.tensors[0]],dim=0)\n","                    all_attention_masks = torch.cat([all_attention_masks,data.tensors[1]],dim=0)\n","                    all_token_type_ids = torch.cat([all_token_type_ids,data.tensors[2]],dim=0)\n","                    all_cls_index = torch.cat([all_cls_index,data.tensors[4]],dim=0)\n","                    all_p_mask = torch.cat([all_p_mask,data.tensors[5]],dim=0)\n","                else:\n","                    all_input_ids = torch.cat([all_input_ids,data.tensors[0]],dim=0)\n","                    all_attention_masks = torch.cat([all_attention_masks,data.tensors[1]],dim=0)\n","                    all_token_type_ids = torch.cat([all_token_type_ids,data.tensors[2]],dim=0)\n","                    all_start_positions = torch.cat([all_start_positions,data.tensors[3]],dim=0)\n","                    all_end_positions = torch.cat([all_end_positions,data.tensors[4]],dim=0)\n","                    all_cls_index = torch.cat([all_cls_index,data.tensors[5]],dim=0)\n","                    all_p_mask = torch.cat([all_p_mask,data.tensors[6]],dim=0)\n","                    all_is_impossible = torch.cat([all_is_impossible,data.tensors[7]],dim=0)\n","            elif isinstance(data,list):\n","                all_features[i] += data\n","    \n","    if evaluate and \"datasets\" in feat.split(\";\"):\n","        all_example_index = torch.arange(all_input_ids.size(0), dtype=torch.long)\n","        all_features[\"datasets\"] = TensorDataset(all_input_ids, all_attention_masks, all_token_type_ids, all_example_index, all_cls_index, all_p_mask)\n","    elif not evaluate and \"datasets\" in feat.split(\";\"):\n","        all_features[\"datasets\"] = TensorDataset(all_input_ids,all_attention_masks,all_token_type_ids,all_start_positions,all_end_positions,all_cls_index,all_p_mask,all_is_impossible,)\n","\n","\n","    if output_examples:\n","        return all_features['datasets'], all_features['examples'], all_features['features']\n","    else:\n","        return all_features['datasets']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pjSvmX1jOw06"},"outputs":[],"source":["import gc\n","max_seq_length = 384\n","def load_and_cache_examples(tokenizer, evaluate=False, output_examples= False):\n","    input_dir = \".\"\n","    cached_features_file = os.path.join(\n","        input_dir,\n","        \"cached_{}_{}_{}\".format(\n","            \"dev\" if evaluate else \"train\",\n","            \"xlmr\",\n","            str(max_seq_length),\n","        ),\n","    )\n","    root_dir = os.path.join(cached_features_file+\"_dir\")\n","    features_file = os.path.join(root_dir,'features')\n","    datasets_file = os.path.join(root_dir,'datasets')\n","    examples_file = os.path.join(root_dir,'examples')\n","    if evaluate:\n","        print(\"NO EVAL\")\n","#         examples = processor.get_dev_examples('../input/viquad-v1', 'dev_ViQuAD.json')\n","#         examples = processor.get_dev_examples('../input/merge-dataset', 'merge_dataset_v1_dev.json')\n","    else:\n","#         examples = processor.get_train_examples('../input/viquad-v1', 'train_ViQuAD.json')\n","        examples = processor.get_train_examples('/content/drive/MyDrive/Colab Notebooks/MRC - VLSP/Dataset','train_newqa_total.json')\n","    for i,j in enumerate(range(0, len(examples), 20000)):\n","        sub_examples = examples[j:j+20000]\n","        features, dataset = squad_convert_examples_to_features(\n","                examples=sub_examples,\n","                tokenizer=tokenizer,\n","                max_seq_length=384,\n","                doc_stride=128,\n","                max_query_length=64,\n","                is_training=not evaluate,\n","                return_dataset=\"pt\",\n","                threads=10,\n","            )\n","        if not os.path.exists(os.path.join(features_file)):\n","            os.makedirs(os.path.join(features_file))\n","        if not os.path.exists(os.path.join(datasets_file)):\n","            os.makedirs(os.path.join(datasets_file))\n","        if not os.path.exists(os.path.join(examples_file)):\n","            os.makedirs(os.path.join(examples_file))\n","        print(\"Saving features into cached files %s, %s, %s\", os.path.join(features_file,'features_'+str(i)),os.path.join(datasets_file,'datasets_'+str(i)),os.path.join(examples_file,'examples_'+str(i)))\n","        torch.save({\"features\": features}, os.path.join(features_file,'features_'+str(i)))\n","        torch.save({\"datasets\": dataset}, os.path.join(datasets_file,'datasets_'+str(i)))\n","        torch.save({\"examples\": sub_examples}, os.path.join(examples_file,'examples_'+str(i)))\n","        print(\"Done\")\n","        del features, dataset\n","        gc.collect()\n","    del examples\n","    return read_saved_data(root_dir,evaluate=evaluate,output_examples=output_examples)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":642127,"status":"ok","timestamp":1641907281614,"user":{"displayName":"Mạnh Dũng Nguyễn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghv0al56qw_A8F0xE48V5OetG5WUMxf6MGyxK1g4cI=s64","userId":"13942456880411028305"},"user_tz":-420},"id":"60NLb00LOw07","outputId":"db237ca8-0629-45c3-9b3d-5189d5e91797"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 40805/40805 [00:50<00:00, 801.43it/s]\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:1423: FutureWarning: The `max_len` attribute has been deprecated and will be removed in a future version, use `model_max_length` instead.\n","  FutureWarning,\n","convert squad examples to features:   0%|          | 0/20000 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:1423: FutureWarning: The `max_len` attribute has been deprecated and will be removed in a future version, use `model_max_length` instead.\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:1423: FutureWarning: The `max_len` attribute has been deprecated and will be removed in a future version, use `model_max_length` instead.\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:1423: FutureWarning: The `max_len` attribute has been deprecated and will be removed in a future version, use `model_max_length` instead.\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:1423: FutureWarning: The `max_len` attribute has been deprecated and will be removed in a future version, use `model_max_length` instead.\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:1423: FutureWarning: The `max_len` attribute has been deprecated and will be removed in a future version, use `model_max_length` instead.\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:1423: FutureWarning: The `max_len` attribute has been deprecated and will be removed in a future version, use `model_max_length` instead.\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:1423: FutureWarning: The `max_len` attribute has been deprecated and will be removed in a future version, use `model_max_length` instead.\n","  FutureWarning,\n","convert squad examples to features: 100%|██████████| 20000/20000 [02:28<00:00, 134.92it/s]\n","add example index and unique id: 100%|██████████| 20000/20000 [00:00<00:00, 352695.18it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Saving features into cached files %s, %s, %s ./cached_train_xlmr_384_dir/features/features_0 ./cached_train_xlmr_384_dir/datasets/datasets_0 ./cached_train_xlmr_384_dir/examples/examples_0\n","Done\n"]},{"name":"stderr","output_type":"stream","text":["\rconvert squad examples to features:   0%|          | 0/20000 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:1423: FutureWarning: The `max_len` attribute has been deprecated and will be removed in a future version, use `model_max_length` instead.\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:1423: FutureWarning: The `max_len` attribute has been deprecated and will be removed in a future version, use `model_max_length` instead.\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:1423: FutureWarning: The `max_len` attribute has been deprecated and will be removed in a future version, use `model_max_length` instead.\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:1423: FutureWarning: The `max_len` attribute has been deprecated and will be removed in a future version, use `model_max_length` instead.\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:1423: FutureWarning: The `max_len` attribute has been deprecated and will be removed in a future version, use `model_max_length` instead.\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:1423: FutureWarning: The `max_len` attribute has been deprecated and will be removed in a future version, use `model_max_length` instead.\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:1423: FutureWarning: The `max_len` attribute has been deprecated and will be removed in a future version, use `model_max_length` instead.\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:1423: FutureWarning: The `max_len` attribute has been deprecated and will be removed in a future version, use `model_max_length` instead.\n","  FutureWarning,\n","convert squad examples to features: 100%|██████████| 20000/20000 [02:25<00:00, 137.19it/s]\n","add example index and unique id: 100%|██████████| 20000/20000 [00:00<00:00, 244193.49it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Saving features into cached files %s, %s, %s ./cached_train_xlmr_384_dir/features/features_1 ./cached_train_xlmr_384_dir/datasets/datasets_1 ./cached_train_xlmr_384_dir/examples/examples_1\n","Done\n"]},{"name":"stderr","output_type":"stream","text":["\rconvert squad examples to features:   0%|          | 0/805 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:1423: FutureWarning: The `max_len` attribute has been deprecated and will be removed in a future version, use `model_max_length` instead.\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:1423: FutureWarning: The `max_len` attribute has been deprecated and will be removed in a future version, use `model_max_length` instead.\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:1423: FutureWarning: The `max_len` attribute has been deprecated and will be removed in a future version, use `model_max_length` instead.\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:1423: FutureWarning: The `max_len` attribute has been deprecated and will be removed in a future version, use `model_max_length` instead.\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:1423: FutureWarning: The `max_len` attribute has been deprecated and will be removed in a future version, use `model_max_length` instead.\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:1423: FutureWarning: The `max_len` attribute has been deprecated and will be removed in a future version, use `model_max_length` instead.\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:1423: FutureWarning: The `max_len` attribute has been deprecated and will be removed in a future version, use `model_max_length` instead.\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:1423: FutureWarning: The `max_len` attribute has been deprecated and will be removed in a future version, use `model_max_length` instead.\n","  FutureWarning,\n","convert squad examples to features: 100%|██████████| 805/805 [00:06<00:00, 122.83it/s]\n","add example index and unique id: 100%|██████████| 805/805 [00:00<00:00, 294703.21it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Saving features into cached files %s, %s, %s ./cached_train_xlmr_384_dir/features/features_2 ./cached_train_xlmr_384_dir/datasets/datasets_2 ./cached_train_xlmr_384_dir/examples/examples_2\n","Done\n"]}],"source":["import os\n","train_dataset = load_and_cache_examples(tokenizer, evaluate= False, output_examples = False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ik4r_ambOw07"},"outputs":[],"source":["def to_list(tensor):\n","    return tensor.detach().cpu().tolist()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tyc2jAblOw07"},"outputs":[],"source":["import os\n","def evaluate(model, tokenizer, dev_dataset, dev_examples, dev_features):\n","    eval_sampler = SequentialSampler(dev_dataset)\n","    eval_dataloader = DataLoader(dev_dataset, sampler=eval_sampler, batch_size=12)\n","    all_results = []\n","#     start_time = timeit.default_timer()\n","    for batch in tqdm(eval_dataloader, desc=\"Evaluating\"):\n","        model.eval()\n","        batch = tuple(t.to(device) for t in batch)\n","        with torch.no_grad():\n","            inputs = {\n","                \"input_ids\": batch[0],\n","                \"attention_mask\": batch[1],\n","                \"token_type_ids\": batch[2],\n","            }\n","            del inputs[\"token_type_ids\"]\n","            example_indices = batch[3]\n","            outputs = model(**inputs)\n","        for i, example_index in enumerate(example_indices):\n","            eval_feature = dev_features[example_index.item()]\n","            unique_id = int(eval_feature.unique_id)\n","#             for output in outputs:\n","#                 print(output)\n","            output = [to_list(output[i]) for output in outputs]\n","#             output = [to_list(output) for output in outputs]\n","            if len(output) >= 5:\n","                start_logits = output[0]\n","                start_top_index = output[1]\n","                end_logits = output[2]\n","                end_top_index = output[3]\n","                cls_logits = output[4]\n","\n","                result = SquadResult(\n","                    unique_id,\n","                    start_logits,\n","                    end_logits,\n","                    start_top_index=start_top_index,\n","                    end_top_index=end_top_index,\n","                    cls_logits=cls_logits,\n","                )\n","            else:\n","                start_logits, end_logits = output\n","                result = SquadResult(unique_id, start_logits, end_logits)\n","            all_results.append(result)\n","    \n","    output_prediction_file = os.path.join(\"./\", \"predictions_{}.json\".format(\"\"))\n","    output_nbest_file = os.path.join(\"./\", \"nbest_predictions_{}.json\".format(\"\"))\n","    output_null_log_odds_file = os.path.join(\"./\", \"null_odds_{}.json\".format(\"\"))\n","    predictions = compute_predictions_logits(\n","            dev_examples,\n","            dev_features,\n","            all_results,\n","            20,\n","            300,\n","            False,\n","            output_prediction_file,\n","            output_nbest_file,\n","            output_null_log_odds_file,\n","            True,\n","            False,\n","            0.0,\n","            tokenizer,\n","        )\n","    results = squad_evaluate(dev_examples, predictions)\n","    return results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bn_upq6_Ow08"},"outputs":[],"source":["from torch.utils.tensorboard import SummaryWriter\n","from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n","from transformers import AdamW, get_linear_schedule_with_warmup\n","from tqdm import trange, tqdm\n","device = torch.device('cuda')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hpUdsryXOw08"},"outputs":[],"source":["# for param in model.bert.parameters():\n","#     param.requires_grad = False"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7H3iY-yXOw08","executionInfo":{"status":"ok","timestamp":1641928610199,"user_tz":-420,"elapsed":5786091,"user":{"displayName":"Mạnh Dũng Nguyễn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghv0al56qw_A8F0xE48V5OetG5WUMxf6MGyxK1g4cI=s64","userId":"13942456880411028305"}},"outputId":"48866f1d-11d1-45ff-e894-bc6886071514"},"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Iteration:  15%|█▍        | 4999/33388 [53:11<5:01:49,  1.57it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":[" global_step = %s, average loss = %s 5000 1.8118483253791928\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Iteration:  30%|██▉       | 9999/33388 [1:46:24<4:08:36,  1.57it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":[" global_step = %s, average loss = %s 10000 1.5698463851884008\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Iteration:  45%|████▍     | 14999/33388 [2:39:37<3:15:44,  1.57it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":[" global_step = %s, average loss = %s 15000 1.4658125299381712\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Iteration:  60%|█████▉    | 19999/33388 [3:32:48<2:22:23,  1.57it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":[" global_step = %s, average loss = %s 20000 1.3848523918325082\n"]},{"output_type":"stream","name":"stderr","text":["Iteration:  75%|███████▍  | 24999/33388 [4:25:57<1:29:10,  1.57it/s]"]},{"output_type":"stream","name":"stdout","text":[" global_step = %s, average loss = %s 25000 1.3209817822427303\n"]},{"output_type":"stream","name":"stderr","text":["Iteration:  90%|████████▉ | 29999/33388 [5:19:08<36:05,  1.57it/s]"]},{"output_type":"stream","name":"stdout","text":[" global_step = %s, average loss = %s 30000 1.2676217542879593\n"]},{"output_type":"stream","name":"stderr","text":["Iteration: 100%|██████████| 33388/33388 [5:55:10<00:00,  1.57it/s]\n","Epoch: 100%|██████████| 1/1 [5:55:10<00:00, 21310.09s/it]\n"]},{"output_type":"execute_result","data":{"text/plain":["('/content/drive/MyDrive/Colab Notebooks/MRC - VLSP/Data Preprocessing/final_model_newqa_Jan11/tokenizer_config.json',\n"," '/content/drive/MyDrive/Colab Notebooks/MRC - VLSP/Data Preprocessing/final_model_newqa_Jan11/special_tokens_map.json',\n"," '/content/drive/MyDrive/Colab Notebooks/MRC - VLSP/Data Preprocessing/final_model_newqa_Jan11/sentencepiece.bpe.model',\n"," '/content/drive/MyDrive/Colab Notebooks/MRC - VLSP/Data Preprocessing/final_model_newqa_Jan11/added_tokens.json')"]},"metadata":{},"execution_count":15}],"source":["import numpy as np\n","num_epochs = 1\n","tb_writer = SummaryWriter()\n","train_sampler = RandomSampler(train_dataset)\n","train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=4)\n","t_total = len(train_dataloader) // 1 * num_epochs\n","\n","\n","no_decay = [\"bias\", \"LayerNorm.weight\"]\n","\n","optimizer_grouped_parameters = [\n","    {\n","        \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n","        \"weight_decay\": 0,\n","    },\n","    {\"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], \"weight_decay\": 0.0},\n","]\n","optimizer = AdamW(optimizer_grouped_parameters, lr=2e-5, eps = 1e-8)\n","scheduler = get_linear_schedule_with_warmup(\n","    optimizer, num_warmup_steps=814, num_training_steps=t_total\n",")\n","\n","device = torch.device('cuda')\n","\n","model.to(device)\n","\n","global_step = 1\n","epochs_trained = 0\n","steps_trained_in_current_epoch = 0\n","tr_loss, logging_loss = 0.0, 0.0\n","\n","model.zero_grad()\n","train_iterator = trange(\n","    epochs_trained, int(num_epochs), desc=\"Epoch\", disable=-1 not in [-1, 0]\n",")\n","\n","from functools import partial\n","tqdm = partial(tqdm, position=0, leave=True)\n","\n","for _ in train_iterator:\n","    epoch_iterator = tqdm(train_dataloader, desc=\"Iteration\", disable=False)\n","    for step, batch in enumerate(epoch_iterator):\n","        model.train()\n","        batch = tuple(t.to(device) for t in batch)\n","        \n","        inputs = {\n","            \"input_ids\": batch[0],\n","            \"attention_mask\": batch[1],\n","            \"token_type_ids\": batch[2],\n","            \"start_positions\": batch[3],\n","            \"end_positions\": batch[4],\n","        }\n","        del inputs[\"token_type_ids\"]\n","        outputs = model(**inputs)\n","        loss = outputs[0]\n","        loss.backward()\n","        tr_loss += loss.item()\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n","        optimizer.step()\n","        scheduler.step()\n","        model.zero_grad()\n","        global_step += 1\n","\n","        if global_step % 5000 == 0:\n","#             output_dir = os.path.join('./', \"checkpoint-{}\".format(global_step))\n","#             model_to_save = model.module if hasattr(model, \"module\") else model\n","#             model_to_save.save_pretrained(output_dir)\n","#             tokenizer.save_pretrained(output_dir)\n","#             torch.save(optimizer.state_dict(), os.path.join(output_dir, \"optimizer.pt\"))\n","#             torch.save(scheduler.state_dict(), os.path.join(output_dir, \"scheduler.pt\"))\n","            print(\" global_step = %s, average loss = %s\", global_step, tr_loss/global_step)\n","\n","            \n","output_dir = os.path.join('/content/drive/MyDrive/Colab Notebooks/MRC - VLSP/Data Preprocessing', 'final_model_newqa_Jan11')\n","model_to_save = model.module if hasattr(model, \"module\") else model\n","model_to_save.save_pretrained(output_dir)\n","tokenizer.save_pretrained(output_dir)\n","\n","# print(\" global_step = %s, average loss = %s\", global_step, tr_loss/global_step)\n","\n","# results = evaluate(model, tokenizer, dev_dataset, dev_examples, dev_features)\n","# for key, value in results.items():\n","#     print(key, value)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qZcfiFdmOw09"},"outputs":[],"source":["# tokenizer_1 = XLMRobertaTokenizer.from_pretrained(\"xlm-roberta-large\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c0goOUX9Ow09"},"outputs":[],"source":["# test_examples = processor.get_dev_examples('../input/viquad-v1','test_ViQuAD.json')\n","# test_features, test_dataset = squad_convert_examples_to_features(test_examples, \n","#                                                        tokenizer, \n","#                                                        max_seq_length = 384, \n","#                                                        doc_stride = 128,\n","#                                                        max_query_length = 64,\n","#                                                        is_training = False,\n","#                                                        return_dataset = 'pt',\n","#                                                        threads = 10\n","#                                                        )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QNG8KZnWOw09"},"outputs":[],"source":["# results = evaluate(model, tokenizer_1, test_dataset, test_examples, test_features)\n","# for key, value in results.items():\n","#     print(key, value)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QlRnjc1NOw0-"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kv56Nag_Ow0-"},"outputs":[],"source":[""]}],"metadata":{"accelerator":"GPU","colab":{"background_execution":"on","collapsed_sections":[],"machine_shape":"hm","name":"fork-of-xlm-r_2.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"},"widgets":{"application/vnd.jupyter.widget-state+json":{"09a2c37c4ace49e69aa804aba2eea84e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0abbb8f587ec492eb449c7ee3cb6d78b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_aa6e52fac9b6404cac2e933693988905","IPY_MODEL_43c785572b454a20a720889235f16b56","IPY_MODEL_76c3fc827e824114a646f2634af0c8ad"],"layout":"IPY_MODEL_0f97382c09694ef4bf0599cef4562e38"}},"0f97382c09694ef4bf0599cef4562e38":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1723e237e92742eb988cf1c8d549b5bb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1a05d62323d74f329d6fce98715e4097":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"29d746c6a60249528a971d36db2f383c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bff7196efaac474d8e3e45c25b07788f","placeholder":"​","style":"IPY_MODEL_c2a3f5aaa86f44bbb28550950c4a4dcc","value":"Downloading: 100%"}},"2ca1a0e9a05548cba4e498112203e0bb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3c6647b51f1741da850af7a20605bb62":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6f8c27fe0a87435c86b5637b2b42d909","IPY_MODEL_4837cacf57724760999a89a0365bca6e","IPY_MODEL_edffec3f92e94ca3a81ea78faa081a1f"],"layout":"IPY_MODEL_e65e44e3c9144c028cc3042d897be393"}},"43c785572b454a20a720889235f16b56":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6d928868abcc48558fc87b5fd8924fa6","max":513,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f0cd3b239a29469b9b50fbcc3f9a95b5","value":513}},"4837cacf57724760999a89a0365bca6e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_afee3108efd74ba19242e6e32fac9a08","max":2244861551,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7fbf249791754b0d9ad9c6e27e7336c0","value":2244861551}},"5581bab7dfef4107bf878a271a11da07":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5e852e9a8ac34dabb83a030755617534":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6d928868abcc48558fc87b5fd8924fa6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6f8c27fe0a87435c86b5637b2b42d909":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5e852e9a8ac34dabb83a030755617534","placeholder":"​","style":"IPY_MODEL_f4057157417c41f6acbc8186b4de8821","value":"Downloading: 100%"}},"76c3fc827e824114a646f2634af0c8ad":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1a05d62323d74f329d6fce98715e4097","placeholder":"​","style":"IPY_MODEL_dac6339054af4363988f231147ea575c","value":" 513/513 [00:00&lt;00:00, 23.7kB/s]"}},"77944ceee3734a4fb9a796c0622c99dc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2ca1a0e9a05548cba4e498112203e0bb","max":5069051,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ff9014db204f4fcb9a5af0072bea1e47","value":5069051}},"7fbf249791754b0d9ad9c6e27e7336c0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"89844ac41a5b4447b5aefe02eb7823d5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"998b0376d06a42919b09aebeb68f23e5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aa6e52fac9b6404cac2e933693988905":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b6d3eec335654e489bbd9217890f88c2","placeholder":"​","style":"IPY_MODEL_5581bab7dfef4107bf878a271a11da07","value":"Downloading: 100%"}},"afee3108efd74ba19242e6e32fac9a08":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b6d3eec335654e489bbd9217890f88c2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bff7196efaac474d8e3e45c25b07788f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c1e6920fa9cd402aacb99b7586fefe46":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c2a3f5aaa86f44bbb28550950c4a4dcc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d0123ac550a44d21a8d4c2e429ed38e3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_29d746c6a60249528a971d36db2f383c","IPY_MODEL_77944ceee3734a4fb9a796c0622c99dc","IPY_MODEL_dbf4751f44f74bf0a047610d981e4ca0"],"layout":"IPY_MODEL_998b0376d06a42919b09aebeb68f23e5"}},"dac6339054af4363988f231147ea575c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dbf4751f44f74bf0a047610d981e4ca0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_89844ac41a5b4447b5aefe02eb7823d5","placeholder":"​","style":"IPY_MODEL_1723e237e92742eb988cf1c8d549b5bb","value":" 5.07M/5.07M [00:00&lt;00:00, 7.05MB/s]"}},"e65e44e3c9144c028cc3042d897be393":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"edffec3f92e94ca3a81ea78faa081a1f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_09a2c37c4ace49e69aa804aba2eea84e","placeholder":"​","style":"IPY_MODEL_c1e6920fa9cd402aacb99b7586fefe46","value":" 2.24G/2.24G [00:37&lt;00:00, 64.4MB/s]"}},"f0cd3b239a29469b9b50fbcc3f9a95b5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f4057157417c41f6acbc8186b4de8821":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ff9014db204f4fcb9a5af0072bea1e47":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}}}}},"nbformat":4,"nbformat_minor":0}