{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":39582,"status":"ok","timestamp":1655621294720,"user":{"displayName":"Mạnh Dũng Nguyễn","userId":"13942456880411028305"},"user_tz":-420},"id":"4MOxD9_LPDmo","outputId":"2591f837-79e1-4178-b6d9-ef2c13756766"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":186572,"status":"ok","timestamp":1655621481286,"user":{"displayName":"Mạnh Dũng Nguyễn","userId":"13942456880411028305"},"user_tz":-420},"id":"DEdH6oi9euAW","outputId":"113826b9-0b9b-45f6-831a-86f7df5d8f07"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting torch==1.4.0\n","  Downloading torch-1.4.0-cp37-cp37m-manylinux1_x86_64.whl (753.4 MB)\n","\u001b[K     |████████████████████████████████| 753.4 MB 6.4 kB/s \n","\u001b[?25hInstalling collected packages: torch\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.11.0+cu113\n","    Uninstalling torch-1.11.0+cu113:\n","      Successfully uninstalled torch-1.11.0+cu113\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchvision 0.12.0+cu113 requires torch==1.11.0, but you have torch 1.4.0 which is incompatible.\n","torchtext 0.12.0 requires torch==1.11.0, but you have torch 1.4.0 which is incompatible.\n","torchaudio 0.11.0+cu113 requires torch==1.11.0, but you have torch 1.4.0 which is incompatible.\n","fastai 2.6.3 requires torch<1.12,>=1.7.0, but you have torch 1.4.0 which is incompatible.\u001b[0m\n","Successfully installed torch-1.4.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting requests==2.22.0\n","  Downloading requests-2.22.0-py2.py3-none-any.whl (57 kB)\n","\u001b[K     |████████████████████████████████| 57 kB 2.7 MB/s \n","\u001b[?25hCollecting idna<2.9,>=2.5\n","  Downloading idna-2.8-py2.py3-none-any.whl (58 kB)\n","\u001b[K     |████████████████████████████████| 58 kB 6.7 MB/s \n","\u001b[?25hRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests==2.22.0) (1.24.3)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests==2.22.0) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests==2.22.0) (2022.6.15)\n","Installing collected packages: idna, requests\n","  Attempting uninstall: idna\n","    Found existing installation: idna 2.10\n","    Uninstalling idna-2.10:\n","      Successfully uninstalled idna-2.10\n","  Attempting uninstall: requests\n","    Found existing installation: requests 2.23.0\n","    Uninstalling requests-2.23.0:\n","      Successfully uninstalled requests-2.23.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchvision 0.12.0+cu113 requires torch==1.11.0, but you have torch 1.4.0 which is incompatible.\n","torchtext 0.12.0 requires torch==1.11.0, but you have torch 1.4.0 which is incompatible.\n","google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.22.0 which is incompatible.\n","fastai 2.6.3 requires torch<1.12,>=1.7.0, but you have torch 1.4.0 which is incompatible.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n","Successfully installed idna-2.8 requests-2.22.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting boto3==1.11.7\n","  Downloading boto3-1.11.7-py2.py3-none-any.whl (128 kB)\n","\u001b[K     |████████████████████████████████| 128 kB 4.2 MB/s \n","\u001b[?25hCollecting botocore<1.15.0,>=1.14.7\n","  Downloading botocore-1.14.17-py2.py3-none-any.whl (5.9 MB)\n","\u001b[K     |████████████████████████████████| 5.9 MB 15.4 MB/s \n","\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n","  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n","Collecting s3transfer<0.4.0,>=0.3.0\n","  Downloading s3transfer-0.3.7-py2.py3-none-any.whl (73 kB)\n","\u001b[K     |████████████████████████████████| 73 kB 2.4 MB/s \n","\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.15.0,>=1.14.7->boto3==1.11.7) (2.8.2)\n","Requirement already satisfied: urllib3<1.26,>=1.20 in /usr/local/lib/python3.7/dist-packages (from botocore<1.15.0,>=1.14.7->boto3==1.11.7) (1.24.3)\n","Collecting docutils<0.16,>=0.10\n","  Downloading docutils-0.15.2-py3-none-any.whl (547 kB)\n","\u001b[K     |████████████████████████████████| 547 kB 89.7 MB/s \n","\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.15.0,>=1.14.7->boto3==1.11.7) (1.15.0)\n","Installing collected packages: jmespath, docutils, botocore, s3transfer, boto3\n","  Attempting uninstall: docutils\n","    Found existing installation: docutils 0.17.1\n","    Uninstalling docutils-0.17.1:\n","      Successfully uninstalled docutils-0.17.1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n","Successfully installed boto3-1.11.7 botocore-1.14.17 docutils-0.15.2 jmespath-0.10.0 s3transfer-0.3.7\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting numpy==1.17.4\n","  Downloading numpy-1.17.4-cp37-cp37m-manylinux1_x86_64.whl (20.0 MB)\n","\u001b[K     |████████████████████████████████| 20.0 MB 3.7 MB/s \n","\u001b[?25hInstalling collected packages: numpy\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.21.6\n","    Uninstalling numpy-1.21.6:\n","      Successfully uninstalled numpy-1.21.6\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","xarray 0.20.2 requires numpy>=1.18, but you have numpy 1.17.4 which is incompatible.\n","xarray-einstats 0.2.2 requires numpy>=1.21, but you have numpy 1.17.4 which is incompatible.\n","torchvision 0.12.0+cu113 requires torch==1.11.0, but you have torch 1.4.0 which is incompatible.\n","torchtext 0.12.0 requires torch==1.11.0, but you have torch 1.4.0 which is incompatible.\n","tensorflow 2.8.2+zzzcolab20220527125636 requires numpy>=1.20, but you have numpy 1.17.4 which is incompatible.\n","tables 3.7.0 requires numpy>=1.19.0, but you have numpy 1.17.4 which is incompatible.\n","kapre 0.3.7 requires numpy>=1.18.5, but you have numpy 1.17.4 which is incompatible.\n","jaxlib 0.3.7+cuda11.cudnn805 requires numpy>=1.19, but you have numpy 1.17.4 which is incompatible.\n","jax 0.3.8 requires numpy>=1.19, but you have numpy 1.17.4 which is incompatible.\n","google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.22.0 which is incompatible.\n","fastai 2.6.3 requires torch<1.12,>=1.7.0, but you have torch 1.4.0 which is incompatible.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n","albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Successfully installed numpy-1.17.4\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["numpy"]}}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting tqdm==4.36.1\n","  Downloading tqdm-4.36.1-py2.py3-none-any.whl (52 kB)\n","\u001b[K     |████████████████████████████████| 52 kB 1.4 MB/s \n","\u001b[?25hInstalling collected packages: tqdm\n","  Attempting uninstall: tqdm\n","    Found existing installation: tqdm 4.64.0\n","    Uninstalling tqdm-4.64.0:\n","      Successfully uninstalled tqdm-4.64.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchtext 0.12.0 requires torch==1.11.0, but you have torch 1.4.0 which is incompatible.\n","spacy 3.3.1 requires tqdm<5.0.0,>=4.38.0, but you have tqdm 4.36.1 which is incompatible.\n","panel 0.12.1 requires tqdm>=4.48.0, but you have tqdm 4.36.1 which is incompatible.\n","fastai 2.6.3 requires torch<1.12,>=1.7.0, but you have torch 1.4.0 which is incompatible.\u001b[0m\n","Successfully installed tqdm-4.36.1\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting botocore==1.14.7\n","  Downloading botocore-1.14.7-py2.py3-none-any.whl (5.9 MB)\n","\u001b[K     |████████████████████████████████| 5.9 MB 4.1 MB/s \n","\u001b[?25hRequirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.7/dist-packages (from botocore==1.14.7) (0.15.2)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore==1.14.7) (2.8.2)\n","Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from botocore==1.14.7) (0.10.0)\n","Requirement already satisfied: urllib3<1.26,>=1.20 in /usr/local/lib/python3.7/dist-packages (from botocore==1.14.7) (1.24.3)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore==1.14.7) (1.15.0)\n","Installing collected packages: botocore\n","  Attempting uninstall: botocore\n","    Found existing installation: botocore 1.14.17\n","    Uninstalling botocore-1.14.17:\n","      Successfully uninstalled botocore-1.14.17\n","Successfully installed botocore-1.14.7\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting apex==0.9.10dev\n","  Downloading apex-0.9.10dev.tar.gz (36 kB)\n","Collecting cryptacular\n","  Downloading cryptacular-1.6.2.tar.gz (75 kB)\n","\u001b[K     |████████████████████████████████| 75 kB 3.0 MB/s \n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","Collecting zope.sqlalchemy\n","  Downloading zope.sqlalchemy-1.6-py2.py3-none-any.whl (22 kB)\n","Collecting velruse>=1.0.3\n","  Downloading velruse-1.1.1.tar.gz (709 kB)\n","\u001b[K     |████████████████████████████████| 709 kB 23.6 MB/s \n","\u001b[?25hCollecting pyramid>1.1.2\n","  Downloading pyramid-2.0-py3-none-any.whl (246 kB)\n","\u001b[K     |████████████████████████████████| 246 kB 64.0 MB/s \n","\u001b[?25hCollecting pyramid_mailer\n","  Downloading pyramid_mailer-0.15.1-py2.py3-none-any.whl (19 kB)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from apex==0.9.10dev) (2.22.0)\n","Collecting wtforms\n","  Downloading WTForms-3.0.1-py3-none-any.whl (136 kB)\n","\u001b[K     |████████████████████████████████| 136 kB 72.0 MB/s \n","\u001b[?25hCollecting wtforms-recaptcha\n","  Downloading wtforms_recaptcha-0.3.2-py2.py3-none-any.whl (7.5 kB)\n","Collecting venusian>=1.0\n","  Downloading venusian-3.0.0-py3-none-any.whl (13 kB)\n","Collecting hupper>=1.5\n","  Downloading hupper-1.10.3-py2.py3-none-any.whl (26 kB)\n","Collecting plaster\n","  Downloading plaster-1.0-py2.py3-none-any.whl (14 kB)\n","Collecting zope.interface>=3.8.0\n","  Downloading zope.interface-5.4.0-cp37-cp37m-manylinux2010_x86_64.whl (251 kB)\n","\u001b[K     |████████████████████████████████| 251 kB 79.1 MB/s \n","\u001b[?25hCollecting zope.deprecation>=3.5.0\n","  Downloading zope.deprecation-4.4.0-py2.py3-none-any.whl (10 kB)\n","Collecting webob>=1.8.3\n","  Downloading WebOb-1.8.7-py2.py3-none-any.whl (114 kB)\n","\u001b[K     |████████████████████████████████| 114 kB 59.4 MB/s \n","\u001b[?25hCollecting plaster-pastedeploy\n","  Downloading plaster_pastedeploy-0.7-py2.py3-none-any.whl (7.8 kB)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from pyramid>1.1.2->apex==0.9.10dev) (57.4.0)\n","Collecting translationstring>=0.4\n","  Downloading translationstring-1.4-py2.py3-none-any.whl (15 kB)\n","Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.7/dist-packages (from velruse>=1.0.3->apex==0.9.10dev) (1.3.1)\n","Collecting anykeystore\n","  Downloading anykeystore-0.2.tar.gz (10 kB)\n","Collecting python3-openid\n","  Downloading python3_openid-3.2.0-py3-none-any.whl (133 kB)\n","\u001b[K     |████████████████████████████████| 133 kB 86.6 MB/s \n","\u001b[?25hCollecting pbkdf2\n","  Downloading pbkdf2-1.3.tar.gz (6.4 kB)\n","Collecting PasteDeploy>=2.0\n","  Downloading PasteDeploy-2.1.1-py2.py3-none-any.whl (17 kB)\n","Collecting repoze.sendmail>=4.1\n","  Downloading repoze.sendmail-4.4.1-py2.py3-none-any.whl (41 kB)\n","\u001b[K     |████████████████████████████████| 41 kB 53 kB/s \n","\u001b[?25hCollecting transaction\n","  Downloading transaction-3.0.1-py2.py3-none-any.whl (47 kB)\n","\u001b[K     |████████████████████████████████| 47 kB 5.9 MB/s \n","\u001b[?25hRequirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from python3-openid->velruse>=1.0.3->apex==0.9.10dev) (0.7.1)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->apex==0.9.10dev) (3.0.4)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->apex==0.9.10dev) (2.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->apex==0.9.10dev) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->apex==0.9.10dev) (2022.6.15)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib->velruse>=1.0.3->apex==0.9.10dev) (3.2.0)\n","Requirement already satisfied: MarkupSafe in /usr/local/lib/python3.7/dist-packages (from wtforms->apex==0.9.10dev) (2.0.1)\n","Requirement already satisfied: SQLAlchemy!=1.4.0,!=1.4.1,!=1.4.2,!=1.4.3,!=1.4.4,!=1.4.5,!=1.4.6,>=0.9 in /usr/local/lib/python3.7/dist-packages (from zope.sqlalchemy->apex==0.9.10dev) (1.4.37)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from SQLAlchemy!=1.4.0,!=1.4.1,!=1.4.2,!=1.4.3,!=1.4.4,!=1.4.5,!=1.4.6,>=0.9->zope.sqlalchemy->apex==0.9.10dev) (1.1.2)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from SQLAlchemy!=1.4.0,!=1.4.1,!=1.4.2,!=1.4.3,!=1.4.4,!=1.4.5,!=1.4.6,>=0.9->zope.sqlalchemy->apex==0.9.10dev) (4.11.4)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->SQLAlchemy!=1.4.0,!=1.4.1,!=1.4.2,!=1.4.3,!=1.4.4,!=1.4.5,!=1.4.6,>=0.9->zope.sqlalchemy->apex==0.9.10dev) (3.8.0)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->SQLAlchemy!=1.4.0,!=1.4.1,!=1.4.2,!=1.4.3,!=1.4.4,!=1.4.5,!=1.4.6,>=0.9->zope.sqlalchemy->apex==0.9.10dev) (4.1.1)\n","Building wheels for collected packages: apex, velruse, anykeystore, cryptacular, pbkdf2\n","  Building wheel for apex (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for apex: filename=apex-0.9.10.dev0-py3-none-any.whl size=46467 sha256=2988cba03e108549369a3138e93099737949aa2de3327a8b6ff0d6ec1dbc5a7c\n","  Stored in directory: /root/.cache/pip/wheels/f0/00/2b/37b6028388b451bbd30230c62f5238aef3b11fdff9503138bc\n","  Building wheel for velruse (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for velruse: filename=velruse-1.1.1-py3-none-any.whl size=50938 sha256=ba5fa2bf077629c7c63af6902e1a6eaf042bee0a88a01069dd32a64761f4b10a\n","  Stored in directory: /root/.cache/pip/wheels/61/f0/95/7f8b3bb1cce5c78ca7a7922cf72383f886f70e358f0a18d60b\n","  Building wheel for anykeystore (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for anykeystore: filename=anykeystore-0.2-py3-none-any.whl size=17043 sha256=139c8a53049ead18a9bbf5d8fd4319cc012bfe45e777405df6de5cc98a440b89\n","  Stored in directory: /root/.cache/pip/wheels/12/14/12/afad2dc2b7ea0884e12f260b0723b49b98f39f08adb7b0414f\n","  Building wheel for cryptacular (PEP 517) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for cryptacular: filename=cryptacular-1.6.2-cp37-cp37m-linux_x86_64.whl size=54544 sha256=60cc067e0ec761e302820f69cd3e73dc9bf3fb2c71cf52bf375b6e05ddb31700\n","  Stored in directory: /root/.cache/pip/wheels/fc/e8/c2/4b71f45f434136d31df930960b8a916bb36ebe2144479a37a1\n","  Building wheel for pbkdf2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pbkdf2: filename=pbkdf2-1.3-py3-none-any.whl size=5105 sha256=83e4984bad599cb243aa1d00dd341d8799cc73c170b3d06559560254e3eeb993\n","  Stored in directory: /root/.cache/pip/wheels/49/16/ea/daca297d70ee0782ac6e16e83b2c55b2ca42a2113750bc0489\n","Successfully built apex velruse anykeystore cryptacular pbkdf2\n","Installing collected packages: zope.interface, plaster, PasteDeploy, zope.deprecation, webob, venusian, translationstring, transaction, plaster-pastedeploy, hupper, wtforms, repoze.sendmail, python3-openid, pyramid, pbkdf2, anykeystore, zope.sqlalchemy, wtforms-recaptcha, velruse, pyramid-mailer, cryptacular, apex\n","Successfully installed PasteDeploy-2.1.1 anykeystore-0.2 apex-0.9.10.dev0 cryptacular-1.6.2 hupper-1.10.3 pbkdf2-1.3 plaster-1.0 plaster-pastedeploy-0.7 pyramid-2.0 pyramid-mailer-0.15.1 python3-openid-3.2.0 repoze.sendmail-4.4.1 transaction-3.0.1 translationstring-1.4 velruse-1.1.1 venusian-3.0.0 webob-1.8.7 wtforms-3.0.1 wtforms-recaptcha-0.3.2 zope.deprecation-4.4.0 zope.interface-5.4.0 zope.sqlalchemy-1.6\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting tensorflow==2.3.1\n","  Downloading tensorflow-2.3.1-cp37-cp37m-manylinux2010_x86_64.whl (320.4 MB)\n","\u001b[K     |████████████████████████████████| 320.4 MB 20 kB/s \n","\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.1) (3.3.0)\n","Collecting gast==0.3.3\n","  Downloading gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n","Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.1) (3.17.3)\n","Collecting h5py<2.11.0,>=2.10.0\n","  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n","\u001b[K     |████████████████████████████████| 2.9 MB 23.9 MB/s \n","\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.1) (1.46.3)\n","Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.1) (1.1.2)\n","Collecting tensorflow-estimator<2.4.0,>=2.3.0\n","  Downloading tensorflow_estimator-2.3.0-py2.py3-none-any.whl (459 kB)\n","\u001b[K     |████████████████████████████████| 459 kB 49.8 MB/s \n","\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.1) (1.1.0)\n","Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.1) (1.6.3)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.1) (1.14.1)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.1) (1.15.0)\n","Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.1) (0.2.0)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.1) (0.37.1)\n","Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.1) (2.8.0)\n","Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.1) (1.17.4)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.1) (1.1.0)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.1) (57.4.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.1) (1.35.0)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.1) (0.6.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.1) (0.4.6)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.1) (1.0.1)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.1) (2.22.0)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.1) (1.8.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.1) (3.3.7)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.1) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.1) (4.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.1) (4.2.4)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow==2.3.1) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow==2.3.1) (4.11.4)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow==2.3.1) (3.8.0)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow==2.3.1) (4.1.1)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.1) (0.4.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.1) (1.24.3)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.1) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.1) (2022.6.15)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.1) (2.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow==2.3.1) (3.2.0)\n","Installing collected packages: tensorflow-estimator, h5py, gast, tensorflow\n","  Attempting uninstall: tensorflow-estimator\n","    Found existing installation: tensorflow-estimator 2.8.0\n","    Uninstalling tensorflow-estimator-2.8.0:\n","      Successfully uninstalled tensorflow-estimator-2.8.0\n","  Attempting uninstall: h5py\n","    Found existing installation: h5py 3.1.0\n","    Uninstalling h5py-3.1.0:\n","      Successfully uninstalled h5py-3.1.0\n","  Attempting uninstall: gast\n","    Found existing installation: gast 0.5.3\n","    Uninstalling gast-0.5.3:\n","      Successfully uninstalled gast-0.5.3\n","  Attempting uninstall: tensorflow\n","    Found existing installation: tensorflow 2.8.2+zzzcolab20220527125636\n","    Uninstalling tensorflow-2.8.2+zzzcolab20220527125636:\n","      Successfully uninstalled tensorflow-2.8.2+zzzcolab20220527125636\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","kapre 0.3.7 requires numpy>=1.18.5, but you have numpy 1.17.4 which is incompatible.\u001b[0m\n","Successfully installed gast-0.3.3 h5py-2.10.0 tensorflow-2.3.1 tensorflow-estimator-2.3.0\n"]}],"source":["!pip install torch==1.4.0\n","!pip install requests==2.22.0\n","!pip install boto3==1.11.7\n","!pip install numpy==1.17.4\n","!pip install tqdm==4.36.1\n","!pip install botocore==1.14.7\n","!pip install apex==0.9.10dev\n","!pip install tensorflow==2.3.1"]},{"cell_type":"markdown","metadata":{"id":"qqvXqwk2iCOO"},"source":["# Data Prepareration"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":346,"status":"ok","timestamp":1655563444860,"user":{"displayName":"Mạnh Dũng Nguyễn","userId":"13942456880411028305"},"user_tz":-420},"id":"uenkD3_CQpDl","outputId":"64dbffd6-dc1c-4897-893d-174e7a2cb8cb"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/gdrive/My Drive/Colab Notebooks\n"]}],"source":["%cd gdrive/My\\ Drive/Colab\\ Notebooks"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1655566788176,"user":{"displayName":"Mạnh Dũng Nguyễn","userId":"13942456880411028305"},"user_tz":-420},"id":"tLYT9hthRW7h","outputId":"6aeb5fdb-7cf8-44f2-a1d3-c4c3464adf38"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/gdrive/MyDrive/Colab Notebooks/BLANC/code/src/preprocessor\n"]}],"source":["!pwd"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2838,"status":"ok","timestamp":1655563520480,"user":{"displayName":"Mạnh Dũng Nguyễn","userId":"13942456880411028305"},"user_tz":-420},"id":"_j9oYqlHRcDe","outputId":"14ceff24-47cf-4879-970e-d37281cba15b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Cloning into 'BLANC'...\n","remote: Enumerating objects: 73, done.\u001b[K\n","remote: Counting objects: 100% (73/73), done.\u001b[K\n","remote: Compressing objects: 100% (45/45), done.\u001b[K\n","remote: Total 73 (delta 28), reused 68 (delta 24), pack-reused 0\u001b[K\n","Unpacking objects: 100% (73/73), done.\n"]}],"source":["!git clone https://github.com/yeonsw/BLANC.git"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1655566089149,"user":{"displayName":"Mạnh Dũng Nguyễn","userId":"13942456880411028305"},"user_tz":-420},"id":"RVAkVuf0O2J7","outputId":"8d1a5a21-78b9-443d-c758-cc55b0a03b97"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/gdrive/My Drive/Colab Notebooks\n"]}],"source":["# %cd BLANC\n","%cd -"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":359,"status":"ok","timestamp":1655566142959,"user":{"displayName":"Mạnh Dũng Nguyễn","userId":"13942456880411028305"},"user_tz":-420},"id":"_sdFhYM-bYS2","outputId":"f7b85be1-be0f-4453-8321-1c4944eb3aff"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/gdrive/MyDrive/Colab Notebooks/BLANC/code/src/preprocessor\n"]}],"source":["%cd BLANC/code/src/preprocessor"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":84612,"status":"ok","timestamp":1655566551079,"user":{"displayName":"Mạnh Dũng Nguyễn","userId":"13942456880411028305"},"user_tz":-420},"id":"0dPDYpP_TW0l","outputId":"2242f6ce-b924-4290-dbd1-6209040f3aec"},"outputs":[{"name":"stdout","output_type":"stream","text":["Set random seed: 1234\n"]}],"source":["!python split_data.py \\\n","    --source /content/gdrive/MyDrive/Colab\\ Notebooks/BLANC/data/naturalQ/train.jsonl.gz \\\n","    --train_output /content/gdrive/MyDrive/Colab\\ Notebooks/BLANC/data/naturalQ/train.jsonl \\\n","    --dev_output /content/gdrive/MyDrive/Colab\\ Notebooks/BLANC/data/naturalQ/dev.jsonl \\\n","    --data_type mrqa"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S4v3PMXAYjHd"},"outputs":[],"source":["!gzip \"/content/gdrive/MyDrive/Colab Notebooks/BLANC/data/naturalQ/train.jsonl\"\n","!gzip \"/content/gdrive/MyDrive/Colab Notebooks/BLANC/data/naturalQ/dev.jsonl\""]},{"cell_type":"markdown","metadata":{"id":"SvKrrNaRiIXF"},"source":["# Train"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":445,"status":"ok","timestamp":1655621508521,"user":{"displayName":"Mạnh Dũng Nguyễn","userId":"13942456880411028305"},"user_tz":-420},"id":"z-_KhCtNeFpE","outputId":"3d8bd169-3106-4e3e-a13f-1edbc52519b9"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n","/content/gdrive/My Drive/Colab Notebooks/BLANC/code\n"]}],"source":["%cd /content\n","%cd gdrive/My\\ Drive/Colab\\ Notebooks/BLANC/code"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"g_dqhFcCd44K","outputId":"60381da6-a1d2-4b9b-c0c9-8c606d49f3ec"},"outputs":[{"name":"stdout","output_type":"stream","text":["06/18/2022 16:00:01 - INFO - __main__ - device: cuda, n_gpu: 1, 16-bits training: False\n","06/18/2022 16:00:01 - INFO - __main__ - Namespace(dev_file='../data/naturalQ/dev.jsonl.gz', do_eval=True, do_lower_case=False, do_train=True, doc_stride=128, eval_batch_size=16, eval_metric='span_f1', eval_per_epoch=20, eval_test=True, fp16=False, geometric_p=0.99, gradient_accumulation_steps=1, learning_rate=2e-05, lmb=0.8, loss_scale=0, max_answer_length=30, max_query_length=64, max_seq_length=384, model='spanbert-base-cased', n_best_size=20, no_cuda=False, num_train_epochs=3.0, output_dir='./checkpoints/naturalqa/trial_001/1234', seed=1234, test_file='../data/naturalQ/test.jsonl.gz', train_batch_size=8, train_file='../data/naturalQ/train.jsonl.gz', train_mode='random_sorted', verbose_logging=False, warmup_proportion=0.1, window_size=3)\n","06/18/2022 16:00:01 - INFO - pytorch_pretrained_bert.file_utils - https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt not found in cache, downloading to /tmp/tmpenv0wvxa\n","100% 213450/213450 [00:00<00:00, 1148201.07B/s]\n","06/18/2022 16:00:02 - INFO - pytorch_pretrained_bert.file_utils - copying /tmp/tmpenv0wvxa to cache at /root/.pytorch_pretrained_bert/5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1\n","06/18/2022 16:00:02 - INFO - pytorch_pretrained_bert.file_utils - creating metadata file for /root/.pytorch_pretrained_bert/5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1\n","06/18/2022 16:00:02 - INFO - pytorch_pretrained_bert.file_utils - removing temp file /tmp/tmpenv0wvxa\n","06/18/2022 16:00:02 - INFO - pytorch_pretrained_bert.tokenization - loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt from cache at /root/.pytorch_pretrained_bert/5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1\n","06/18/2022 16:00:06 - INFO - __main__ - Processing 0 / 10406..\n","06/18/2022 16:00:07 - INFO - __main__ - Processing 1000 / 10406..\n","06/18/2022 16:00:07 - INFO - __main__ - Processing 2000 / 10406..\n","06/18/2022 16:00:07 - INFO - __main__ - Processing 3000 / 10406..\n","06/18/2022 16:00:08 - INFO - __main__ - Processing 4000 / 10406..\n","06/18/2022 16:00:08 - INFO - __main__ - Processing 5000 / 10406..\n","06/18/2022 16:00:08 - INFO - __main__ - Processing 6000 / 10406..\n","06/18/2022 16:00:09 - INFO - __main__ - Processing 7000 / 10406..\n","06/18/2022 16:00:09 - INFO - __main__ - Processing 8000 / 10406..\n","06/18/2022 16:00:09 - INFO - __main__ - Processing 9000 / 10406..\n","06/18/2022 16:00:09 - INFO - __main__ - Processing 10000 / 10406..\n","06/18/2022 16:00:10 - INFO - __main__ - Num avg answers: 1.2161253123198155\n","06/18/2022 16:00:53 - INFO - __main__ - ***** Dev *****\n","06/18/2022 16:00:53 - INFO - __main__ -   Num orig examples = 10406\n","06/18/2022 16:00:53 - INFO - __main__ -   Num split examples = 19506\n","06/18/2022 16:00:53 - INFO - __main__ -   Batch size = 16\n","06/18/2022 16:01:14 - INFO - __main__ - Processing 0 / 93663..\n","06/18/2022 16:01:14 - INFO - __main__ - Processing 1000 / 93663..\n","06/18/2022 16:01:15 - INFO - __main__ - Processing 2000 / 93663..\n","06/18/2022 16:01:15 - INFO - __main__ - Processing 3000 / 93663..\n","06/18/2022 16:01:15 - INFO - __main__ - Processing 4000 / 93663..\n","06/18/2022 16:01:16 - INFO - __main__ - Processing 5000 / 93663..\n","06/18/2022 16:01:16 - INFO - __main__ - Processing 6000 / 93663..\n","06/18/2022 16:01:16 - INFO - __main__ - Processing 7000 / 93663..\n","06/18/2022 16:01:17 - INFO - __main__ - Processing 8000 / 93663..\n","06/18/2022 16:01:17 - INFO - __main__ - Processing 9000 / 93663..\n","06/18/2022 16:01:17 - INFO - __main__ - Processing 10000 / 93663..\n","06/18/2022 16:01:17 - INFO - __main__ - Processing 11000 / 93663..\n","06/18/2022 16:01:18 - INFO - __main__ - Processing 12000 / 93663..\n","06/18/2022 16:01:18 - INFO - __main__ - Processing 13000 / 93663..\n","06/18/2022 16:01:18 - INFO - __main__ - Processing 14000 / 93663..\n","06/18/2022 16:01:19 - INFO - __main__ - Processing 15000 / 93663..\n","06/18/2022 16:01:19 - INFO - __main__ - Processing 16000 / 93663..\n","06/18/2022 16:01:19 - INFO - __main__ - Processing 17000 / 93663..\n","06/18/2022 16:01:20 - INFO - __main__ - Processing 18000 / 93663..\n","06/18/2022 16:01:20 - INFO - __main__ - Processing 19000 / 93663..\n","06/18/2022 16:01:20 - INFO - __main__ - Processing 20000 / 93663..\n","06/18/2022 16:01:21 - INFO - __main__ - Processing 21000 / 93663..\n","06/18/2022 16:01:21 - INFO - __main__ - Processing 22000 / 93663..\n","06/18/2022 16:01:21 - INFO - __main__ - Processing 23000 / 93663..\n","06/18/2022 16:01:22 - INFO - __main__ - Processing 24000 / 93663..\n","06/18/2022 16:01:22 - INFO - __main__ - Processing 25000 / 93663..\n","06/18/2022 16:01:22 - INFO - __main__ - Processing 26000 / 93663..\n","06/18/2022 16:01:23 - INFO - __main__ - Processing 27000 / 93663..\n","06/18/2022 16:01:23 - INFO - __main__ - Processing 28000 / 93663..\n","06/18/2022 16:01:23 - INFO - __main__ - Processing 29000 / 93663..\n","06/18/2022 16:01:24 - INFO - __main__ - Processing 30000 / 93663..\n","06/18/2022 16:01:24 - INFO - __main__ - Processing 31000 / 93663..\n","06/18/2022 16:01:24 - INFO - __main__ - Processing 32000 / 93663..\n","06/18/2022 16:01:25 - INFO - __main__ - Processing 33000 / 93663..\n","06/18/2022 16:01:25 - INFO - __main__ - Processing 34000 / 93663..\n","06/18/2022 16:01:25 - INFO - __main__ - Processing 35000 / 93663..\n","06/18/2022 16:01:26 - INFO - __main__ - Processing 36000 / 93663..\n","06/18/2022 16:01:26 - INFO - __main__ - Processing 37000 / 93663..\n","06/18/2022 16:01:26 - INFO - __main__ - Processing 38000 / 93663..\n","06/18/2022 16:01:27 - INFO - __main__ - Processing 39000 / 93663..\n","06/18/2022 16:01:27 - INFO - __main__ - Processing 40000 / 93663..\n","06/18/2022 16:01:27 - INFO - __main__ - Processing 41000 / 93663..\n","06/18/2022 16:01:28 - INFO - __main__ - Processing 42000 / 93663..\n","06/18/2022 16:01:28 - INFO - __main__ - Processing 43000 / 93663..\n","06/18/2022 16:01:28 - INFO - __main__ - Processing 44000 / 93663..\n","06/18/2022 16:01:29 - INFO - __main__ - Processing 45000 / 93663..\n","06/18/2022 16:01:29 - INFO - __main__ - Processing 46000 / 93663..\n","06/18/2022 16:01:29 - INFO - __main__ - Processing 47000 / 93663..\n","06/18/2022 16:01:30 - INFO - __main__ - Processing 48000 / 93663..\n","06/18/2022 16:01:30 - INFO - __main__ - Processing 49000 / 93663..\n","06/18/2022 16:01:30 - INFO - __main__ - Processing 50000 / 93663..\n","06/18/2022 16:01:31 - INFO - __main__ - Processing 51000 / 93663..\n","06/18/2022 16:01:31 - INFO - __main__ - Processing 52000 / 93663..\n","06/18/2022 16:01:31 - INFO - __main__ - Processing 53000 / 93663..\n","06/18/2022 16:01:32 - INFO - __main__ - Processing 54000 / 93663..\n","06/18/2022 16:01:32 - INFO - __main__ - Processing 55000 / 93663..\n","06/18/2022 16:01:32 - INFO - __main__ - Processing 56000 / 93663..\n","06/18/2022 16:01:33 - INFO - __main__ - Processing 57000 / 93663..\n","06/18/2022 16:01:33 - INFO - __main__ - Processing 58000 / 93663..\n","06/18/2022 16:01:33 - INFO - __main__ - Processing 59000 / 93663..\n","06/18/2022 16:01:33 - INFO - __main__ - Processing 60000 / 93663..\n","06/18/2022 16:01:34 - INFO - __main__ - Processing 61000 / 93663..\n","06/18/2022 16:01:34 - INFO - __main__ - Processing 62000 / 93663..\n","06/18/2022 16:01:34 - INFO - __main__ - Processing 63000 / 93663..\n","06/18/2022 16:01:35 - INFO - __main__ - Processing 64000 / 93663..\n","06/18/2022 16:01:35 - INFO - __main__ - Processing 65000 / 93663..\n","06/18/2022 16:01:35 - INFO - __main__ - Processing 66000 / 93663..\n","06/18/2022 16:01:36 - INFO - __main__ - Processing 67000 / 93663..\n","06/18/2022 16:01:36 - INFO - __main__ - Processing 68000 / 93663..\n","06/18/2022 16:01:36 - INFO - __main__ - Processing 69000 / 93663..\n","06/18/2022 16:01:37 - INFO - __main__ - Processing 70000 / 93663..\n","06/18/2022 16:01:37 - INFO - __main__ - Processing 71000 / 93663..\n","06/18/2022 16:01:37 - INFO - __main__ - Processing 72000 / 93663..\n","06/18/2022 16:01:38 - INFO - __main__ - Processing 73000 / 93663..\n","06/18/2022 16:01:38 - INFO - __main__ - Processing 74000 / 93663..\n","06/18/2022 16:01:38 - INFO - __main__ - Processing 75000 / 93663..\n","06/18/2022 16:01:39 - INFO - __main__ - Processing 76000 / 93663..\n","06/18/2022 16:01:39 - INFO - __main__ - Processing 77000 / 93663..\n","06/18/2022 16:01:39 - INFO - __main__ - Processing 78000 / 93663..\n","06/18/2022 16:01:40 - INFO - __main__ - Processing 79000 / 93663..\n","06/18/2022 16:01:40 - INFO - __main__ - Processing 80000 / 93663..\n","06/18/2022 16:01:40 - INFO - __main__ - Processing 81000 / 93663..\n","06/18/2022 16:01:41 - INFO - __main__ - Processing 82000 / 93663..\n","06/18/2022 16:01:41 - INFO - __main__ - Processing 83000 / 93663..\n","06/18/2022 16:01:41 - INFO - __main__ - Processing 84000 / 93663..\n","06/18/2022 16:01:42 - INFO - __main__ - Processing 85000 / 93663..\n","06/18/2022 16:01:42 - INFO - __main__ - Processing 86000 / 93663..\n","06/18/2022 16:01:42 - INFO - __main__ - Processing 87000 / 93663..\n","06/18/2022 16:01:43 - INFO - __main__ - Processing 88000 / 93663..\n","06/18/2022 16:01:43 - INFO - __main__ - Processing 89000 / 93663..\n","06/18/2022 16:01:43 - INFO - __main__ - Processing 90000 / 93663..\n","06/18/2022 16:01:44 - INFO - __main__ - Processing 91000 / 93663..\n","06/18/2022 16:01:44 - INFO - __main__ - Processing 92000 / 93663..\n","06/18/2022 16:01:44 - INFO - __main__ - Processing 93000 / 93663..\n","06/18/2022 16:01:45 - INFO - __main__ - Num avg answers: 1.2142574976244622\n","06/18/2022 16:08:45 - INFO - __main__ - ***** Train *****\n","06/18/2022 16:08:45 - INFO - __main__ -   Num orig examples = 93663\n","06/18/2022 16:08:45 - INFO - __main__ -   Num split examples = 22814\n","06/18/2022 16:08:45 - INFO - __main__ -   Batch size = 8\n","06/18/2022 16:08:45 - INFO - __main__ -   Num steps = 68442\n","06/18/2022 16:08:46 - INFO - pytorch_pretrained_bert.file_utils - https://dl.fbaipublicfiles.com/fairseq/models/spanbert_hf_base.tar.gz not found in cache, downloading to /tmp/tmpr65afc95\n","100% 198960653/198960653 [00:03<00:00, 59655474.53B/s]\n","06/18/2022 16:08:49 - INFO - pytorch_pretrained_bert.file_utils - copying /tmp/tmpr65afc95 to cache at /root/.pytorch_pretrained_bert/3ff3afa095e0b3ff30e3bb5e134292af6ad4b922ae1f7d16a37148c7a9c8fd96.d8c385bb8e09a3e5a28b5af1308a4242e2ff27ba6477a532c9762e71b0cfb3f0\n","06/18/2022 16:08:49 - INFO - pytorch_pretrained_bert.file_utils - creating metadata file for /root/.pytorch_pretrained_bert/3ff3afa095e0b3ff30e3bb5e134292af6ad4b922ae1f7d16a37148c7a9c8fd96.d8c385bb8e09a3e5a28b5af1308a4242e2ff27ba6477a532c9762e71b0cfb3f0\n","06/18/2022 16:08:49 - INFO - pytorch_pretrained_bert.file_utils - removing temp file /tmp/tmpr65afc95\n","06/18/2022 16:08:49 - INFO - pytorch_pretrained_bert.blanc - loading archive file https://dl.fbaipublicfiles.com/fairseq/models/spanbert_hf_base.tar.gz from cache at /root/.pytorch_pretrained_bert/3ff3afa095e0b3ff30e3bb5e134292af6ad4b922ae1f7d16a37148c7a9c8fd96.d8c385bb8e09a3e5a28b5af1308a4242e2ff27ba6477a532c9762e71b0cfb3f0\n","06/18/2022 16:08:49 - INFO - pytorch_pretrained_bert.blanc - extracting archive file /root/.pytorch_pretrained_bert/3ff3afa095e0b3ff30e3bb5e134292af6ad4b922ae1f7d16a37148c7a9c8fd96.d8c385bb8e09a3e5a28b5af1308a4242e2ff27ba6477a532c9762e71b0cfb3f0 to temp dir /tmp/tmp7_yesrl0\n","06/18/2022 16:08:51 - INFO - pytorch_pretrained_bert.blanc - Model config {\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"directionality\": \"bidi\",\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"max_position_embeddings\": 512,\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 28996\n","}\n","\n","06/18/2022 16:08:53 - INFO - pytorch_pretrained_bert.blanc - Weights of BLANC not initialized from pretrained model: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias', 'qa_outputs.weight', 'qa_outputs.bias', 'block_outputs.weight', 'block_outputs.bias']\n","06/18/2022 16:08:57 - INFO - __main__ - Start epoch #0 (lr = 2e-05)...\n","06/18/2022 16:17:08 - INFO - __main__ - Epoch: 0, Step: 1140 / 22814, used_time = 491.33s\n","06/18/2022 16:17:08 - INFO - __main__ - Processing example: 0\n","06/18/2022 16:17:37 - INFO - __main__ - Processing example: 2000\n","06/18/2022 16:18:05 - INFO - __main__ - Processing example: 4000\n","06/18/2022 16:18:34 - INFO - __main__ - Processing example: 6000\n","06/18/2022 16:19:03 - INFO - __main__ - Processing example: 8000\n","06/18/2022 16:19:32 - INFO - __main__ - Processing example: 10000\n","06/18/2022 16:20:00 - INFO - __main__ - Processing example: 12000\n","06/18/2022 16:20:29 - INFO - __main__ - Processing example: 14000\n","06/18/2022 16:20:58 - INFO - __main__ - Processing example: 16000\n","06/18/2022 16:21:26 - INFO - __main__ - Processing example: 18000\n","06/18/2022 16:22:23 - INFO - __main__ - ***** Eval results *****\n","06/18/2022 16:22:23 - INFO - __main__ -   exact = 15.827407265039401\n","06/18/2022 16:22:23 - INFO - __main__ -   f1 = 27.088303439038796\n","06/18/2022 16:22:23 - INFO - __main__ -   precision = 28.14357258518062\n","06/18/2022 16:22:23 - INFO - __main__ -   recall = 33.337239207458545\n","06/18/2022 16:22:23 - INFO - __main__ -   span_exact = 13.722852200653469\n","06/18/2022 16:22:23 - INFO - __main__ -   span_f1 = 22.46838275503882\n","06/18/2022 16:22:23 - INFO - __main__ -   span_precision = 23.408696186098606\n","06/18/2022 16:22:23 - INFO - __main__ -   span_recall = 27.617007240532306\n","06/18/2022 16:22:23 - INFO - __main__ -   total = 10406\n","06/18/2022 16:22:23 - INFO - __main__ - !!! Best dev span_f1 (lr=2e-05, epoch=0): 22.47\n","06/18/2022 16:30:36 - INFO - __main__ - Epoch: 0, Step: 2280 / 22814, used_time = 1299.00s\n","06/18/2022 16:30:36 - INFO - __main__ - Processing example: 0\n","06/18/2022 16:31:04 - INFO - __main__ - Processing example: 2000\n","06/18/2022 16:31:33 - INFO - __main__ - Processing example: 4000\n","06/18/2022 16:32:02 - INFO - __main__ - Processing example: 6000\n","06/18/2022 16:32:31 - INFO - __main__ - Processing example: 8000\n","06/18/2022 16:32:59 - INFO - __main__ - Processing example: 10000\n","06/18/2022 16:33:28 - INFO - __main__ - Processing example: 12000\n","06/18/2022 16:33:57 - INFO - __main__ - Processing example: 14000\n","06/18/2022 16:34:25 - INFO - __main__ - Processing example: 16000\n","06/18/2022 16:34:54 - INFO - __main__ - Processing example: 18000\n","06/18/2022 16:35:47 - INFO - __main__ - ***** Eval results *****\n","06/18/2022 16:35:47 - INFO - __main__ -   exact = 43.81126273303863\n","06/18/2022 16:35:47 - INFO - __main__ -   f1 = 57.52618074912812\n","06/18/2022 16:35:47 - INFO - __main__ -   precision = 61.623381678631056\n","06/18/2022 16:35:47 - INFO - __main__ -   recall = 60.61127498448144\n","06/18/2022 16:35:47 - INFO - __main__ -   span_exact = 40.024985585239286\n","06/18/2022 16:35:47 - INFO - __main__ -   span_f1 = 52.46287944181835\n","06/18/2022 16:35:47 - INFO - __main__ -   span_precision = 56.703383585991425\n","06/18/2022 16:35:47 - INFO - __main__ -   span_recall = 55.26069554936629\n","06/18/2022 16:35:47 - INFO - __main__ -   total = 10406\n","06/18/2022 16:35:48 - INFO - __main__ - !!! Best dev span_f1 (lr=2e-05, epoch=0): 52.46\n","06/18/2022 16:44:01 - INFO - __main__ - Epoch: 0, Step: 3420 / 22814, used_time = 2104.49s\n","06/18/2022 16:44:01 - INFO - __main__ - Processing example: 0\n","06/18/2022 16:44:30 - INFO - __main__ - Processing example: 2000\n","06/18/2022 16:44:59 - INFO - __main__ - Processing example: 4000\n","06/18/2022 16:45:27 - INFO - __main__ - Processing example: 6000\n","06/18/2022 16:45:56 - INFO - __main__ - Processing example: 8000\n","06/18/2022 16:46:25 - INFO - __main__ - Processing example: 10000\n","06/18/2022 16:46:53 - INFO - __main__ - Processing example: 12000\n","06/18/2022 16:47:22 - INFO - __main__ - Processing example: 14000\n","06/18/2022 16:47:51 - INFO - __main__ - Processing example: 16000\n","06/18/2022 16:48:20 - INFO - __main__ - Processing example: 18000\n","06/18/2022 16:49:11 - INFO - __main__ - ***** Eval results *****\n","06/18/2022 16:49:11 - INFO - __main__ -   exact = 50.31712473572939\n","06/18/2022 16:49:11 - INFO - __main__ -   f1 = 63.96579115607761\n","06/18/2022 16:49:11 - INFO - __main__ -   precision = 68.48763760966622\n","06/18/2022 16:49:11 - INFO - __main__ -   recall = 65.79206050527807\n","06/18/2022 16:49:11 - INFO - __main__ -   span_exact = 45.79088987122814\n","06/18/2022 16:49:11 - INFO - __main__ -   span_f1 = 58.85399146528517\n","06/18/2022 16:49:11 - INFO - __main__ -   span_precision = 63.60351294901554\n","06/18/2022 16:49:11 - INFO - __main__ -   span_recall = 60.64548276144971\n","06/18/2022 16:49:11 - INFO - __main__ -   total = 10406\n","06/18/2022 16:49:11 - INFO - __main__ - !!! Best dev span_f1 (lr=2e-05, epoch=0): 58.85\n","06/18/2022 16:57:24 - INFO - __main__ - Epoch: 0, Step: 4560 / 22814, used_time = 2907.41s\n","06/18/2022 16:57:24 - INFO - __main__ - Processing example: 0\n","06/18/2022 16:57:53 - INFO - __main__ - Processing example: 2000\n","06/18/2022 16:58:21 - INFO - __main__ - Processing example: 4000\n","06/18/2022 16:58:50 - INFO - __main__ - Processing example: 6000\n","06/18/2022 16:59:19 - INFO - __main__ - Processing example: 8000\n","06/18/2022 16:59:48 - INFO - __main__ - Processing example: 10000\n","06/18/2022 17:00:16 - INFO - __main__ - Processing example: 12000\n","06/18/2022 17:00:45 - INFO - __main__ - Processing example: 14000\n","06/18/2022 17:01:14 - INFO - __main__ - Processing example: 16000\n","06/18/2022 17:01:42 - INFO - __main__ - Processing example: 18000\n","06/18/2022 17:02:35 - INFO - __main__ - ***** Eval results *****\n","06/18/2022 17:02:35 - INFO - __main__ -   exact = 54.708821833557565\n","06/18/2022 17:02:35 - INFO - __main__ -   f1 = 67.89168958839956\n","06/18/2022 17:02:35 - INFO - __main__ -   precision = 70.99647264123773\n","06/18/2022 17:02:35 - INFO - __main__ -   recall = 70.50921721354771\n","06/18/2022 17:02:35 - INFO - __main__ -   span_exact = 50.4997117047857\n","06/18/2022 17:02:35 - INFO - __main__ -   span_f1 = 62.98923741749892\n","06/18/2022 17:02:35 - INFO - __main__ -   span_precision = 66.18950856473234\n","06/18/2022 17:02:35 - INFO - __main__ -   span_recall = 65.57009755241582\n","06/18/2022 17:02:35 - INFO - __main__ -   total = 10406\n","06/18/2022 17:02:35 - INFO - __main__ - !!! Best dev span_f1 (lr=2e-05, epoch=0): 62.99\n","06/18/2022 17:10:48 - INFO - __main__ - Epoch: 0, Step: 5700 / 22814, used_time = 3711.17s\n","06/18/2022 17:10:48 - INFO - __main__ - Processing example: 0\n","06/18/2022 17:11:17 - INFO - __main__ - Processing example: 2000\n","06/18/2022 17:11:45 - INFO - __main__ - Processing example: 4000\n","06/18/2022 17:12:14 - INFO - __main__ - Processing example: 6000\n","06/18/2022 17:12:43 - INFO - __main__ - Processing example: 8000\n","06/18/2022 17:13:11 - INFO - __main__ - Processing example: 10000\n","06/18/2022 17:13:40 - INFO - __main__ - Processing example: 12000\n","06/18/2022 17:14:09 - INFO - __main__ - Processing example: 14000\n","06/18/2022 17:14:38 - INFO - __main__ - Processing example: 16000\n","06/18/2022 17:15:06 - INFO - __main__ - Processing example: 18000\n","06/18/2022 17:15:58 - INFO - __main__ - ***** Eval results *****\n","06/18/2022 17:15:58 - INFO - __main__ -   exact = 56.89025562175668\n","06/18/2022 17:15:58 - INFO - __main__ -   f1 = 70.10307687297218\n","06/18/2022 17:15:58 - INFO - __main__ -   precision = 74.48461718240766\n","06/18/2022 17:15:58 - INFO - __main__ -   recall = 71.33077922299448\n","06/18/2022 17:15:58 - INFO - __main__ -   span_exact = 52.11416490486258\n","06/18/2022 17:15:58 - INFO - __main__ -   span_f1 = 64.89809779968533\n","06/18/2022 17:15:58 - INFO - __main__ -   span_precision = 69.52283210257292\n","06/18/2022 17:15:58 - INFO - __main__ -   span_recall = 65.95226147827795\n","06/18/2022 17:15:58 - INFO - __main__ -   total = 10406\n","06/18/2022 17:15:59 - INFO - __main__ - !!! Best dev span_f1 (lr=2e-05, epoch=0): 64.90\n","06/18/2022 17:24:13 - INFO - __main__ - Epoch: 0, Step: 6840 / 22814, used_time = 4516.20s\n","06/18/2022 17:24:13 - INFO - __main__ - Processing example: 0\n","06/18/2022 17:24:42 - INFO - __main__ - Processing example: 2000\n","06/18/2022 17:25:10 - INFO - __main__ - Processing example: 4000\n","06/18/2022 17:25:39 - INFO - __main__ - Processing example: 6000\n","06/18/2022 17:26:08 - INFO - __main__ - Processing example: 8000\n","06/18/2022 17:26:36 - INFO - __main__ - Processing example: 10000\n","06/18/2022 17:27:05 - INFO - __main__ - Processing example: 12000\n","06/18/2022 17:27:34 - INFO - __main__ - Processing example: 14000\n","06/18/2022 17:28:03 - INFO - __main__ - Processing example: 16000\n","06/18/2022 17:28:31 - INFO - __main__ - Processing example: 18000\n","06/18/2022 17:29:24 - INFO - __main__ - ***** Eval results *****\n","06/18/2022 17:29:24 - INFO - __main__ -   exact = 57.7743609456083\n","06/18/2022 17:29:24 - INFO - __main__ -   f1 = 70.92766801771432\n","06/18/2022 17:29:24 - INFO - __main__ -   precision = 75.06945631165193\n","06/18/2022 17:29:24 - INFO - __main__ -   recall = 72.21535506113588\n","06/18/2022 17:29:24 - INFO - __main__ -   span_exact = 53.31539496444359\n","06/18/2022 17:29:24 - INFO - __main__ -   span_f1 = 65.92602493038363\n","06/18/2022 17:29:24 - INFO - __main__ -   span_precision = 70.31483643136558\n","06/18/2022 17:29:24 - INFO - __main__ -   span_recall = 67.05868298234546\n","06/18/2022 17:29:24 - INFO - __main__ -   total = 10406\n","06/18/2022 17:29:24 - INFO - __main__ - !!! Best dev span_f1 (lr=2e-05, epoch=0): 65.93\n","06/18/2022 17:37:38 - INFO - __main__ - Epoch: 0, Step: 7980 / 22814, used_time = 5321.33s\n","06/18/2022 17:37:38 - INFO - __main__ - Processing example: 0\n","06/18/2022 17:38:07 - INFO - __main__ - Processing example: 2000\n","06/18/2022 17:38:35 - INFO - __main__ - Processing example: 4000\n","06/18/2022 17:39:04 - INFO - __main__ - Processing example: 6000\n","06/18/2022 17:39:33 - INFO - __main__ - Processing example: 8000\n","06/18/2022 17:40:02 - INFO - __main__ - Processing example: 10000\n","06/18/2022 17:40:30 - INFO - __main__ - Processing example: 12000\n","06/18/2022 17:40:59 - INFO - __main__ - Processing example: 14000\n","06/18/2022 17:41:28 - INFO - __main__ - Processing example: 16000\n","06/18/2022 17:41:56 - INFO - __main__ - Processing example: 18000\n","06/18/2022 17:42:50 - INFO - __main__ - ***** Eval results *****\n","06/18/2022 17:42:50 - INFO - __main__ -   exact = 59.74437824332116\n","06/18/2022 17:42:50 - INFO - __main__ -   f1 = 72.64856057331966\n","06/18/2022 17:42:50 - INFO - __main__ -   precision = 75.79239785276224\n","06/18/2022 17:42:50 - INFO - __main__ -   recall = 74.9506730830844\n","06/18/2022 17:42:50 - INFO - __main__ -   span_exact = 55.16048433596002\n","06/18/2022 17:42:50 - INFO - __main__ -   span_f1 = 67.98259525868525\n","06/18/2022 17:42:50 - INFO - __main__ -   span_precision = 71.43652990296644\n","06/18/2022 17:42:50 - INFO - __main__ -   span_recall = 70.07539521916321\n","06/18/2022 17:42:50 - INFO - __main__ -   total = 10406\n","06/18/2022 17:42:51 - INFO - __main__ - !!! Best dev span_f1 (lr=2e-05, epoch=0): 67.98\n","06/18/2022 17:51:04 - INFO - __main__ - Epoch: 0, Step: 9120 / 22814, used_time = 6127.40s\n","06/18/2022 17:51:04 - INFO - __main__ - Processing example: 0\n","06/18/2022 17:51:33 - INFO - __main__ - Processing example: 2000\n","06/18/2022 17:52:01 - INFO - __main__ - Processing example: 4000\n","06/18/2022 17:52:30 - INFO - __main__ - Processing example: 6000\n","06/18/2022 17:52:59 - INFO - __main__ - Processing example: 8000\n","06/18/2022 17:53:28 - INFO - __main__ - Processing example: 10000\n","06/18/2022 17:53:56 - INFO - __main__ - Processing example: 12000\n","06/18/2022 17:54:25 - INFO - __main__ - Processing example: 14000\n","06/18/2022 17:54:54 - INFO - __main__ - Processing example: 16000\n","06/18/2022 17:55:23 - INFO - __main__ - Processing example: 18000\n","06/18/2022 17:56:17 - INFO - __main__ - ***** Eval results *****\n","06/18/2022 17:56:17 - INFO - __main__ -   exact = 61.627906976744185\n","06/18/2022 17:56:17 - INFO - __main__ -   f1 = 74.5013469267462\n","06/18/2022 17:56:17 - INFO - __main__ -   precision = 77.39198553639177\n","06/18/2022 17:56:17 - INFO - __main__ -   recall = 77.0668419447726\n","06/18/2022 17:56:17 - INFO - __main__ -   span_exact = 56.84220641937344\n","06/18/2022 17:56:17 - INFO - __main__ -   span_f1 = 69.82157414872562\n","06/18/2022 17:56:17 - INFO - __main__ -   span_precision = 73.01729869550215\n","06/18/2022 17:56:17 - INFO - __main__ -   span_recall = 72.23913842257186\n","06/18/2022 17:56:17 - INFO - __main__ -   total = 10406\n","06/18/2022 17:56:17 - INFO - __main__ - !!! Best dev span_f1 (lr=2e-05, epoch=0): 69.82\n","06/18/2022 18:04:30 - INFO - __main__ - Epoch: 0, Step: 10260 / 22814, used_time = 6933.47s\n","06/18/2022 18:04:30 - INFO - __main__ - Processing example: 0\n","06/18/2022 18:04:59 - INFO - __main__ - Processing example: 2000\n","06/18/2022 18:05:28 - INFO - __main__ - Processing example: 4000\n","06/18/2022 18:05:56 - INFO - __main__ - Processing example: 6000\n","06/18/2022 18:06:25 - INFO - __main__ - Processing example: 8000\n","06/18/2022 18:06:54 - INFO - __main__ - Processing example: 10000\n","06/18/2022 18:07:22 - INFO - __main__ - Processing example: 12000\n","06/18/2022 18:07:51 - INFO - __main__ - Processing example: 14000\n","06/18/2022 18:08:20 - INFO - __main__ - Processing example: 16000\n","06/18/2022 18:08:49 - INFO - __main__ - Processing example: 18000\n","06/18/2022 18:09:45 - INFO - __main__ - ***** Eval results *****\n","06/18/2022 18:09:45 - INFO - __main__ -   exact = 62.31981549106285\n","06/18/2022 18:09:45 - INFO - __main__ -   f1 = 74.91056494990256\n","06/18/2022 18:09:45 - INFO - __main__ -   precision = 78.87480576224657\n","06/18/2022 18:09:45 - INFO - __main__ -   recall = 76.41950031094926\n","06/18/2022 18:09:45 - INFO - __main__ -   span_exact = 58.01460695752451\n","06/18/2022 18:09:45 - INFO - __main__ -   span_f1 = 70.59726679703668\n","06/18/2022 18:09:45 - INFO - __main__ -   span_precision = 74.9302005693494\n","06/18/2022 18:09:45 - INFO - __main__ -   span_recall = 71.9680107924901\n","06/18/2022 18:09:45 - INFO - __main__ -   total = 10406\n","06/18/2022 18:09:46 - INFO - __main__ - !!! Best dev span_f1 (lr=2e-05, epoch=0): 70.60\n","06/18/2022 18:17:58 - INFO - __main__ - Epoch: 0, Step: 11400 / 22814, used_time = 7741.74s\n","06/18/2022 18:17:58 - INFO - __main__ - Processing example: 0\n","06/18/2022 18:18:27 - INFO - __main__ - Processing example: 2000\n","06/18/2022 18:18:56 - INFO - __main__ - Processing example: 4000\n","06/18/2022 18:19:25 - INFO - __main__ - Processing example: 6000\n","06/18/2022 18:19:53 - INFO - __main__ - Processing example: 8000\n","06/18/2022 18:20:22 - INFO - __main__ - Processing example: 10000\n","06/18/2022 18:20:51 - INFO - __main__ - Processing example: 12000\n","06/18/2022 18:21:19 - INFO - __main__ - Processing example: 14000\n","06/18/2022 18:21:48 - INFO - __main__ - Processing example: 16000\n","06/18/2022 18:22:17 - INFO - __main__ - Processing example: 18000\n","06/18/2022 18:23:10 - INFO - __main__ - ***** Eval results *****\n","06/18/2022 18:23:10 - INFO - __main__ -   exact = 61.92581203152028\n","06/18/2022 18:23:10 - INFO - __main__ -   f1 = 75.26247560684618\n","06/18/2022 18:23:10 - INFO - __main__ -   precision = 78.14908746167524\n","06/18/2022 18:23:10 - INFO - __main__ -   recall = 77.9197089873355\n","06/18/2022 18:23:10 - INFO - __main__ -   span_exact = 57.255429559869306\n","06/18/2022 18:23:10 - INFO - __main__ -   span_f1 = 70.65284450236364\n","06/18/2022 18:23:10 - INFO - __main__ -   span_precision = 73.66341077114123\n","06/18/2022 18:23:10 - INFO - __main__ -   span_recall = 73.37855080275466\n","06/18/2022 18:23:10 - INFO - __main__ -   total = 10406\n","06/18/2022 18:23:10 - INFO - __main__ - !!! Best dev span_f1 (lr=2e-05, epoch=0): 70.65\n","06/18/2022 18:31:22 - INFO - __main__ - Epoch: 0, Step: 12540 / 22814, used_time = 8545.51s\n","06/18/2022 18:31:22 - INFO - __main__ - Processing example: 0\n","06/18/2022 18:31:51 - INFO - __main__ - Processing example: 2000\n","06/18/2022 18:32:20 - INFO - __main__ - Processing example: 4000\n","06/18/2022 18:32:48 - INFO - __main__ - Processing example: 6000\n","06/18/2022 18:33:17 - INFO - __main__ - Processing example: 8000\n","06/18/2022 18:33:46 - INFO - __main__ - Processing example: 10000\n","06/18/2022 18:34:14 - INFO - __main__ - Processing example: 12000\n","06/18/2022 18:34:43 - INFO - __main__ - Processing example: 14000\n","06/18/2022 18:35:12 - INFO - __main__ - Processing example: 16000\n","06/18/2022 18:35:41 - INFO - __main__ - Processing example: 18000\n","06/18/2022 18:36:33 - INFO - __main__ - ***** Eval results *****\n","06/18/2022 18:36:33 - INFO - __main__ -   exact = 62.444743417259275\n","06/18/2022 18:36:33 - INFO - __main__ -   f1 = 75.65079669378767\n","06/18/2022 18:36:33 - INFO - __main__ -   precision = 78.1947555231705\n","06/18/2022 18:36:33 - INFO - __main__ -   recall = 79.00531532079313\n","06/18/2022 18:36:33 - INFO - __main__ -   span_exact = 57.89928887180473\n","06/18/2022 18:36:33 - INFO - __main__ -   span_f1 = 71.33300496310986\n","06/18/2022 18:36:33 - INFO - __main__ -   span_precision = 73.9233399042894\n","06/18/2022 18:36:33 - INFO - __main__ -   span_recall = 74.96023992269058\n","06/18/2022 18:36:33 - INFO - __main__ -   total = 10406\n","06/18/2022 18:36:34 - INFO - __main__ - !!! Best dev span_f1 (lr=2e-05, epoch=0): 71.33\n","06/18/2022 18:44:46 - INFO - __main__ - Epoch: 0, Step: 13680 / 22814, used_time = 9349.12s\n","06/18/2022 18:44:46 - INFO - __main__ - Processing example: 0\n","06/18/2022 18:45:14 - INFO - __main__ - Processing example: 2000\n","06/18/2022 18:45:43 - INFO - __main__ - Processing example: 4000\n","06/18/2022 18:46:12 - INFO - __main__ - Processing example: 6000\n","06/18/2022 18:46:41 - INFO - __main__ - Processing example: 8000\n","06/18/2022 18:47:09 - INFO - __main__ - Processing example: 10000\n","06/18/2022 18:47:38 - INFO - __main__ - Processing example: 12000\n","06/18/2022 18:48:07 - INFO - __main__ - Processing example: 14000\n","06/18/2022 18:48:36 - INFO - __main__ - Processing example: 16000\n","06/18/2022 18:49:04 - INFO - __main__ - Processing example: 18000\n","06/18/2022 18:50:01 - INFO - __main__ - ***** Eval results *****\n","06/18/2022 18:50:01 - INFO - __main__ -   exact = 63.0693830482414\n","06/18/2022 18:50:01 - INFO - __main__ -   f1 = 76.02195221551153\n","06/18/2022 18:50:01 - INFO - __main__ -   precision = 79.63309774932033\n","06/18/2022 18:50:01 - INFO - __main__ -   recall = 78.05341988811837\n","06/18/2022 18:50:01 - INFO - __main__ -   span_exact = 58.71612531231982\n","06/18/2022 18:50:01 - INFO - __main__ -   span_f1 = 71.75523681830865\n","06/18/2022 18:50:01 - INFO - __main__ -   span_precision = 75.68293457754055\n","06/18/2022 18:50:01 - INFO - __main__ -   span_recall = 73.77688779940988\n","06/18/2022 18:50:01 - INFO - __main__ -   total = 10406\n","06/18/2022 18:50:01 - INFO - __main__ - !!! Best dev span_f1 (lr=2e-05, epoch=0): 71.76\n","06/18/2022 18:58:13 - INFO - __main__ - Epoch: 0, Step: 14820 / 22814, used_time = 10156.07s\n","06/18/2022 18:58:13 - INFO - __main__ - Processing example: 0\n","06/18/2022 18:58:41 - INFO - __main__ - Processing example: 2000\n","06/18/2022 18:59:10 - INFO - __main__ - Processing example: 4000\n","06/18/2022 18:59:39 - INFO - __main__ - Processing example: 6000\n","06/18/2022 19:00:08 - INFO - __main__ - Processing example: 8000\n","06/18/2022 19:00:36 - INFO - __main__ - Processing example: 10000\n","06/18/2022 19:01:05 - INFO - __main__ - Processing example: 12000\n","06/18/2022 19:01:34 - INFO - __main__ - Processing example: 14000\n","06/18/2022 19:02:03 - INFO - __main__ - Processing example: 16000\n","06/18/2022 19:02:31 - INFO - __main__ - Processing example: 18000\n","06/18/2022 19:03:24 - INFO - __main__ - ***** Eval results *****\n","06/18/2022 19:03:24 - INFO - __main__ -   exact = 62.348645012492796\n","06/18/2022 19:03:24 - INFO - __main__ -   f1 = 75.43398747845814\n","06/18/2022 19:03:24 - INFO - __main__ -   precision = 78.31329945560847\n","06/18/2022 19:03:24 - INFO - __main__ -   recall = 78.22320931487748\n","06/18/2022 19:03:24 - INFO - __main__ -   span_exact = 57.86084950989814\n","06/18/2022 19:03:24 - INFO - __main__ -   span_f1 = 71.01768643021464\n","06/18/2022 19:03:24 - INFO - __main__ -   span_precision = 74.00873882351846\n","06/18/2022 19:03:24 - INFO - __main__ -   span_recall = 73.89167798034141\n","06/18/2022 19:03:24 - INFO - __main__ -   total = 10406\n","06/18/2022 19:11:35 - INFO - __main__ - Epoch: 0, Step: 15960 / 22814, used_time = 10958.05s\n","06/18/2022 19:11:35 - INFO - __main__ - Processing example: 0\n","06/18/2022 19:12:03 - INFO - __main__ - Processing example: 2000\n","06/18/2022 19:12:32 - INFO - __main__ - Processing example: 4000\n","06/18/2022 19:13:01 - INFO - __main__ - Processing example: 6000\n","06/18/2022 19:13:30 - INFO - __main__ - Processing example: 8000\n","06/18/2022 19:13:58 - INFO - __main__ - Processing example: 10000\n","06/18/2022 19:14:27 - INFO - __main__ - Processing example: 12000\n","06/18/2022 19:14:56 - INFO - __main__ - Processing example: 14000\n","06/18/2022 19:15:24 - INFO - __main__ - Processing example: 16000\n","06/18/2022 19:15:53 - INFO - __main__ - Processing example: 18000\n","06/18/2022 19:16:44 - INFO - __main__ - ***** Eval results *****\n","06/18/2022 19:16:44 - INFO - __main__ -   exact = 63.61714395541034\n","06/18/2022 19:16:44 - INFO - __main__ -   f1 = 76.06980612633328\n","06/18/2022 19:16:44 - INFO - __main__ -   precision = 80.0060195483339\n","06/18/2022 19:16:44 - INFO - __main__ -   recall = 77.660367892251\n","06/18/2022 19:16:44 - INFO - __main__ -   span_exact = 58.77378435517971\n","06/18/2022 19:16:44 - INFO - __main__ -   span_f1 = 71.60833020643206\n","06/18/2022 19:16:44 - INFO - __main__ -   span_precision = 75.61204842143417\n","06/18/2022 19:16:44 - INFO - __main__ -   span_recall = 73.34484983913512\n","06/18/2022 19:16:44 - INFO - __main__ -   total = 10406\n","06/18/2022 19:24:55 - INFO - __main__ - Epoch: 0, Step: 17100 / 22814, used_time = 11758.10s\n","06/18/2022 19:24:55 - INFO - __main__ - Processing example: 0\n","06/18/2022 19:25:23 - INFO - __main__ - Processing example: 2000\n","06/18/2022 19:25:52 - INFO - __main__ - Processing example: 4000\n","06/18/2022 19:26:21 - INFO - __main__ - Processing example: 6000\n","06/18/2022 19:26:50 - INFO - __main__ - Processing example: 8000\n","06/18/2022 19:27:18 - INFO - __main__ - Processing example: 10000\n","06/18/2022 19:27:47 - INFO - __main__ - Processing example: 12000\n","06/18/2022 19:28:16 - INFO - __main__ - Processing example: 14000\n","06/18/2022 19:28:45 - INFO - __main__ - Processing example: 16000\n","06/18/2022 19:29:13 - INFO - __main__ - Processing example: 18000\n","06/18/2022 19:30:09 - INFO - __main__ - ***** Eval results *****\n","06/18/2022 19:30:09 - INFO - __main__ -   exact = 61.90659235056698\n","06/18/2022 19:30:09 - INFO - __main__ -   f1 = 74.68184549116725\n","06/18/2022 19:30:09 - INFO - __main__ -   precision = 78.80622151184193\n","06/18/2022 19:30:09 - INFO - __main__ -   recall = 76.08025603370021\n","06/18/2022 19:30:09 - INFO - __main__ -   span_exact = 57.0536229098597\n","06/18/2022 19:30:09 - INFO - __main__ -   span_f1 = 70.04132857135528\n","06/18/2022 19:30:09 - INFO - __main__ -   span_precision = 74.22575386369813\n","06/18/2022 19:30:09 - INFO - __main__ -   span_recall = 71.57897284271749\n","06/18/2022 19:30:09 - INFO - __main__ -   total = 10406\n","06/18/2022 19:38:19 - INFO - __main__ - Epoch: 0, Step: 18240 / 22814, used_time = 12562.73s\n","06/18/2022 19:38:19 - INFO - __main__ - Processing example: 0\n","06/18/2022 19:38:48 - INFO - __main__ - Processing example: 2000\n","06/18/2022 19:39:17 - INFO - __main__ - Processing example: 4000\n","06/18/2022 19:39:46 - INFO - __main__ - Processing example: 6000\n","06/18/2022 19:40:14 - INFO - __main__ - Processing example: 8000\n","06/18/2022 19:40:43 - INFO - __main__ - Processing example: 10000\n","06/18/2022 19:41:12 - INFO - __main__ - Processing example: 12000\n","06/18/2022 19:41:40 - INFO - __main__ - Processing example: 14000\n","06/18/2022 19:42:09 - INFO - __main__ - Processing example: 16000\n","06/18/2022 19:42:38 - INFO - __main__ - Processing example: 18000\n","06/18/2022 19:43:31 - INFO - __main__ - ***** Eval results *****\n","06/18/2022 19:43:31 - INFO - __main__ -   exact = 63.8093407649433\n","06/18/2022 19:43:31 - INFO - __main__ -   f1 = 76.61054361401055\n","06/18/2022 19:43:31 - INFO - __main__ -   precision = 80.54938558253164\n","06/18/2022 19:43:31 - INFO - __main__ -   recall = 78.18149127578242\n","06/18/2022 19:43:31 - INFO - __main__ -   span_exact = 58.89871228137613\n","06/18/2022 19:43:31 - INFO - __main__ -   span_f1 = 71.83597755984712\n","06/18/2022 19:43:31 - INFO - __main__ -   span_precision = 75.95873274644399\n","06/18/2022 19:43:31 - INFO - __main__ -   span_recall = 73.41371357357788\n","06/18/2022 19:43:31 - INFO - __main__ -   total = 10406\n","06/18/2022 19:43:31 - INFO - __main__ - !!! Best dev span_f1 (lr=2e-05, epoch=0): 71.84\n","06/18/2022 19:51:44 - INFO - __main__ - Epoch: 0, Step: 19380 / 22814, used_time = 13366.85s\n","06/18/2022 19:51:44 - INFO - __main__ - Processing example: 0\n","06/18/2022 19:52:12 - INFO - __main__ - Processing example: 2000\n","06/18/2022 19:52:41 - INFO - __main__ - Processing example: 4000\n","06/18/2022 19:53:10 - INFO - __main__ - Processing example: 6000\n","06/18/2022 19:53:38 - INFO - __main__ - Processing example: 8000\n","06/18/2022 19:54:07 - INFO - __main__ - Processing example: 10000\n","06/18/2022 19:54:36 - INFO - __main__ - Processing example: 12000\n","06/18/2022 19:55:05 - INFO - __main__ - Processing example: 14000\n","06/18/2022 19:55:33 - INFO - __main__ - Processing example: 16000\n","06/18/2022 19:56:02 - INFO - __main__ - Processing example: 18000\n","06/18/2022 19:56:54 - INFO - __main__ - ***** Eval results *****\n","06/18/2022 19:56:54 - INFO - __main__ -   exact = 63.55948491255045\n","06/18/2022 19:56:54 - INFO - __main__ -   f1 = 76.48629538147297\n","06/18/2022 19:56:54 - INFO - __main__ -   precision = 80.2366857010124\n","06/18/2022 19:56:54 - INFO - __main__ -   recall = 78.38117182585769\n","06/18/2022 19:56:54 - INFO - __main__ -   span_exact = 58.80261387660965\n","06/18/2022 19:56:54 - INFO - __main__ -   span_f1 = 72.16457953740229\n","06/18/2022 19:56:54 - INFO - __main__ -   span_precision = 75.94230787324018\n","06/18/2022 19:56:54 - INFO - __main__ -   span_recall = 74.32764458037087\n","06/18/2022 19:56:54 - INFO - __main__ -   total = 10406\n","06/18/2022 19:56:54 - INFO - __main__ - !!! Best dev span_f1 (lr=2e-05, epoch=0): 72.16\n","06/18/2022 20:05:06 - INFO - __main__ - Epoch: 0, Step: 20520 / 22814, used_time = 14169.38s\n","06/18/2022 20:05:06 - INFO - __main__ - Processing example: 0\n","06/18/2022 20:05:35 - INFO - __main__ - Processing example: 2000\n","06/18/2022 20:06:03 - INFO - __main__ - Processing example: 4000\n","06/18/2022 20:06:32 - INFO - __main__ - Processing example: 6000\n","06/18/2022 20:07:01 - INFO - __main__ - Processing example: 8000\n","06/18/2022 20:07:30 - INFO - __main__ - Processing example: 10000\n","06/18/2022 20:07:58 - INFO - __main__ - Processing example: 12000\n","06/18/2022 20:08:27 - INFO - __main__ - Processing example: 14000\n","06/18/2022 20:08:56 - INFO - __main__ - Processing example: 16000\n","06/18/2022 20:09:25 - INFO - __main__ - Processing example: 18000\n","06/18/2022 20:10:21 - INFO - __main__ - ***** Eval results *****\n","06/18/2022 20:10:21 - INFO - __main__ -   exact = 62.684989429175474\n","06/18/2022 20:10:21 - INFO - __main__ -   f1 = 75.97143459831987\n","06/18/2022 20:10:21 - INFO - __main__ -   precision = 79.74960685936303\n","06/18/2022 20:10:21 - INFO - __main__ -   recall = 77.93758155697884\n","06/18/2022 20:10:21 - INFO - __main__ -   span_exact = 57.85123966942149\n","06/18/2022 20:10:21 - INFO - __main__ -   span_f1 = 71.39620841772275\n","06/18/2022 20:10:21 - INFO - __main__ -   span_precision = 75.3927525145896\n","06/18/2022 20:10:21 - INFO - __main__ -   span_recall = 73.41965697791372\n","06/18/2022 20:10:21 - INFO - __main__ -   total = 10406\n","06/18/2022 20:18:31 - INFO - __main__ - Epoch: 0, Step: 21660 / 22814, used_time = 14974.76s\n","06/18/2022 20:18:31 - INFO - __main__ - Processing example: 0\n","06/18/2022 20:19:00 - INFO - __main__ - Processing example: 2000\n","06/18/2022 20:19:29 - INFO - __main__ - Processing example: 4000\n","06/18/2022 20:19:58 - INFO - __main__ - Processing example: 6000\n","06/18/2022 20:20:26 - INFO - __main__ - Processing example: 8000\n","06/18/2022 20:20:55 - INFO - __main__ - Processing example: 10000\n","06/18/2022 20:21:24 - INFO - __main__ - Processing example: 12000\n","06/18/2022 20:21:53 - INFO - __main__ - Processing example: 14000\n","06/18/2022 20:22:21 - INFO - __main__ - Processing example: 16000\n","06/18/2022 20:22:50 - INFO - __main__ - Processing example: 18000\n","06/18/2022 20:23:41 - INFO - __main__ - ***** Eval results *****\n","06/18/2022 20:23:41 - INFO - __main__ -   exact = 62.85796655775514\n","06/18/2022 20:23:41 - INFO - __main__ -   f1 = 75.73361906262781\n","06/18/2022 20:23:41 - INFO - __main__ -   precision = 80.65703166234724\n","06/18/2022 20:23:41 - INFO - __main__ -   recall = 76.54051487714024\n","06/18/2022 20:23:41 - INFO - __main__ -   span_exact = 57.74553142417836\n","06/18/2022 20:23:41 - INFO - __main__ -   span_f1 = 70.73231323617442\n","06/18/2022 20:23:41 - INFO - __main__ -   span_precision = 75.90337119935157\n","06/18/2022 20:23:41 - INFO - __main__ -   span_recall = 71.55745800470315\n","06/18/2022 20:23:41 - INFO - __main__ -   total = 10406\n","06/18/2022 20:31:52 - INFO - __main__ - Epoch: 0, Step: 22800 / 22814, used_time = 15775.49s\n","06/18/2022 20:31:52 - INFO - __main__ - Processing example: 0\n","06/18/2022 20:32:21 - INFO - __main__ - Processing example: 2000\n","06/18/2022 20:32:50 - INFO - __main__ - Processing example: 4000\n","06/18/2022 20:33:18 - INFO - __main__ - Processing example: 6000\n","06/18/2022 20:33:47 - INFO - __main__ - Processing example: 8000\n","06/18/2022 20:34:16 - INFO - __main__ - Processing example: 10000\n","06/18/2022 20:34:44 - INFO - __main__ - Processing example: 12000\n","06/18/2022 20:35:13 - INFO - __main__ - Processing example: 14000\n","06/18/2022 20:35:42 - INFO - __main__ - Processing example: 16000\n","06/18/2022 20:36:11 - INFO - __main__ - Processing example: 18000\n","06/18/2022 20:37:05 - INFO - __main__ - ***** Eval results *****\n","06/18/2022 20:37:05 - INFO - __main__ -   exact = 63.59792427445704\n","06/18/2022 20:37:05 - INFO - __main__ -   f1 = 76.53137252646377\n","06/18/2022 20:37:05 - INFO - __main__ -   precision = 79.42439577102273\n","06/18/2022 20:37:05 - INFO - __main__ -   recall = 79.23979212166364\n","06/18/2022 20:37:05 - INFO - __main__ -   span_exact = 58.927541802806076\n","06/18/2022 20:37:05 - INFO - __main__ -   span_f1 = 72.1826716373111\n","06/18/2022 20:37:05 - INFO - __main__ -   span_precision = 75.15316484279455\n","06/18/2022 20:37:05 - INFO - __main__ -   span_recall = 75.0495018123407\n","06/18/2022 20:37:05 - INFO - __main__ -   total = 10406\n","06/18/2022 20:37:05 - INFO - __main__ - !!! Best dev span_f1 (lr=2e-05, epoch=0): 72.18\n","06/18/2022 20:37:13 - INFO - __main__ - Start epoch #1 (lr = 2e-05)...\n","06/18/2022 20:45:25 - INFO - __main__ - Epoch: 1, Step: 1140 / 22814, used_time = 16588.16s\n","06/18/2022 20:45:25 - INFO - __main__ - Processing example: 0\n","06/18/2022 20:45:54 - INFO - __main__ - Processing example: 2000\n","06/18/2022 20:46:22 - INFO - __main__ - Processing example: 4000\n","06/18/2022 20:46:51 - INFO - __main__ - Processing example: 6000\n","06/18/2022 20:47:20 - INFO - __main__ - Processing example: 8000\n","06/18/2022 20:47:48 - INFO - __main__ - Processing example: 10000\n","06/18/2022 20:48:17 - INFO - __main__ - Processing example: 12000\n","06/18/2022 20:48:46 - INFO - __main__ - Processing example: 14000\n","06/18/2022 20:49:15 - INFO - __main__ - Processing example: 16000\n","06/18/2022 20:49:43 - INFO - __main__ - Processing example: 18000\n","06/18/2022 20:50:42 - INFO - __main__ - ***** Eval results *****\n","06/18/2022 20:50:42 - INFO - __main__ -   exact = 64.84720353642129\n","06/18/2022 20:50:42 - INFO - __main__ -   f1 = 77.18035117958362\n","06/18/2022 20:50:42 - INFO - __main__ -   precision = 80.81672530495302\n","06/18/2022 20:50:42 - INFO - __main__ -   recall = 78.93965651520398\n","06/18/2022 20:50:42 - INFO - __main__ -   span_exact = 60.34018835287334\n","06/18/2022 20:50:42 - INFO - __main__ -   span_f1 = 72.83272440871386\n","06/18/2022 20:50:42 - INFO - __main__ -   span_precision = 76.82271548010915\n","06/18/2022 20:50:42 - INFO - __main__ -   span_recall = 74.48822348001232\n","06/18/2022 20:50:42 - INFO - __main__ -   total = 10406\n","06/18/2022 20:50:42 - INFO - __main__ - !!! Best dev span_f1 (lr=2e-05, epoch=1): 72.83\n","06/18/2022 20:58:56 - INFO - __main__ - Epoch: 1, Step: 2280 / 22814, used_time = 17398.95s\n","06/18/2022 20:58:56 - INFO - __main__ - Processing example: 0\n","06/18/2022 20:59:24 - INFO - __main__ - Processing example: 2000\n","06/18/2022 20:59:53 - INFO - __main__ - Processing example: 4000\n","06/18/2022 21:00:22 - INFO - __main__ - Processing example: 6000\n","06/18/2022 21:00:51 - INFO - __main__ - Processing example: 8000\n","06/18/2022 21:01:19 - INFO - __main__ - Processing example: 10000\n","06/18/2022 21:01:48 - INFO - __main__ - Processing example: 12000\n","06/18/2022 21:02:17 - INFO - __main__ - Processing example: 14000\n","06/18/2022 21:02:45 - INFO - __main__ - Processing example: 16000\n","06/18/2022 21:03:14 - INFO - __main__ - Processing example: 18000\n","06/18/2022 21:04:08 - INFO - __main__ - ***** Eval results *****\n","06/18/2022 21:04:08 - INFO - __main__ -   exact = 65.3661349221603\n","06/18/2022 21:04:08 - INFO - __main__ -   f1 = 77.11554126575182\n","06/18/2022 21:04:08 - INFO - __main__ -   precision = 81.37866469505859\n","06/18/2022 21:04:08 - INFO - __main__ -   recall = 78.11975014503042\n","06/18/2022 21:04:08 - INFO - __main__ -   span_exact = 60.89755910051893\n","06/18/2022 21:04:08 - INFO - __main__ -   span_f1 = 72.85564239346935\n","06/18/2022 21:04:08 - INFO - __main__ -   span_precision = 77.48710125024465\n","06/18/2022 21:04:08 - INFO - __main__ -   span_recall = 73.71923110765701\n","06/18/2022 21:04:08 - INFO - __main__ -   total = 10406\n","06/18/2022 21:04:08 - INFO - __main__ - !!! Best dev span_f1 (lr=2e-05, epoch=1): 72.86\n","06/18/2022 21:12:22 - INFO - __main__ - Epoch: 1, Step: 3420 / 22814, used_time = 18204.96s\n","06/18/2022 21:12:22 - INFO - __main__ - Processing example: 0\n","06/18/2022 21:12:50 - INFO - __main__ - Processing example: 2000\n","06/18/2022 21:13:19 - INFO - __main__ - Processing example: 4000\n","06/18/2022 21:13:48 - INFO - __main__ - Processing example: 6000\n","06/18/2022 21:14:16 - INFO - __main__ - Processing example: 8000\n","06/18/2022 21:14:45 - INFO - __main__ - Processing example: 10000\n","06/18/2022 21:15:14 - INFO - __main__ - Processing example: 12000\n","06/18/2022 21:15:43 - INFO - __main__ - Processing example: 14000\n","06/18/2022 21:16:11 - INFO - __main__ - Processing example: 16000\n","06/18/2022 21:16:40 - INFO - __main__ - Processing example: 18000\n","06/18/2022 21:17:33 - INFO - __main__ - ***** Eval results *****\n","06/18/2022 21:17:33 - INFO - __main__ -   exact = 64.85681337689795\n","06/18/2022 21:17:33 - INFO - __main__ -   f1 = 77.69423398565941\n","06/18/2022 21:17:33 - INFO - __main__ -   precision = 80.4415071388988\n","06/18/2022 21:17:33 - INFO - __main__ -   recall = 80.38951327324\n","06/18/2022 21:17:33 - INFO - __main__ -   span_exact = 60.52277532192966\n","06/18/2022 21:17:33 - INFO - __main__ -   span_f1 = 73.36683178357427\n","06/18/2022 21:17:33 - INFO - __main__ -   span_precision = 76.1987750931727\n","06/18/2022 21:17:33 - INFO - __main__ -   span_recall = 76.15776735123828\n","06/18/2022 21:17:33 - INFO - __main__ -   total = 10406\n","06/18/2022 21:17:33 - INFO - __main__ - !!! Best dev span_f1 (lr=2e-05, epoch=1): 73.37\n","06/18/2022 21:25:47 - INFO - __main__ - Epoch: 1, Step: 4560 / 22814, used_time = 19010.63s\n","06/18/2022 21:25:47 - INFO - __main__ - Processing example: 0\n","06/18/2022 21:26:16 - INFO - __main__ - Processing example: 2000\n","06/18/2022 21:26:45 - INFO - __main__ - Processing example: 4000\n","06/18/2022 21:27:13 - INFO - __main__ - Processing example: 6000\n","06/18/2022 21:27:42 - INFO - __main__ - Processing example: 8000\n","06/18/2022 21:28:11 - INFO - __main__ - Processing example: 10000\n","06/18/2022 21:28:40 - INFO - __main__ - Processing example: 12000\n","06/18/2022 21:29:08 - INFO - __main__ - Processing example: 14000\n","06/18/2022 21:29:37 - INFO - __main__ - Processing example: 16000\n","06/18/2022 21:30:06 - INFO - __main__ - Processing example: 18000\n","06/18/2022 21:31:03 - INFO - __main__ - ***** Eval results *****\n","06/18/2022 21:31:03 - INFO - __main__ -   exact = 66.48087641745147\n","06/18/2022 21:31:03 - INFO - __main__ -   f1 = 78.46038838382539\n","06/18/2022 21:31:03 - INFO - __main__ -   precision = 82.21690248661068\n","06/18/2022 21:31:03 - INFO - __main__ -   recall = 79.77463144665047\n","06/18/2022 21:31:03 - INFO - __main__ -   span_exact = 61.85854314818374\n","06/18/2022 21:31:03 - INFO - __main__ -   span_f1 = 74.25604110632047\n","06/18/2022 21:31:03 - INFO - __main__ -   span_precision = 78.18080652564466\n","06/18/2022 21:31:03 - INFO - __main__ -   span_recall = 75.57038253023626\n","06/18/2022 21:31:03 - INFO - __main__ -   total = 10406\n","06/18/2022 21:31:04 - INFO - __main__ - !!! Best dev span_f1 (lr=2e-05, epoch=1): 74.26\n","06/18/2022 21:39:17 - INFO - __main__ - Epoch: 1, Step: 5700 / 22814, used_time = 19820.42s\n","06/18/2022 21:39:17 - INFO - __main__ - Processing example: 0\n","06/18/2022 21:39:46 - INFO - __main__ - Processing example: 2000\n","06/18/2022 21:40:15 - INFO - __main__ - Processing example: 4000\n","06/18/2022 21:40:43 - INFO - __main__ - Processing example: 6000\n","06/18/2022 21:41:12 - INFO - __main__ - Processing example: 8000\n","06/18/2022 21:41:41 - INFO - __main__ - Processing example: 10000\n","06/18/2022 21:42:09 - INFO - __main__ - Processing example: 12000\n","06/18/2022 21:42:38 - INFO - __main__ - Processing example: 14000\n","06/18/2022 21:43:07 - INFO - __main__ - Processing example: 16000\n","06/18/2022 21:43:36 - INFO - __main__ - Processing example: 18000\n","06/18/2022 21:44:28 - INFO - __main__ - ***** Eval results *****\n","06/18/2022 21:44:28 - INFO - __main__ -   exact = 67.00941764366712\n","06/18/2022 21:44:28 - INFO - __main__ -   f1 = 78.92145485987044\n","06/18/2022 21:44:28 - INFO - __main__ -   precision = 82.93444148148376\n","06/18/2022 21:44:28 - INFO - __main__ -   recall = 80.03205684256218\n","06/18/2022 21:44:28 - INFO - __main__ -   span_exact = 62.19488756486642\n","06/18/2022 21:44:28 - INFO - __main__ -   span_f1 = 74.58510626456547\n","06/18/2022 21:44:28 - INFO - __main__ -   span_precision = 78.66597675879274\n","06/18/2022 21:44:28 - INFO - __main__ -   span_recall = 75.83910427879101\n","06/18/2022 21:44:28 - INFO - __main__ -   total = 10406\n","06/18/2022 21:44:28 - INFO - __main__ - !!! Best dev span_f1 (lr=2e-05, epoch=1): 74.59\n","06/18/2022 21:52:41 - INFO - __main__ - Epoch: 1, Step: 6840 / 22814, used_time = 20624.49s\n","06/18/2022 21:52:41 - INFO - __main__ - Processing example: 0\n","06/18/2022 21:53:10 - INFO - __main__ - Processing example: 2000\n","06/18/2022 21:53:39 - INFO - __main__ - Processing example: 4000\n","06/18/2022 21:54:07 - INFO - __main__ - Processing example: 6000\n","06/18/2022 21:54:36 - INFO - __main__ - Processing example: 8000\n","06/18/2022 21:55:05 - INFO - __main__ - Processing example: 10000\n","06/18/2022 21:55:33 - INFO - __main__ - Processing example: 12000\n","06/18/2022 21:56:02 - INFO - __main__ - Processing example: 14000\n","06/18/2022 21:56:31 - INFO - __main__ - Processing example: 16000\n","06/18/2022 21:57:00 - INFO - __main__ - Processing example: 18000\n","06/18/2022 21:57:53 - INFO - __main__ - ***** Eval results *****\n","06/18/2022 21:57:53 - INFO - __main__ -   exact = 66.74034211032097\n","06/18/2022 21:57:53 - INFO - __main__ -   f1 = 78.64685687051693\n","06/18/2022 21:57:53 - INFO - __main__ -   precision = 82.79348078232562\n","06/18/2022 21:57:53 - INFO - __main__ -   recall = 79.64322545614726\n","06/18/2022 21:57:53 - INFO - __main__ -   span_exact = 62.16605804343648\n","06/18/2022 21:57:53 - INFO - __main__ -   span_f1 = 74.29538229513226\n","06/18/2022 21:57:53 - INFO - __main__ -   span_precision = 78.59614075445272\n","06/18/2022 21:57:53 - INFO - __main__ -   span_recall = 75.30219011216958\n","06/18/2022 21:57:53 - INFO - __main__ -   total = 10406\n","06/18/2022 22:06:05 - INFO - __main__ - Epoch: 1, Step: 7980 / 22814, used_time = 21428.15s\n","06/18/2022 22:06:05 - INFO - __main__ - Processing example: 0\n","06/18/2022 22:06:34 - INFO - __main__ - Processing example: 2000\n","06/18/2022 22:07:02 - INFO - __main__ - Processing example: 4000\n","06/18/2022 22:07:31 - INFO - __main__ - Processing example: 6000\n","06/18/2022 22:08:00 - INFO - __main__ - Processing example: 8000\n","06/18/2022 22:08:28 - INFO - __main__ - Processing example: 10000\n","06/18/2022 22:08:57 - INFO - __main__ - Processing example: 12000\n","06/18/2022 22:09:26 - INFO - __main__ - Processing example: 14000\n","06/18/2022 22:09:55 - INFO - __main__ - Processing example: 16000\n","06/18/2022 22:10:23 - INFO - __main__ - Processing example: 18000\n","06/18/2022 22:11:22 - INFO - __main__ - ***** Eval results *****\n","06/18/2022 22:11:22 - INFO - __main__ -   exact = 66.81722083413415\n","06/18/2022 22:11:22 - INFO - __main__ -   f1 = 78.94985969295185\n","06/18/2022 22:11:22 - INFO - __main__ -   precision = 83.09426123288605\n","06/18/2022 22:11:22 - INFO - __main__ -   recall = 80.01664873274699\n","06/18/2022 22:11:22 - INFO - __main__ -   span_exact = 62.435133576782626\n","06/18/2022 22:11:22 - INFO - __main__ -   span_f1 = 74.68377169569258\n","06/18/2022 22:11:22 - INFO - __main__ -   span_precision = 79.1273323538764\n","06/18/2022 22:11:22 - INFO - __main__ -   span_recall = 75.63070315073023\n","06/18/2022 22:11:22 - INFO - __main__ -   total = 10406\n","06/18/2022 22:11:22 - INFO - __main__ - !!! Best dev span_f1 (lr=2e-05, epoch=1): 74.68\n","06/18/2022 22:19:35 - INFO - __main__ - Epoch: 1, Step: 9120 / 22814, used_time = 22238.74s\n","06/18/2022 22:19:35 - INFO - __main__ - Processing example: 0\n","06/18/2022 22:20:04 - INFO - __main__ - Processing example: 2000\n","06/18/2022 22:20:33 - INFO - __main__ - Processing example: 4000\n","06/18/2022 22:21:02 - INFO - __main__ - Processing example: 6000\n","06/18/2022 22:21:30 - INFO - __main__ - Processing example: 8000\n","06/18/2022 22:21:59 - INFO - __main__ - Processing example: 10000\n","06/18/2022 22:22:28 - INFO - __main__ - Processing example: 12000\n","06/18/2022 22:22:56 - INFO - __main__ - Processing example: 14000\n","06/18/2022 22:23:25 - INFO - __main__ - Processing example: 16000\n","06/18/2022 22:23:54 - INFO - __main__ - Processing example: 18000\n","06/18/2022 22:24:48 - INFO - __main__ - ***** Eval results *****\n","06/18/2022 22:24:48 - INFO - __main__ -   exact = 66.41360753411493\n","06/18/2022 22:24:48 - INFO - __main__ -   f1 = 78.64025982663846\n","06/18/2022 22:24:48 - INFO - __main__ -   precision = 82.47021734911502\n","06/18/2022 22:24:48 - INFO - __main__ -   recall = 79.92647120851228\n","06/18/2022 22:24:48 - INFO - __main__ -   span_exact = 61.84893330770709\n","06/18/2022 22:24:48 - INFO - __main__ -   span_f1 = 74.4417072151428\n","06/18/2022 22:24:48 - INFO - __main__ -   span_precision = 78.47843321140357\n","06/18/2022 22:24:48 - INFO - __main__ -   span_recall = 75.73649272365621\n","06/18/2022 22:24:48 - INFO - __main__ -   total = 10406\n","06/18/2022 22:32:59 - INFO - __main__ - Epoch: 1, Step: 10260 / 22814, used_time = 23042.34s\n","06/18/2022 22:32:59 - INFO - __main__ - Processing example: 0\n","06/18/2022 22:33:28 - INFO - __main__ - Processing example: 2000\n","06/18/2022 22:33:56 - INFO - __main__ - Processing example: 4000\n","06/18/2022 22:34:25 - INFO - __main__ - Processing example: 6000\n","06/18/2022 22:34:54 - INFO - __main__ - Processing example: 8000\n","06/18/2022 22:35:23 - INFO - __main__ - Processing example: 10000\n","06/18/2022 22:35:51 - INFO - __main__ - Processing example: 12000\n","06/18/2022 22:36:20 - INFO - __main__ - Processing example: 14000\n","06/18/2022 22:36:49 - INFO - __main__ - Processing example: 16000\n","06/18/2022 22:37:17 - INFO - __main__ - Processing example: 18000\n","06/18/2022 22:38:10 - INFO - __main__ - ***** Eval results *****\n","06/18/2022 22:38:10 - INFO - __main__ -   exact = 66.77878147222756\n","06/18/2022 22:38:10 - INFO - __main__ -   f1 = 79.31426495955117\n","06/18/2022 22:38:10 - INFO - __main__ -   precision = 82.90552018150359\n","06/18/2022 22:38:10 - INFO - __main__ -   recall = 80.886350217771\n","06/18/2022 22:38:10 - INFO - __main__ -   span_exact = 62.406304055352685\n","06/18/2022 22:38:10 - INFO - __main__ -   span_f1 = 75.13202635097367\n","06/18/2022 22:38:10 - INFO - __main__ -   span_precision = 79.0597627455794\n","06/18/2022 22:38:10 - INFO - __main__ -   span_recall = 76.6117544663502\n","06/18/2022 22:38:10 - INFO - __main__ -   total = 10406\n","06/18/2022 22:38:10 - INFO - __main__ - !!! Best dev span_f1 (lr=2e-05, epoch=1): 75.13\n","06/18/2022 22:46:22 - INFO - __main__ - Epoch: 1, Step: 11400 / 22814, used_time = 23845.40s\n","06/18/2022 22:46:22 - INFO - __main__ - Processing example: 0\n","06/18/2022 22:46:51 - INFO - __main__ - Processing example: 2000\n","06/18/2022 22:47:19 - INFO - __main__ - Processing example: 4000\n","06/18/2022 22:47:48 - INFO - __main__ - Processing example: 6000\n","06/18/2022 22:48:17 - INFO - __main__ - Processing example: 8000\n","06/18/2022 22:48:46 - INFO - __main__ - Processing example: 10000\n","06/18/2022 22:49:14 - INFO - __main__ - Processing example: 12000\n","06/18/2022 22:49:43 - INFO - __main__ - Processing example: 14000\n","06/18/2022 22:50:12 - INFO - __main__ - Processing example: 16000\n","06/18/2022 22:50:40 - INFO - __main__ - Processing example: 18000\n","06/18/2022 22:51:38 - INFO - __main__ - ***** Eval results *****\n","06/18/2022 22:51:38 - INFO - __main__ -   exact = 66.99980780319046\n","06/18/2022 22:51:38 - INFO - __main__ -   f1 = 79.22171312617135\n","06/18/2022 22:51:38 - INFO - __main__ -   precision = 82.8268809440813\n","06/18/2022 22:51:38 - INFO - __main__ -   recall = 80.70930154551922\n","06/18/2022 22:51:38 - INFO - __main__ -   span_exact = 62.396694214876035\n","06/18/2022 22:51:38 - INFO - __main__ -   span_f1 = 74.95374331556214\n","06/18/2022 22:51:38 - INFO - __main__ -   span_precision = 78.6051565862042\n","06/18/2022 22:51:38 - INFO - __main__ -   span_recall = 76.6373854732842\n","06/18/2022 22:51:38 - INFO - __main__ -   total = 10406\n","06/18/2022 22:59:48 - INFO - __main__ - Epoch: 1, Step: 12540 / 22814, used_time = 24651.33s\n","06/18/2022 22:59:48 - INFO - __main__ - Processing example: 0\n","06/18/2022 23:00:17 - INFO - __main__ - Processing example: 2000\n","06/18/2022 23:00:45 - INFO - __main__ - Processing example: 4000\n","06/18/2022 23:01:14 - INFO - __main__ - Processing example: 6000\n","06/18/2022 23:01:43 - INFO - __main__ - Processing example: 8000\n","06/18/2022 23:02:12 - INFO - __main__ - Processing example: 10000\n","06/18/2022 23:02:40 - INFO - __main__ - Processing example: 12000\n","06/18/2022 23:03:09 - INFO - __main__ - Processing example: 14000\n","06/18/2022 23:03:38 - INFO - __main__ - Processing example: 16000\n","06/18/2022 23:04:06 - INFO - __main__ - Processing example: 18000\n","06/18/2022 23:05:00 - INFO - __main__ - ***** Eval results *****\n","06/18/2022 23:05:00 - INFO - __main__ -   exact = 66.5673649817413\n","06/18/2022 23:05:00 - INFO - __main__ -   f1 = 79.23675925522295\n","06/18/2022 23:05:00 - INFO - __main__ -   precision = 81.95284885082968\n","06/18/2022 23:05:00 - INFO - __main__ -   recall = 81.67284258498228\n","06/18/2022 23:05:00 - INFO - __main__ -   span_exact = 62.06034979819335\n","06/18/2022 23:05:00 - INFO - __main__ -   span_f1 = 75.06565908859653\n","06/18/2022 23:05:00 - INFO - __main__ -   span_precision = 77.69974365755027\n","06/18/2022 23:05:00 - INFO - __main__ -   span_recall = 77.9413421009618\n","06/18/2022 23:05:00 - INFO - __main__ -   total = 10406\n","06/18/2022 23:13:10 - INFO - __main__ - Epoch: 1, Step: 13680 / 22814, used_time = 25453.54s\n","06/18/2022 23:13:10 - INFO - __main__ - Processing example: 0\n","06/18/2022 23:13:39 - INFO - __main__ - Processing example: 2000\n","06/18/2022 23:14:08 - INFO - __main__ - Processing example: 4000\n","06/18/2022 23:14:36 - INFO - __main__ - Processing example: 6000\n","06/18/2022 23:15:05 - INFO - __main__ - Processing example: 8000\n","06/18/2022 23:15:34 - INFO - __main__ - Processing example: 10000\n","06/18/2022 23:16:02 - INFO - __main__ - Processing example: 12000\n","06/18/2022 23:16:31 - INFO - __main__ - Processing example: 14000\n","06/18/2022 23:17:00 - INFO - __main__ - Processing example: 16000\n","06/18/2022 23:17:29 - INFO - __main__ - Processing example: 18000\n","06/18/2022 23:18:21 - INFO - __main__ - ***** Eval results *****\n","06/18/2022 23:18:21 - INFO - __main__ -   exact = 66.91331923890064\n","06/18/2022 23:18:21 - INFO - __main__ -   f1 = 79.09576361099383\n","06/18/2022 23:18:21 - INFO - __main__ -   precision = 82.89403122688009\n","06/18/2022 23:18:21 - INFO - __main__ -   recall = 80.41733700299518\n","06/18/2022 23:18:21 - INFO - __main__ -   span_exact = 62.15644820295983\n","06/18/2022 23:18:21 - INFO - __main__ -   span_f1 = 74.85346036485365\n","06/18/2022 23:18:21 - INFO - __main__ -   span_precision = 78.72388195866796\n","06/18/2022 23:18:21 - INFO - __main__ -   span_recall = 76.36063224083519\n","06/18/2022 23:18:21 - INFO - __main__ -   total = 10406\n","06/18/2022 23:26:31 - INFO - __main__ - Epoch: 1, Step: 14820 / 22814, used_time = 26254.50s\n","06/18/2022 23:26:31 - INFO - __main__ - Processing example: 0\n","06/18/2022 23:27:00 - INFO - __main__ - Processing example: 2000\n","06/18/2022 23:27:29 - INFO - __main__ - Processing example: 4000\n","06/18/2022 23:27:57 - INFO - __main__ - Processing example: 6000\n","06/18/2022 23:28:26 - INFO - __main__ - Processing example: 8000\n","06/18/2022 23:28:55 - INFO - __main__ - Processing example: 10000\n","06/18/2022 23:29:23 - INFO - __main__ - Processing example: 12000\n","06/18/2022 23:29:52 - INFO - __main__ - Processing example: 14000\n","06/18/2022 23:30:21 - INFO - __main__ - Processing example: 16000\n","06/18/2022 23:30:50 - INFO - __main__ - Processing example: 18000\n","06/18/2022 23:31:46 - INFO - __main__ - ***** Eval results *****\n","06/18/2022 23:31:46 - INFO - __main__ -   exact = 66.76917163175091\n","06/18/2022 23:31:46 - INFO - __main__ -   f1 = 78.92540789824896\n","06/18/2022 23:31:46 - INFO - __main__ -   precision = 83.26894303113431\n","06/18/2022 23:31:46 - INFO - __main__ -   recall = 79.8674248720947\n","06/18/2022 23:31:46 - INFO - __main__ -   span_exact = 62.06034979819335\n","06/18/2022 23:31:46 - INFO - __main__ -   span_f1 = 74.63994224252508\n","06/18/2022 23:31:46 - INFO - __main__ -   span_precision = 79.18351416227381\n","06/18/2022 23:31:46 - INFO - __main__ -   span_recall = 75.67461820069168\n","06/18/2022 23:31:46 - INFO - __main__ -   total = 10406\n","06/18/2022 23:39:56 - INFO - __main__ - Epoch: 1, Step: 15960 / 22814, used_time = 27059.40s\n","06/18/2022 23:39:56 - INFO - __main__ - Processing example: 0\n","06/18/2022 23:40:25 - INFO - __main__ - Processing example: 2000\n","06/18/2022 23:40:53 - INFO - __main__ - Processing example: 4000\n","06/18/2022 23:41:22 - INFO - __main__ - Processing example: 6000\n","06/18/2022 23:41:51 - INFO - __main__ - Processing example: 8000\n","06/18/2022 23:42:20 - INFO - __main__ - Processing example: 10000\n","06/18/2022 23:42:48 - INFO - __main__ - Processing example: 12000\n","06/18/2022 23:43:17 - INFO - __main__ - Processing example: 14000\n","06/18/2022 23:43:46 - INFO - __main__ - Processing example: 16000\n","06/18/2022 23:44:15 - INFO - __main__ - Processing example: 18000\n","06/18/2022 23:45:06 - INFO - __main__ - ***** Eval results *****\n","06/18/2022 23:45:06 - INFO - __main__ -   exact = 66.61541418412455\n","06/18/2022 23:45:06 - INFO - __main__ -   f1 = 78.65531504565969\n","06/18/2022 23:45:06 - INFO - __main__ -   precision = 83.3052983120412\n","06/18/2022 23:45:06 - INFO - __main__ -   recall = 79.34934253437298\n","06/18/2022 23:45:06 - INFO - __main__ -   span_exact = 61.97386123390352\n","06/18/2022 23:45:06 - INFO - __main__ -   span_f1 = 74.29230759727797\n","06/18/2022 23:45:06 - INFO - __main__ -   span_precision = 78.9306101821123\n","06/18/2022 23:45:06 - INFO - __main__ -   span_recall = 75.2203790193746\n","06/18/2022 23:45:06 - INFO - __main__ -   total = 10406\n","06/18/2022 23:53:16 - INFO - __main__ - Epoch: 1, Step: 17100 / 22814, used_time = 27859.09s\n","06/18/2022 23:53:16 - INFO - __main__ - Processing example: 0\n","06/18/2022 23:53:44 - INFO - __main__ - Processing example: 2000\n","06/18/2022 23:54:13 - INFO - __main__ - Processing example: 4000\n","06/18/2022 23:54:42 - INFO - __main__ - Processing example: 6000\n","06/18/2022 23:55:11 - INFO - __main__ - Processing example: 8000\n","06/18/2022 23:55:39 - INFO - __main__ - Processing example: 10000\n","06/18/2022 23:56:08 - INFO - __main__ - Processing example: 12000\n","06/18/2022 23:56:37 - INFO - __main__ - Processing example: 14000\n","06/18/2022 23:57:05 - INFO - __main__ - Processing example: 16000\n","06/18/2022 23:57:34 - INFO - __main__ - Processing example: 18000\n","06/18/2022 23:58:26 - INFO - __main__ - ***** Eval results *****\n","06/18/2022 23:58:26 - INFO - __main__ -   exact = 66.46165673649817\n","06/18/2022 23:58:26 - INFO - __main__ -   f1 = 78.79993484670561\n","06/18/2022 23:58:26 - INFO - __main__ -   precision = 82.84230307033758\n","06/18/2022 23:58:26 - INFO - __main__ -   recall = 80.01351923962967\n","06/18/2022 23:58:26 - INFO - __main__ -   span_exact = 61.531808571977706\n","06/18/2022 23:58:26 - INFO - __main__ -   span_f1 = 74.53777735271517\n","06/18/2022 23:58:26 - INFO - __main__ -   span_precision = 78.82584006229172\n","06/18/2022 23:58:26 - INFO - __main__ -   span_recall = 75.82430966686181\n","06/18/2022 23:58:26 - INFO - __main__ -   total = 10406\n","06/19/2022 00:06:36 - INFO - __main__ - Epoch: 1, Step: 18240 / 22814, used_time = 28659.39s\n","06/19/2022 00:06:36 - INFO - __main__ - Processing example: 0\n","06/19/2022 00:07:05 - INFO - __main__ - Processing example: 2000\n","06/19/2022 00:07:33 - INFO - __main__ - Processing example: 4000\n","06/19/2022 00:08:02 - INFO - __main__ - Processing example: 6000\n","06/19/2022 00:08:31 - INFO - __main__ - Processing example: 8000\n","06/19/2022 00:09:00 - INFO - __main__ - Processing example: 10000\n","06/19/2022 00:09:28 - INFO - __main__ - Processing example: 12000\n","06/19/2022 00:09:57 - INFO - __main__ - Processing example: 14000\n","06/19/2022 00:10:26 - INFO - __main__ - Processing example: 16000\n","06/19/2022 00:10:54 - INFO - __main__ - Processing example: 18000\n","06/19/2022 00:11:51 - INFO - __main__ - ***** Eval results *****\n","06/19/2022 00:11:51 - INFO - __main__ -   exact = 66.64424370555449\n","06/19/2022 00:11:51 - INFO - __main__ -   f1 = 78.84424486653606\n","06/19/2022 00:11:51 - INFO - __main__ -   precision = 83.35749325013066\n","06/19/2022 00:11:51 - INFO - __main__ -   recall = 79.50292261387119\n","06/19/2022 00:11:51 - INFO - __main__ -   span_exact = 61.579857774360946\n","06/19/2022 00:11:51 - INFO - __main__ -   span_f1 = 74.32078321958055\n","06/19/2022 00:11:51 - INFO - __main__ -   span_precision = 79.17632432685262\n","06/19/2022 00:11:51 - INFO - __main__ -   span_recall = 74.9632821267989\n","06/19/2022 00:11:51 - INFO - __main__ -   total = 10406\n","06/19/2022 00:20:01 - INFO - __main__ - Epoch: 1, Step: 19380 / 22814, used_time = 29464.36s\n","06/19/2022 00:20:01 - INFO - __main__ - Processing example: 0\n","06/19/2022 00:20:30 - INFO - __main__ - Processing example: 2000\n","06/19/2022 00:20:58 - INFO - __main__ - Processing example: 4000\n","06/19/2022 00:21:27 - INFO - __main__ - Processing example: 6000\n","06/19/2022 00:21:56 - INFO - __main__ - Processing example: 8000\n","06/19/2022 00:22:25 - INFO - __main__ - Processing example: 10000\n","06/19/2022 00:22:53 - INFO - __main__ - Processing example: 12000\n","06/19/2022 00:23:22 - INFO - __main__ - Processing example: 14000\n","06/19/2022 00:23:51 - INFO - __main__ - Processing example: 16000\n","06/19/2022 00:24:19 - INFO - __main__ - Processing example: 18000\n","06/19/2022 00:25:12 - INFO - __main__ - ***** Eval results *****\n","06/19/2022 00:25:12 - INFO - __main__ -   exact = 66.1060926388622\n","06/19/2022 00:25:12 - INFO - __main__ -   f1 = 79.0501811244622\n","06/19/2022 00:25:12 - INFO - __main__ -   precision = 81.86435216923613\n","06/19/2022 00:25:12 - INFO - __main__ -   recall = 81.65116920045192\n","06/19/2022 00:25:12 - INFO - __main__ -   span_exact = 61.40688064578128\n","06/19/2022 00:25:12 - INFO - __main__ -   span_f1 = 74.64008904993389\n","06/19/2022 00:25:12 - INFO - __main__ -   span_precision = 77.46401504924535\n","06/19/2022 00:25:12 - INFO - __main__ -   span_recall = 77.57233060169528\n","06/19/2022 00:25:12 - INFO - __main__ -   total = 10406\n","06/19/2022 00:33:22 - INFO - __main__ - Epoch: 1, Step: 20520 / 22814, used_time = 30265.10s\n","06/19/2022 00:33:22 - INFO - __main__ - Processing example: 0\n","06/19/2022 00:33:50 - INFO - __main__ - Processing example: 2000\n","06/19/2022 00:34:19 - INFO - __main__ - Processing example: 4000\n","06/19/2022 00:34:48 - INFO - __main__ - Processing example: 6000\n","06/19/2022 00:35:17 - INFO - __main__ - Processing example: 8000\n","06/19/2022 00:35:45 - INFO - __main__ - Processing example: 10000\n","06/19/2022 00:36:14 - INFO - __main__ - Processing example: 12000\n","06/19/2022 00:36:43 - INFO - __main__ - Processing example: 14000\n","06/19/2022 00:37:11 - INFO - __main__ - Processing example: 16000\n","06/19/2022 00:37:40 - INFO - __main__ - Processing example: 18000\n","06/19/2022 00:38:31 - INFO - __main__ - ***** Eval results *****\n","06/19/2022 00:38:31 - INFO - __main__ -   exact = 66.8076109936575\n","06/19/2022 00:38:31 - INFO - __main__ -   f1 = 78.96189069693163\n","06/19/2022 00:38:31 - INFO - __main__ -   precision = 82.86448685499931\n","06/19/2022 00:38:31 - INFO - __main__ -   recall = 80.2513779409082\n","06/19/2022 00:38:31 - INFO - __main__ -   span_exact = 62.01230059581011\n","06/19/2022 00:38:31 - INFO - __main__ -   span_f1 = 74.59218432340722\n","06/19/2022 00:38:31 - INFO - __main__ -   span_precision = 78.65961004640859\n","06/19/2022 00:38:31 - INFO - __main__ -   span_recall = 75.97340802521533\n","06/19/2022 00:38:31 - INFO - __main__ -   total = 10406\n","06/19/2022 00:46:41 - INFO - __main__ - Epoch: 1, Step: 21660 / 22814, used_time = 31063.92s\n","06/19/2022 00:46:41 - INFO - __main__ - Processing example: 0\n","06/19/2022 00:47:09 - INFO - __main__ - Processing example: 2000\n","06/19/2022 00:47:38 - INFO - __main__ - Processing example: 4000\n","06/19/2022 00:48:07 - INFO - __main__ - Processing example: 6000\n","06/19/2022 00:48:35 - INFO - __main__ - Processing example: 8000\n","06/19/2022 00:49:04 - INFO - __main__ - Processing example: 10000\n","06/19/2022 00:49:33 - INFO - __main__ - Processing example: 12000\n","06/19/2022 00:50:06 - INFO - __main__ - Processing example: 14000\n","06/19/2022 00:50:34 - INFO - __main__ - Processing example: 16000\n","06/19/2022 00:51:03 - INFO - __main__ - Processing example: 18000\n","06/19/2022 00:51:55 - INFO - __main__ - ***** Eval results *****\n","06/19/2022 00:51:55 - INFO - __main__ -   exact = 66.39438785316163\n","06/19/2022 00:51:55 - INFO - __main__ -   f1 = 78.53643781126277\n","06/19/2022 00:51:55 - INFO - __main__ -   precision = 83.07073641438457\n","06/19/2022 00:51:55 - INFO - __main__ -   recall = 79.31578947662597\n","06/19/2022 00:51:55 - INFO - __main__ -   span_exact = 61.18585431481837\n","06/19/2022 00:51:55 - INFO - __main__ -   span_f1 = 73.79310658847699\n","06/19/2022 00:51:55 - INFO - __main__ -   span_precision = 78.60570033283827\n","06/19/2022 00:51:55 - INFO - __main__ -   span_recall = 74.55879101632027\n","06/19/2022 00:51:55 - INFO - __main__ -   total = 10406\n","06/19/2022 01:00:05 - INFO - __main__ - Epoch: 1, Step: 22800 / 22814, used_time = 31868.47s\n","06/19/2022 01:00:05 - INFO - __main__ - Processing example: 0\n","06/19/2022 01:00:34 - INFO - __main__ - Processing example: 2000\n","06/19/2022 01:01:03 - INFO - __main__ - Processing example: 4000\n","06/19/2022 01:01:31 - INFO - __main__ - Processing example: 6000\n","06/19/2022 01:02:00 - INFO - __main__ - Processing example: 8000\n","06/19/2022 01:02:29 - INFO - __main__ - Processing example: 10000\n","06/19/2022 01:02:57 - INFO - __main__ - Processing example: 12000\n","06/19/2022 01:03:26 - INFO - __main__ - Processing example: 14000\n","06/19/2022 01:03:55 - INFO - __main__ - Processing example: 16000\n","06/19/2022 01:04:24 - INFO - __main__ - Processing example: 18000\n","06/19/2022 01:05:17 - INFO - __main__ - ***** Eval results *****\n","06/19/2022 01:05:17 - INFO - __main__ -   exact = 66.72112242936767\n","06/19/2022 01:05:17 - INFO - __main__ -   f1 = 78.91534856776883\n","06/19/2022 01:05:17 - INFO - __main__ -   precision = 82.74808654620426\n","06/19/2022 01:05:17 - INFO - __main__ -   recall = 80.29231177729997\n","06/19/2022 01:05:17 - INFO - __main__ -   span_exact = 61.85854314818374\n","06/19/2022 01:05:17 - INFO - __main__ -   span_f1 = 74.57564211390485\n","06/19/2022 01:05:17 - INFO - __main__ -   span_precision = 78.68845415645495\n","06/19/2022 01:05:17 - INFO - __main__ -   span_recall = 75.95164165517774\n","06/19/2022 01:05:17 - INFO - __main__ -   total = 10406\n","06/19/2022 01:05:23 - INFO - __main__ - Start epoch #2 (lr = 2e-05)...\n","06/19/2022 01:13:35 - INFO - __main__ - Epoch: 2, Step: 1140 / 22814, used_time = 32678.03s\n","06/19/2022 01:13:35 - INFO - __main__ - Processing example: 0\n","06/19/2022 01:14:03 - INFO - __main__ - Processing example: 2000\n","06/19/2022 01:14:32 - INFO - __main__ - Processing example: 4000\n","06/19/2022 01:15:01 - INFO - __main__ - Processing example: 6000\n","06/19/2022 01:15:30 - INFO - __main__ - Processing example: 8000\n","06/19/2022 01:15:58 - INFO - __main__ - Processing example: 10000\n","06/19/2022 01:16:27 - INFO - __main__ - Processing example: 12000\n","06/19/2022 01:16:56 - INFO - __main__ - Processing example: 14000\n","06/19/2022 01:17:24 - INFO - __main__ - Processing example: 16000\n","06/19/2022 01:17:53 - INFO - __main__ - Processing example: 18000\n","06/19/2022 01:18:46 - INFO - __main__ - ***** Eval results *****\n","06/19/2022 01:18:46 - INFO - __main__ -   exact = 67.067076686527\n","06/19/2022 01:18:46 - INFO - __main__ -   f1 = 79.08323332113655\n","06/19/2022 01:18:46 - INFO - __main__ -   precision = 82.78115532804205\n","06/19/2022 01:18:46 - INFO - __main__ -   recall = 80.54794875987982\n","06/19/2022 01:18:46 - INFO - __main__ -   span_exact = 62.627330386315585\n","06/19/2022 01:18:46 - INFO - __main__ -   span_f1 = 74.9966244717374\n","06/19/2022 01:18:46 - INFO - __main__ -   span_precision = 78.93979345821762\n","06/19/2022 01:18:46 - INFO - __main__ -   span_recall = 76.50841404210111\n","06/19/2022 01:18:46 - INFO - __main__ -   total = 10406\n","06/19/2022 01:26:58 - INFO - __main__ - Epoch: 2, Step: 2280 / 22814, used_time = 33481.31s\n","06/19/2022 01:26:58 - INFO - __main__ - Processing example: 0\n","06/19/2022 01:27:27 - INFO - __main__ - Processing example: 2000\n","06/19/2022 01:27:59 - INFO - __main__ - Processing example: 4000\n","06/19/2022 01:28:28 - INFO - __main__ - Processing example: 6000\n","06/19/2022 01:28:57 - INFO - __main__ - Processing example: 8000\n","06/19/2022 01:29:25 - INFO - __main__ - Processing example: 10000\n","06/19/2022 01:29:54 - INFO - __main__ - Processing example: 12000\n","06/19/2022 01:30:23 - INFO - __main__ - Processing example: 14000\n","06/19/2022 01:30:52 - INFO - __main__ - Processing example: 16000\n","06/19/2022 01:31:20 - INFO - __main__ - Processing example: 18000\n","06/19/2022 01:32:13 - INFO - __main__ - ***** Eval results *****\n","06/19/2022 01:32:13 - INFO - __main__ -   exact = 67.0478570055737\n","06/19/2022 01:32:13 - INFO - __main__ -   f1 = 78.97574008293327\n","06/19/2022 01:32:13 - INFO - __main__ -   precision = 83.21876352139992\n","06/19/2022 01:32:13 - INFO - __main__ -   recall = 79.88671393754333\n","06/19/2022 01:32:13 - INFO - __main__ -   span_exact = 62.569671343455695\n","06/19/2022 01:32:13 - INFO - __main__ -   span_f1 = 74.82096099005999\n","06/19/2022 01:32:13 - INFO - __main__ -   span_precision = 79.30023383797791\n","06/19/2022 01:32:13 - INFO - __main__ -   span_recall = 75.7264245545256\n","06/19/2022 01:32:13 - INFO - __main__ -   total = 10406\n","06/19/2022 01:40:25 - INFO - __main__ - Epoch: 2, Step: 3420 / 22814, used_time = 34288.15s\n","06/19/2022 01:40:25 - INFO - __main__ - Processing example: 0\n","06/19/2022 01:40:54 - INFO - __main__ - Processing example: 2000\n","06/19/2022 01:41:22 - INFO - __main__ - Processing example: 4000\n","06/19/2022 01:41:51 - INFO - __main__ - Processing example: 6000\n","06/19/2022 01:42:20 - INFO - __main__ - Processing example: 8000\n","06/19/2022 01:42:48 - INFO - __main__ - Processing example: 10000\n","06/19/2022 01:43:17 - INFO - __main__ - Processing example: 12000\n","06/19/2022 01:43:46 - INFO - __main__ - Processing example: 14000\n","06/19/2022 01:44:15 - INFO - __main__ - Processing example: 16000\n","06/19/2022 01:44:43 - INFO - __main__ - Processing example: 18000\n","06/19/2022 01:45:36 - INFO - __main__ - ***** Eval results *****\n","06/19/2022 01:45:36 - INFO - __main__ -   exact = 67.11512588891024\n","06/19/2022 01:45:36 - INFO - __main__ -   f1 = 79.4397936991121\n","06/19/2022 01:45:36 - INFO - __main__ -   precision = 82.60482959521096\n","06/19/2022 01:45:36 - INFO - __main__ -   recall = 81.39876797953384\n","06/19/2022 01:45:36 - INFO - __main__ -   span_exact = 62.531231981549105\n","06/19/2022 01:45:36 - INFO - __main__ -   span_f1 = 75.21781179394488\n","06/19/2022 01:45:36 - INFO - __main__ -   span_precision = 78.53632559309771\n","06/19/2022 01:45:36 - INFO - __main__ -   span_recall = 77.27773216294709\n","06/19/2022 01:45:36 - INFO - __main__ -   total = 10406\n","06/19/2022 01:45:36 - INFO - __main__ - !!! Best dev span_f1 (lr=2e-05, epoch=2): 75.22\n","06/19/2022 01:53:49 - INFO - __main__ - Epoch: 2, Step: 4560 / 22814, used_time = 35092.37s\n","06/19/2022 01:53:49 - INFO - __main__ - Processing example: 0\n","06/19/2022 01:54:18 - INFO - __main__ - Processing example: 2000\n","06/19/2022 01:54:46 - INFO - __main__ - Processing example: 4000\n","06/19/2022 01:55:15 - INFO - __main__ - Processing example: 6000\n","06/19/2022 01:55:44 - INFO - __main__ - Processing example: 8000\n","06/19/2022 01:56:13 - INFO - __main__ - Processing example: 10000\n","06/19/2022 01:56:41 - INFO - __main__ - Processing example: 12000\n","06/19/2022 01:57:10 - INFO - __main__ - Processing example: 14000\n","06/19/2022 01:57:39 - INFO - __main__ - Processing example: 16000\n","06/19/2022 01:58:07 - INFO - __main__ - Processing example: 18000\n","06/19/2022 01:59:05 - INFO - __main__ - ***** Eval results *****\n","06/19/2022 01:59:05 - INFO - __main__ -   exact = 67.52834902940612\n","06/19/2022 01:59:05 - INFO - __main__ -   f1 = 79.73906493085056\n","06/19/2022 01:59:05 - INFO - __main__ -   precision = 83.29262588538695\n","06/19/2022 01:59:05 - INFO - __main__ -   recall = 81.23216976135733\n","06/19/2022 01:59:05 - INFO - __main__ -   span_exact = 62.90601576013838\n","06/19/2022 01:59:05 - INFO - __main__ -   span_f1 = 75.49993757981794\n","06/19/2022 01:59:05 - INFO - __main__ -   span_precision = 79.1922280432751\n","06/19/2022 01:59:05 - INFO - __main__ -   span_recall = 77.03476858578541\n","06/19/2022 01:59:05 - INFO - __main__ -   total = 10406\n","06/19/2022 01:59:05 - INFO - __main__ - !!! Best dev span_f1 (lr=2e-05, epoch=2): 75.50\n","06/19/2022 02:07:18 - INFO - __main__ - Epoch: 2, Step: 5700 / 22814, used_time = 35901.45s\n","06/19/2022 02:07:18 - INFO - __main__ - Processing example: 0\n","06/19/2022 02:07:47 - INFO - __main__ - Processing example: 2000\n","06/19/2022 02:08:16 - INFO - __main__ - Processing example: 4000\n","06/19/2022 02:08:44 - INFO - __main__ - Processing example: 6000\n","06/19/2022 02:09:13 - INFO - __main__ - Processing example: 8000\n","06/19/2022 02:09:42 - INFO - __main__ - Processing example: 10000\n","06/19/2022 02:10:10 - INFO - __main__ - Processing example: 12000\n","06/19/2022 02:10:39 - INFO - __main__ - Processing example: 14000\n","06/19/2022 02:11:08 - INFO - __main__ - Processing example: 16000\n","06/19/2022 02:11:37 - INFO - __main__ - Processing example: 18000\n","06/19/2022 02:12:29 - INFO - __main__ - ***** Eval results *****\n","06/19/2022 02:12:29 - INFO - __main__ -   exact = 67.67249663655583\n","06/19/2022 02:12:29 - INFO - __main__ -   f1 = 79.70075831804321\n","06/19/2022 02:12:29 - INFO - __main__ -   precision = 83.59580550827313\n","06/19/2022 02:12:29 - INFO - __main__ -   recall = 80.75507807268087\n","06/19/2022 02:12:29 - INFO - __main__ -   span_exact = 63.15587161253123\n","06/19/2022 02:12:29 - INFO - __main__ -   span_f1 = 75.51710381921025\n","06/19/2022 02:12:29 - INFO - __main__ -   span_precision = 79.57312849878609\n","06/19/2022 02:12:29 - INFO - __main__ -   span_recall = 76.60087391605198\n","06/19/2022 02:12:29 - INFO - __main__ -   total = 10406\n","06/19/2022 02:12:29 - INFO - __main__ - !!! Best dev span_f1 (lr=2e-05, epoch=2): 75.52\n","06/19/2022 02:20:42 - INFO - __main__ - Epoch: 2, Step: 6840 / 22814, used_time = 36705.23s\n","06/19/2022 02:20:42 - INFO - __main__ - Processing example: 0\n","06/19/2022 02:21:11 - INFO - __main__ - Processing example: 2000\n","06/19/2022 02:21:39 - INFO - __main__ - Processing example: 4000\n","06/19/2022 02:22:08 - INFO - __main__ - Processing example: 6000\n","06/19/2022 02:22:37 - INFO - __main__ - Processing example: 8000\n","06/19/2022 02:23:05 - INFO - __main__ - Processing example: 10000\n","06/19/2022 02:23:34 - INFO - __main__ - Processing example: 12000\n","06/19/2022 02:24:03 - INFO - __main__ - Processing example: 14000\n","06/19/2022 02:24:32 - INFO - __main__ - Processing example: 16000\n","06/19/2022 02:25:00 - INFO - __main__ - Processing example: 18000\n","06/19/2022 02:25:53 - INFO - __main__ - ***** Eval results *****\n","06/19/2022 02:25:53 - INFO - __main__ -   exact = 67.70132615798578\n","06/19/2022 02:25:53 - INFO - __main__ -   f1 = 79.74974727705997\n","06/19/2022 02:25:53 - INFO - __main__ -   precision = 83.99656501262534\n","06/19/2022 02:25:53 - INFO - __main__ -   recall = 80.53703913509018\n","06/19/2022 02:25:53 - INFO - __main__ -   span_exact = 63.0886027291947\n","06/19/2022 02:25:53 - INFO - __main__ -   span_f1 = 75.50387060714162\n","06/19/2022 02:25:53 - INFO - __main__ -   span_precision = 79.96286696786204\n","06/19/2022 02:25:53 - INFO - __main__ -   span_recall = 76.32101109621281\n","06/19/2022 02:25:53 - INFO - __main__ -   total = 10406\n","06/19/2022 02:34:05 - INFO - __main__ - Epoch: 2, Step: 7980 / 22814, used_time = 37508.21s\n","06/19/2022 02:34:05 - INFO - __main__ - Processing example: 0\n","06/19/2022 02:34:34 - INFO - __main__ - Processing example: 2000\n","06/19/2022 02:35:02 - INFO - __main__ - Processing example: 4000\n","06/19/2022 02:35:31 - INFO - __main__ - Processing example: 6000\n","06/19/2022 02:36:00 - INFO - __main__ - Processing example: 8000\n","06/19/2022 02:36:28 - INFO - __main__ - Processing example: 10000\n","06/19/2022 02:36:57 - INFO - __main__ - Processing example: 12000\n","06/19/2022 02:37:26 - INFO - __main__ - Processing example: 14000\n","06/19/2022 02:37:54 - INFO - __main__ - Processing example: 16000\n","06/19/2022 02:38:23 - INFO - __main__ - Processing example: 18000\n","06/19/2022 02:39:21 - INFO - __main__ - ***** Eval results *****\n","06/19/2022 02:39:21 - INFO - __main__ -   exact = 67.50912934845282\n","06/19/2022 02:39:21 - INFO - __main__ -   f1 = 79.74918396214771\n","06/19/2022 02:39:21 - INFO - __main__ -   precision = 83.75094395194937\n","06/19/2022 02:39:21 - INFO - __main__ -   recall = 80.82065052692492\n","06/19/2022 02:39:21 - INFO - __main__ -   span_exact = 62.92523544109168\n","06/19/2022 02:39:21 - INFO - __main__ -   span_f1 = 75.56263837104751\n","06/19/2022 02:39:21 - INFO - __main__ -   span_precision = 79.74727434317886\n","06/19/2022 02:39:21 - INFO - __main__ -   span_recall = 76.68736941992843\n","06/19/2022 02:39:21 - INFO - __main__ -   total = 10406\n","06/19/2022 02:39:21 - INFO - __main__ - !!! Best dev span_f1 (lr=2e-05, epoch=2): 75.56\n","06/19/2022 02:47:34 - INFO - __main__ - Epoch: 2, Step: 9120 / 22814, used_time = 38317.16s\n","06/19/2022 02:47:34 - INFO - __main__ - Processing example: 0\n","06/19/2022 02:48:03 - INFO - __main__ - Processing example: 2000\n","06/19/2022 02:48:31 - INFO - __main__ - Processing example: 4000\n","06/19/2022 02:49:00 - INFO - __main__ - Processing example: 6000\n","06/19/2022 02:49:29 - INFO - __main__ - Processing example: 8000\n","06/19/2022 02:49:57 - INFO - __main__ - Processing example: 10000\n","06/19/2022 02:50:26 - INFO - __main__ - Processing example: 12000\n","06/19/2022 02:50:55 - INFO - __main__ - Processing example: 14000\n","06/19/2022 02:51:23 - INFO - __main__ - Processing example: 16000\n","06/19/2022 02:51:52 - INFO - __main__ - Processing example: 18000\n","06/19/2022 02:52:45 - INFO - __main__ - ***** Eval results *****\n","06/19/2022 02:52:45 - INFO - __main__ -   exact = 67.55717855083606\n","06/19/2022 02:52:45 - INFO - __main__ -   f1 = 80.04758618858496\n","06/19/2022 02:52:45 - INFO - __main__ -   precision = 83.41660063186433\n","06/19/2022 02:52:45 - INFO - __main__ -   recall = 81.61208898911835\n","06/19/2022 02:52:45 - INFO - __main__ -   span_exact = 62.98289448395157\n","06/19/2022 02:52:45 - INFO - __main__ -   span_f1 = 75.8580171557099\n","06/19/2022 02:52:45 - INFO - __main__ -   span_precision = 79.35357746209077\n","06/19/2022 02:52:45 - INFO - __main__ -   span_recall = 77.55585228649885\n","06/19/2022 02:52:45 - INFO - __main__ -   total = 10406\n","06/19/2022 02:52:46 - INFO - __main__ - !!! Best dev span_f1 (lr=2e-05, epoch=2): 75.86\n","06/19/2022 03:00:58 - INFO - __main__ - Epoch: 2, Step: 10260 / 22814, used_time = 39120.90s\n","06/19/2022 03:00:58 - INFO - __main__ - Processing example: 0\n","06/19/2022 03:01:26 - INFO - __main__ - Processing example: 2000\n","06/19/2022 03:01:55 - INFO - __main__ - Processing example: 4000\n","06/19/2022 03:02:24 - INFO - __main__ - Processing example: 6000\n","06/19/2022 03:02:52 - INFO - __main__ - Processing example: 8000\n","06/19/2022 03:03:21 - INFO - __main__ - Processing example: 10000\n","06/19/2022 03:03:50 - INFO - __main__ - Processing example: 12000\n","06/19/2022 03:04:18 - INFO - __main__ - Processing example: 14000\n","06/19/2022 03:04:47 - INFO - __main__ - Processing example: 16000\n","06/19/2022 03:05:16 - INFO - __main__ - Processing example: 18000\n","06/19/2022 03:06:08 - INFO - __main__ - ***** Eval results *****\n","06/19/2022 03:06:08 - INFO - __main__ -   exact = 67.90313280799539\n","06/19/2022 03:06:08 - INFO - __main__ -   f1 = 80.16175033239134\n","06/19/2022 03:06:08 - INFO - __main__ -   precision = 83.91959393824546\n","06/19/2022 03:06:08 - INFO - __main__ -   recall = 81.45089688444047\n","06/19/2022 03:06:08 - INFO - __main__ -   span_exact = 63.10782241014799\n","06/19/2022 03:06:08 - INFO - __main__ -   span_f1 = 75.80744442254283\n","06/19/2022 03:06:08 - INFO - __main__ -   span_precision = 79.81935218595824\n","06/19/2022 03:06:08 - INFO - __main__ -   span_recall = 77.11198924882214\n","06/19/2022 03:06:08 - INFO - __main__ -   total = 10406\n","06/19/2022 03:14:19 - INFO - __main__ - Epoch: 2, Step: 11400 / 22814, used_time = 39922.00s\n","06/19/2022 03:14:19 - INFO - __main__ - Processing example: 0\n","06/19/2022 03:14:47 - INFO - __main__ - Processing example: 2000\n","06/19/2022 03:15:16 - INFO - __main__ - Processing example: 4000\n","06/19/2022 03:15:45 - INFO - __main__ - Processing example: 6000\n","06/19/2022 03:16:13 - INFO - __main__ - Processing example: 8000\n","06/19/2022 03:16:42 - INFO - __main__ - Processing example: 10000\n","06/19/2022 03:17:11 - INFO - __main__ - Processing example: 12000\n","06/19/2022 03:17:40 - INFO - __main__ - Processing example: 14000\n","06/19/2022 03:18:08 - INFO - __main__ - Processing example: 16000\n","06/19/2022 03:18:37 - INFO - __main__ - Processing example: 18000\n","06/19/2022 03:19:34 - INFO - __main__ - ***** Eval results *****\n","06/19/2022 03:19:34 - INFO - __main__ -   exact = 67.81664424370555\n","06/19/2022 03:19:34 - INFO - __main__ -   f1 = 80.18579007014526\n","06/19/2022 03:19:34 - INFO - __main__ -   precision = 83.69262023541255\n","06/19/2022 03:19:34 - INFO - __main__ -   recall = 81.7549013385452\n","06/19/2022 03:19:34 - INFO - __main__ -   span_exact = 63.09821256967135\n","06/19/2022 03:19:34 - INFO - __main__ -   span_f1 = 75.94569436680503\n","06/19/2022 03:19:34 - INFO - __main__ -   span_precision = 79.63132158368684\n","06/19/2022 03:19:34 - INFO - __main__ -   span_recall = 77.597972499337\n","06/19/2022 03:19:34 - INFO - __main__ -   total = 10406\n","06/19/2022 03:19:35 - INFO - __main__ - !!! Best dev span_f1 (lr=2e-05, epoch=2): 75.95\n","06/19/2022 03:27:47 - INFO - __main__ - Epoch: 2, Step: 12540 / 22814, used_time = 40729.97s\n","06/19/2022 03:27:47 - INFO - __main__ - Processing example: 0\n","06/19/2022 03:28:15 - INFO - __main__ - Processing example: 2000\n","06/19/2022 03:28:44 - INFO - __main__ - Processing example: 4000\n","06/19/2022 03:29:13 - INFO - __main__ - Processing example: 6000\n","06/19/2022 03:29:41 - INFO - __main__ - Processing example: 8000\n","06/19/2022 03:30:10 - INFO - __main__ - Processing example: 10000\n","06/19/2022 03:30:39 - INFO - __main__ - Processing example: 12000\n","06/19/2022 03:31:08 - INFO - __main__ - Processing example: 14000\n","06/19/2022 03:31:36 - INFO - __main__ - Processing example: 16000\n","06/19/2022 03:32:05 - INFO - __main__ - Processing example: 18000\n","06/19/2022 03:32:58 - INFO - __main__ - ***** Eval results *****\n","06/19/2022 03:32:58 - INFO - __main__ -   exact = 67.66288679607918\n","06/19/2022 03:32:58 - INFO - __main__ -   f1 = 80.03922932557246\n","06/19/2022 03:32:58 - INFO - __main__ -   precision = 83.61750118354244\n","06/19/2022 03:32:58 - INFO - __main__ -   recall = 81.4896285070861\n","06/19/2022 03:32:58 - INFO - __main__ -   span_exact = 63.0501633672881\n","06/19/2022 03:32:58 - INFO - __main__ -   span_f1 = 75.83844611538235\n","06/19/2022 03:32:58 - INFO - __main__ -   span_precision = 79.56499426097803\n","06/19/2022 03:32:58 - INFO - __main__ -   span_recall = 77.47002910396323\n","06/19/2022 03:32:58 - INFO - __main__ -   total = 10406\n","06/19/2022 03:41:08 - INFO - __main__ - Epoch: 2, Step: 13680 / 22814, used_time = 41531.44s\n","06/19/2022 03:41:08 - INFO - __main__ - Processing example: 0\n","06/19/2022 03:41:37 - INFO - __main__ - Processing example: 2000\n","06/19/2022 03:42:06 - INFO - __main__ - Processing example: 4000\n","06/19/2022 03:42:34 - INFO - __main__ - Processing example: 6000\n","06/19/2022 03:43:03 - INFO - __main__ - Processing example: 8000\n","06/19/2022 03:43:32 - INFO - __main__ - Processing example: 10000\n","06/19/2022 03:44:00 - INFO - __main__ - Processing example: 12000\n","06/19/2022 03:44:29 - INFO - __main__ - Processing example: 14000\n","06/19/2022 03:44:58 - INFO - __main__ - Processing example: 16000\n","06/19/2022 03:45:26 - INFO - __main__ - Processing example: 18000\n","06/19/2022 03:46:19 - INFO - __main__ - ***** Eval results *****\n","06/19/2022 03:46:19 - INFO - __main__ -   exact = 67.71093599846243\n","06/19/2022 03:46:19 - INFO - __main__ -   f1 = 79.96363611930903\n","06/19/2022 03:46:19 - INFO - __main__ -   precision = 83.52047223143013\n","06/19/2022 03:46:19 - INFO - __main__ -   recall = 81.42103832375759\n","06/19/2022 03:46:19 - INFO - __main__ -   span_exact = 63.01172400538151\n","06/19/2022 03:46:19 - INFO - __main__ -   span_f1 = 75.70532546555647\n","06/19/2022 03:46:19 - INFO - __main__ -   span_precision = 79.35659956499916\n","06/19/2022 03:46:19 - INFO - __main__ -   span_recall = 77.36956894443051\n","06/19/2022 03:46:19 - INFO - __main__ -   total = 10406\n","06/19/2022 03:54:28 - INFO - __main__ - Epoch: 2, Step: 14820 / 22814, used_time = 42331.78s\n","06/19/2022 03:54:28 - INFO - __main__ - Processing example: 0\n","06/19/2022 03:54:57 - INFO - __main__ - Processing example: 2000\n","06/19/2022 03:55:26 - INFO - __main__ - Processing example: 4000\n","06/19/2022 03:55:55 - INFO - __main__ - Processing example: 6000\n","06/19/2022 03:56:23 - INFO - __main__ - Processing example: 8000\n","06/19/2022 03:56:52 - INFO - __main__ - Processing example: 10000\n","06/19/2022 03:57:21 - INFO - __main__ - Processing example: 12000\n","06/19/2022 03:57:49 - INFO - __main__ - Processing example: 14000\n","06/19/2022 03:58:18 - INFO - __main__ - Processing example: 16000\n","06/19/2022 03:58:47 - INFO - __main__ - Processing example: 18000\n","06/19/2022 03:59:43 - INFO - __main__ - ***** Eval results *****\n","06/19/2022 03:59:43 - INFO - __main__ -   exact = 67.54756871035941\n","06/19/2022 03:59:43 - INFO - __main__ -   f1 = 79.75806854696184\n","06/19/2022 03:59:43 - INFO - __main__ -   precision = 83.7092799482205\n","06/19/2022 03:59:43 - INFO - __main__ -   recall = 80.81447031301799\n","06/19/2022 03:59:43 - INFO - __main__ -   span_exact = 62.74264847203536\n","06/19/2022 03:59:43 - INFO - __main__ -   span_f1 = 75.45461184920454\n","06/19/2022 03:59:43 - INFO - __main__ -   span_precision = 79.56310538938038\n","06/19/2022 03:59:43 - INFO - __main__ -   span_recall = 76.637142679971\n","06/19/2022 03:59:43 - INFO - __main__ -   total = 10406\n","06/19/2022 04:07:53 - INFO - __main__ - Epoch: 2, Step: 15960 / 22814, used_time = 43136.53s\n","06/19/2022 04:07:53 - INFO - __main__ - Processing example: 0\n","06/19/2022 04:08:22 - INFO - __main__ - Processing example: 2000\n","06/19/2022 04:08:51 - INFO - __main__ - Processing example: 4000\n","06/19/2022 04:09:19 - INFO - __main__ - Processing example: 6000\n","06/19/2022 04:09:48 - INFO - __main__ - Processing example: 8000\n","06/19/2022 04:10:17 - INFO - __main__ - Processing example: 10000\n","06/19/2022 04:10:45 - INFO - __main__ - Processing example: 12000\n","06/19/2022 04:11:14 - INFO - __main__ - Processing example: 14000\n","06/19/2022 04:11:43 - INFO - __main__ - Processing example: 16000\n","06/19/2022 04:12:12 - INFO - __main__ - Processing example: 18000\n","06/19/2022 04:13:04 - INFO - __main__ - ***** Eval results *****\n","06/19/2022 04:13:04 - INFO - __main__ -   exact = 67.55717855083606\n","06/19/2022 04:13:04 - INFO - __main__ -   f1 = 79.83112501588657\n","06/19/2022 04:13:04 - INFO - __main__ -   precision = 83.88283881966281\n","06/19/2022 04:13:04 - INFO - __main__ -   recall = 80.91832417505758\n","06/19/2022 04:13:04 - INFO - __main__ -   span_exact = 62.78108783394195\n","06/19/2022 04:13:04 - INFO - __main__ -   span_f1 = 75.52410941458506\n","06/19/2022 04:13:04 - INFO - __main__ -   span_precision = 79.69080697746233\n","06/19/2022 04:13:04 - INFO - __main__ -   span_recall = 76.76627263277273\n","06/19/2022 04:13:04 - INFO - __main__ -   total = 10406\n","06/19/2022 04:21:14 - INFO - __main__ - Epoch: 2, Step: 17100 / 22814, used_time = 43937.00s\n","06/19/2022 04:21:14 - INFO - __main__ - Processing example: 0\n","06/19/2022 04:21:42 - INFO - __main__ - Processing example: 2000\n","06/19/2022 04:22:11 - INFO - __main__ - Processing example: 4000\n","06/19/2022 04:22:40 - INFO - __main__ - Processing example: 6000\n","06/19/2022 04:23:08 - INFO - __main__ - Processing example: 8000\n","06/19/2022 04:23:37 - INFO - __main__ - Processing example: 10000\n","06/19/2022 04:24:06 - INFO - __main__ - Processing example: 12000\n","06/19/2022 04:24:34 - INFO - __main__ - Processing example: 14000\n","06/19/2022 04:25:03 - INFO - __main__ - Processing example: 16000\n","06/19/2022 04:25:32 - INFO - __main__ - Processing example: 18000\n","06/19/2022 04:26:23 - INFO - __main__ - ***** Eval results *****\n","06/19/2022 04:26:23 - INFO - __main__ -   exact = 67.74937536036902\n","06/19/2022 04:26:23 - INFO - __main__ -   f1 = 79.88349035579685\n","06/19/2022 04:26:23 - INFO - __main__ -   precision = 83.83511664151301\n","06/19/2022 04:26:23 - INFO - __main__ -   recall = 80.94216115371653\n","06/19/2022 04:26:23 - INFO - __main__ -   span_exact = 62.88679607918509\n","06/19/2022 04:26:23 - INFO - __main__ -   span_f1 = 75.57312827273725\n","06/19/2022 04:26:23 - INFO - __main__ -   span_precision = 79.7210519583009\n","06/19/2022 04:26:23 - INFO - __main__ -   span_recall = 76.76341506656627\n","06/19/2022 04:26:23 - INFO - __main__ -   total = 10406\n","06/19/2022 04:34:32 - INFO - __main__ - Epoch: 2, Step: 18240 / 22814, used_time = 44735.43s\n","06/19/2022 04:34:32 - INFO - __main__ - Processing example: 0\n","06/19/2022 04:35:01 - INFO - __main__ - Processing example: 2000\n","06/19/2022 04:35:29 - INFO - __main__ - Processing example: 4000\n","06/19/2022 04:35:58 - INFO - __main__ - Processing example: 6000\n","06/19/2022 04:36:27 - INFO - __main__ - Processing example: 8000\n","06/19/2022 04:36:56 - INFO - __main__ - Processing example: 10000\n","06/19/2022 04:37:24 - INFO - __main__ - Processing example: 12000\n","06/19/2022 04:37:53 - INFO - __main__ - Processing example: 14000\n","06/19/2022 04:38:22 - INFO - __main__ - Processing example: 16000\n","06/19/2022 04:38:50 - INFO - __main__ - Processing example: 18000\n","06/19/2022 04:39:43 - INFO - __main__ - ***** Eval results *****\n","06/19/2022 04:39:43 - INFO - __main__ -   exact = 67.87430328656545\n","06/19/2022 04:39:43 - INFO - __main__ -   f1 = 79.97999367006722\n","06/19/2022 04:39:43 - INFO - __main__ -   precision = 84.08791510743859\n","06/19/2022 04:39:43 - INFO - __main__ -   recall = 80.94540446631898\n","06/19/2022 04:39:43 - INFO - __main__ -   span_exact = 62.96367480299827\n","06/19/2022 04:39:43 - INFO - __main__ -   span_f1 = 75.58356214511996\n","06/19/2022 04:39:43 - INFO - __main__ -   span_precision = 79.94150753460464\n","06/19/2022 04:39:43 - INFO - __main__ -   span_recall = 76.59071968196497\n","06/19/2022 04:39:43 - INFO - __main__ -   total = 10406\n","06/19/2022 04:47:52 - INFO - __main__ - Epoch: 2, Step: 19380 / 22814, used_time = 45535.20s\n","06/19/2022 04:47:52 - INFO - __main__ - Processing example: 0\n","06/19/2022 04:48:21 - INFO - __main__ - Processing example: 2000\n","06/19/2022 04:48:49 - INFO - __main__ - Processing example: 4000\n","06/19/2022 04:49:18 - INFO - __main__ - Processing example: 6000\n","06/19/2022 04:49:51 - INFO - __main__ - Processing example: 8000\n","06/19/2022 04:50:19 - INFO - __main__ - Processing example: 10000\n","06/19/2022 04:50:48 - INFO - __main__ - Processing example: 12000\n","06/19/2022 04:51:17 - INFO - __main__ - Processing example: 14000\n","06/19/2022 04:51:45 - INFO - __main__ - Processing example: 16000\n","06/19/2022 04:52:14 - INFO - __main__ - Processing example: 18000\n","06/19/2022 04:53:06 - INFO - __main__ - ***** Eval results *****\n","06/19/2022 04:53:06 - INFO - __main__ -   exact = 67.67249663655583\n","06/19/2022 04:53:06 - INFO - __main__ -   f1 = 80.05651976058164\n","06/19/2022 04:53:06 - INFO - __main__ -   precision = 83.53533133852966\n","06/19/2022 04:53:06 - INFO - __main__ -   recall = 81.60782236583123\n","06/19/2022 04:53:06 - INFO - __main__ -   span_exact = 62.80030751489525\n","06/19/2022 04:53:06 - INFO - __main__ -   span_f1 = 75.64573973971915\n","06/19/2022 04:53:06 - INFO - __main__ -   span_precision = 79.2970201150599\n","06/19/2022 04:53:06 - INFO - __main__ -   span_recall = 77.34578019490414\n","06/19/2022 04:53:06 - INFO - __main__ -   total = 10406\n","06/19/2022 05:01:16 - INFO - __main__ - Epoch: 2, Step: 20520 / 22814, used_time = 46339.16s\n","06/19/2022 05:01:16 - INFO - __main__ - Processing example: 0\n","06/19/2022 05:01:44 - INFO - __main__ - Processing example: 2000\n","06/19/2022 05:02:13 - INFO - __main__ - Processing example: 4000\n","06/19/2022 05:02:42 - INFO - __main__ - Processing example: 6000\n","06/19/2022 05:03:11 - INFO - __main__ - Processing example: 8000\n","06/19/2022 05:03:39 - INFO - __main__ - Processing example: 10000\n","06/19/2022 05:04:08 - INFO - __main__ - Processing example: 12000\n","06/19/2022 05:04:37 - INFO - __main__ - Processing example: 14000\n","06/19/2022 05:05:05 - INFO - __main__ - Processing example: 16000\n","06/19/2022 05:05:34 - INFO - __main__ - Processing example: 18000\n","06/19/2022 05:06:26 - INFO - __main__ - ***** Eval results *****\n","06/19/2022 05:06:26 - INFO - __main__ -   exact = 67.73015567941572\n","06/19/2022 05:06:26 - INFO - __main__ -   f1 = 79.9524336965885\n","06/19/2022 05:06:26 - INFO - __main__ -   precision = 83.68217025930139\n","06/19/2022 05:06:26 - INFO - __main__ -   recall = 81.24606161501382\n","06/19/2022 05:06:26 - INFO - __main__ -   span_exact = 62.92523544109168\n","06/19/2022 05:06:26 - INFO - __main__ -   span_f1 = 75.60130506979944\n","06/19/2022 05:06:26 - INFO - __main__ -   span_precision = 79.57624964133568\n","06/19/2022 05:06:26 - INFO - __main__ -   span_recall = 76.96270262772707\n","06/19/2022 05:06:26 - INFO - __main__ -   total = 10406\n","06/19/2022 05:14:35 - INFO - __main__ - Epoch: 2, Step: 21660 / 22814, used_time = 47138.38s\n","06/19/2022 05:14:35 - INFO - __main__ - Processing example: 0\n","06/19/2022 05:15:04 - INFO - __main__ - Processing example: 2000\n","06/19/2022 05:15:32 - INFO - __main__ - Processing example: 4000\n","06/19/2022 05:16:01 - INFO - __main__ - Processing example: 6000\n","06/19/2022 05:16:30 - INFO - __main__ - Processing example: 8000\n","06/19/2022 05:16:58 - INFO - __main__ - Processing example: 10000\n","06/19/2022 05:17:27 - INFO - __main__ - Processing example: 12000\n","06/19/2022 05:17:56 - INFO - __main__ - Processing example: 14000\n","06/19/2022 05:18:24 - INFO - __main__ - Processing example: 16000\n","06/19/2022 05:18:53 - INFO - __main__ - Processing example: 18000\n","06/19/2022 05:19:49 - INFO - __main__ - ***** Eval results *****\n","06/19/2022 05:19:49 - INFO - __main__ -   exact = 67.83586392465885\n","06/19/2022 05:19:49 - INFO - __main__ -   f1 = 79.94904114265375\n","06/19/2022 05:19:49 - INFO - __main__ -   precision = 83.94814960808915\n","06/19/2022 05:19:49 - INFO - __main__ -   recall = 80.98160390488145\n","06/19/2022 05:19:49 - INFO - __main__ -   span_exact = 62.96367480299827\n","06/19/2022 05:19:49 - INFO - __main__ -   span_f1 = 75.61955178436942\n","06/19/2022 05:19:49 - INFO - __main__ -   span_precision = 79.85421908290367\n","06/19/2022 05:19:49 - INFO - __main__ -   span_recall = 76.71850007534137\n","06/19/2022 05:19:49 - INFO - __main__ -   total = 10406\n","06/19/2022 05:27:58 - INFO - __main__ - Epoch: 2, Step: 22800 / 22814, used_time = 47941.72s\n","06/19/2022 05:27:58 - INFO - __main__ - Processing example: 0\n","06/19/2022 05:28:27 - INFO - __main__ - Processing example: 2000\n","06/19/2022 05:28:56 - INFO - __main__ - Processing example: 4000\n","06/19/2022 05:29:24 - INFO - __main__ - Processing example: 6000\n","06/19/2022 05:29:53 - INFO - __main__ - Processing example: 8000\n"]}],"source":["!LABEL=trial_001 GEOP=0.99 WINS=3 LMB=0.8 bash run_blanc_naturalqa.sh"]},{"cell_type":"markdown","metadata":{"id":"9o7X2PkKiRQY"},"source":["# Test"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SekRDZRtiS3b","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1655622040350,"user_tz":-420,"elapsed":528072,"user":{"displayName":"Mạnh Dũng Nguyễn","userId":"13942456880411028305"}},"outputId":"3bb09fa5-4145-417a-820c-7f28f146d32c"},"outputs":[{"output_type":"stream","name":"stdout","text":["06/19/2022 06:51:59 - INFO - __main__ - device: cuda, n_gpu: 1, 16-bits training: False\n","06/19/2022 06:51:59 - INFO - __main__ - Namespace(dev_file='../data/naturalQ/dev.jsonl.gz', do_eval=True, do_lower_case=False, do_train=False, doc_stride=128, eval_batch_size=16, eval_metric='span_f1', eval_per_epoch=20, eval_test=True, fp16=False, geometric_p=0.99, gradient_accumulation_steps=1, learning_rate=2e-05, lmb=0.8, loss_scale=0, max_answer_length=30, max_query_length=64, max_seq_length=384, model='spanbert-base-cased', n_best_size=20, no_cuda=False, num_train_epochs=3.0, output_dir='./checkpoints/naturalqa/trial_001/1234', seed=1234, test_file='../data/naturalQ/test.jsonl.gz', train_batch_size=8, train_file='../data/naturalQ/train.jsonl.gz', train_mode='random_sorted', verbose_logging=False, warmup_proportion=0.1, window_size=3)\n","06/19/2022 06:51:59 - INFO - pytorch_pretrained_bert.file_utils - https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt not found in cache, downloading to /tmp/tmpe_d4nr23\n","100% 213450/213450 [00:00<00:00, 394469.16B/s]\n","06/19/2022 06:52:01 - INFO - pytorch_pretrained_bert.file_utils - copying /tmp/tmpe_d4nr23 to cache at /root/.pytorch_pretrained_bert/5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1\n","06/19/2022 06:52:01 - INFO - pytorch_pretrained_bert.file_utils - creating metadata file for /root/.pytorch_pretrained_bert/5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1\n","06/19/2022 06:52:01 - INFO - pytorch_pretrained_bert.file_utils - removing temp file /tmp/tmpe_d4nr23\n","06/19/2022 06:52:01 - INFO - pytorch_pretrained_bert.tokenization - loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt from cache at /root/.pytorch_pretrained_bert/5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1\n","06/19/2022 06:52:07 - INFO - __main__ - Processing 0 / 12836..\n","06/19/2022 06:52:07 - INFO - __main__ - Processing 1000 / 12836..\n","06/19/2022 06:52:07 - INFO - __main__ - Processing 2000 / 12836..\n","06/19/2022 06:52:08 - INFO - __main__ - Processing 3000 / 12836..\n","06/19/2022 06:52:08 - INFO - __main__ - Processing 4000 / 12836..\n","06/19/2022 06:52:08 - INFO - __main__ - Processing 5000 / 12836..\n","06/19/2022 06:52:09 - INFO - __main__ - Processing 6000 / 12836..\n","06/19/2022 06:52:09 - INFO - __main__ - Processing 7000 / 12836..\n","06/19/2022 06:52:09 - INFO - __main__ - Processing 8000 / 12836..\n","06/19/2022 06:52:10 - INFO - __main__ - Processing 9000 / 12836..\n","06/19/2022 06:52:10 - INFO - __main__ - Processing 10000 / 12836..\n","06/19/2022 06:52:10 - INFO - __main__ - Processing 11000 / 12836..\n","06/19/2022 06:52:11 - INFO - __main__ - Processing 12000 / 12836..\n","06/19/2022 06:52:11 - INFO - __main__ - Num avg answers: 1.2379245870987847\n","06/19/2022 06:53:12 - INFO - __main__ - ***** Test *****\n","06/19/2022 06:53:12 - INFO - __main__ -   Num orig examples = 12836\n","06/19/2022 06:53:12 - INFO - __main__ -   Num split examples = 27260\n","06/19/2022 06:53:12 - INFO - __main__ -   Batch size = 16\n","06/19/2022 06:53:13 - INFO - pytorch_pretrained_bert.blanc - loading archive file ./checkpoints/naturalqa/trial_001/1234\n","06/19/2022 06:53:13 - INFO - pytorch_pretrained_bert.blanc - Model config {\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"directionality\": \"bidi\",\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"max_position_embeddings\": 512,\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 28996\n","}\n","\n","06/19/2022 06:53:25 - INFO - __main__ - Processing example: 0\n","06/19/2022 06:53:53 - INFO - __main__ - Processing example: 2000\n","06/19/2022 06:54:22 - INFO - __main__ - Processing example: 4000\n","06/19/2022 06:54:51 - INFO - __main__ - Processing example: 6000\n","06/19/2022 06:55:20 - INFO - __main__ - Processing example: 8000\n","06/19/2022 06:55:48 - INFO - __main__ - Processing example: 10000\n","06/19/2022 06:56:17 - INFO - __main__ - Processing example: 12000\n","06/19/2022 06:56:46 - INFO - __main__ - Processing example: 14000\n","06/19/2022 06:57:14 - INFO - __main__ - Processing example: 16000\n","06/19/2022 06:57:43 - INFO - __main__ - Processing example: 18000\n","06/19/2022 06:58:12 - INFO - __main__ - Processing example: 20000\n","06/19/2022 06:58:40 - INFO - __main__ - Processing example: 22000\n","06/19/2022 06:59:09 - INFO - __main__ - Processing example: 24000\n","06/19/2022 06:59:38 - INFO - __main__ - Processing example: 26000\n","06/19/2022 07:00:37 - INFO - __main__ - ***** Eval results *****\n","06/19/2022 07:00:37 - INFO - __main__ -   exact = 68.33904643191025\n","06/19/2022 07:00:37 - INFO - __main__ -   f1 = 80.13052942292512\n","06/19/2022 07:00:37 - INFO - __main__ -   precision = 84.3854273736228\n","06/19/2022 07:00:37 - INFO - __main__ -   recall = 81.05526863446389\n","06/19/2022 07:00:37 - INFO - __main__ -   span_exact = 63.64132128388906\n","06/19/2022 07:00:37 - INFO - __main__ -   span_f1 = 76.22898281233684\n","06/19/2022 07:00:37 - INFO - __main__ -   span_precision = 80.78766269400504\n","06/19/2022 07:00:37 - INFO - __main__ -   span_recall = 77.14727778267871\n","06/19/2022 07:00:37 - INFO - __main__ -   total = 12836\n"]}],"source":["!LABEL=trial_001 GEOP=0.99 WINS=3 LMB=0.8 bash run_blanc_naturalqa_test.sh"]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[],"authorship_tag":"ABX9TyNY6tLAlWKSOAEEZRByTkUw"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}